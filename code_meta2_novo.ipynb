{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5874fce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\didia\\AppData\\Local\\Temp\\ipykernel_18608\\3710893620.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 53, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\didia\\AppData\\Local\\Temp\\ipykernel_18608\\3710893620.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 67, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fddcf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file          0\n",
       "id_sente      0\n",
       "id_article    0\n",
       "domain        0\n",
       "year          0\n",
       "sentences     0\n",
       "classe        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carregar dataset\n",
    "df = pd.read_csv('factnews_dataset.csv')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa80a44",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767f6d97",
   "metadata": {},
   "source": [
    "Pré-processamento da primeira meta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b071f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('factnews_dataset.csv')\n",
    "\n",
    "#criar grupo treino e teste\n",
    "train_df, test_df = train_test_split(df, test_size=0.7, random_state=42)\n",
    "\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "#criar coluna tokens\n",
    "train_df['tokens'] = train_df['sentences'].apply(lambda x: nltk.word_tokenize(str(x).lower()))\n",
    "\n",
    "# Tokenizar sem stopwords\n",
    "train_df['tokens'] = train_df['tokens'].apply(lambda toks: [t for t in toks if t not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b710fb",
   "metadata": {},
   "source": [
    "divisão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d457cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#criar grupo treino, validação e teste\\ntrain_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\\'classe\\'])\\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df[\\'classe\\'])\\n\\n#guardar conjuntos em memória\\ntrain_df.to_csv(\"train.csv\", index=False) \\nval_df.to_csv(\"val.csv\", index=False)\\ntest_df.to_csv(\"test.csv\", index=False)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#criar grupo treino, validação e teste\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['classe'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['classe'])\n",
    "\n",
    "#guardar conjuntos em memória\n",
    "train_df.to_csv(\"train.csv\", index=False) \n",
    "val_df.to_csv(\"val.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1708b8",
   "metadata": {},
   "source": [
    "balanceamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65b63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')\n",
    "val= pd.read_csv('val.csv')\n",
    "test= pd.read_csv('test.csv')\n",
    "\n",
    "train_oversampling= pd.read_csv('train_oversampling.csv')\n",
    "val_oversampling= pd.read_csv('val_oversampling.csv')\n",
    "test_oversampling= pd.read_csv('test_oversampling.csv')\n",
    "\n",
    "y_train= train['classe']\n",
    "y_train_oversampling= train_oversampling['classe']\n",
    "\n",
    "y_val=val['classe']\n",
    "y_val_oversampling = val_oversampling['classe']\n",
    "\n",
    "y_test= test['classe']\n",
    "y_test_oversampling = test_oversampling['classe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce488a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto de treino:  classe\n",
      "-1     779\n",
      " 0    2375\n",
      " 1     312\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de validação:  classe\n",
      "-1    195\n",
      " 0    594\n",
      " 1     78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de teste:  classe\n",
      "-1     417\n",
      " 0    1273\n",
      " 1     168\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de treino + exemplos:  classe\n",
      "-1    2375\n",
      " 0    2375\n",
      " 1    2375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de val + exemplos:  classe\n",
      "-1    594\n",
      " 0    594\n",
      " 1    594\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de teste + exemplos:  classe\n",
      "-1    1273\n",
      " 0    1273\n",
      " 1    1273\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes em cada conjunto\n",
    "print (\"conjunto de treino: \",y_train.value_counts().sort_index())\n",
    "print(\"\\nconjunto de validação: \",y_val.value_counts().sort_index())\n",
    "print(\"\\nconjunto de teste: \", y_test.value_counts().sort_index())\n",
    "print(\"\\nconjunto de treino + exemplos: \", y_train_oversampling.value_counts().sort_index())\n",
    "print(\"\\nconjunto de val + exemplos: \", y_val_oversampling.value_counts().sort_index())\n",
    "print(\"\\nconjunto de teste + exemplos: \", y_test_oversampling.value_counts().sort_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "940b76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def balancear_classes(conjunto):\n",
    "  # Separar cada classe\n",
    "  class_min = conjunto[conjunto['classe'] == -1]\n",
    "  class_med = conjunto[conjunto['classe'] == 1]\n",
    "  class_max = conjunto[conjunto['classe'] == 0]\n",
    "\n",
    "  # Número da classe maior\n",
    "  n_samples = len(class_max)\n",
    "\n",
    "  # Replicar as classes menores até o tamanho da maior\n",
    "  class_min_upsampled = resample(class_min, \n",
    "                              replace=True, \n",
    "                              n_samples=n_samples, \n",
    "                              random_state=42)\n",
    "\n",
    "  class_med_upsampled = resample(class_med, \n",
    "                              replace=True, \n",
    "                              n_samples=n_samples, \n",
    "                            random_state=42)\n",
    "\n",
    "  conjunto_oversampled = pd.concat([class_min_upsampled, class_med_upsampled, class_max])\n",
    "\n",
    "  # baralhar o conjunto \n",
    "  conjunto_oversampled = conjunto_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "  print(conjunto_oversampled['classe'].value_counts())\n",
    "\n",
    "  return conjunto_oversampled\n",
    "\n",
    "#train_oversampling.to_csv('train_oversampling.csv', index=False)\n",
    "#val_oversampling = balancear_classes(val)\n",
    "#test_oversampling= balancear_classes(test)\n",
    "\n",
    "#val_oversampling.to_csv('val_oversampling.csv', index=False)\n",
    "#test_oversampling.to_csv('test_oversampling.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262d8a4",
   "metadata": {},
   "source": [
    "tokeinização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d610e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\didia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [neym, ,, part, 20, novembr, vai, lider, seleç...\n",
      "1    [forç, internac, transform, quest, taiwan, ass...\n",
      "2    [alianç, mai, quant, parlament, eleit, nome, p...\n",
      "3    [ger, mort, '', ,, declar, cabr, ,, 16ª, entre...\n",
      "4    [bisp, barr, (, ba, ), ,, dom, luiz, flávi, ca...\n",
      "Name: stems, dtype: object\n",
      "0    [qued, ocorr, aliment, pux, cord, sent, contr,...\n",
      "1    [repercuss, nega, cas, fez, bolsonar, ,, candi...\n",
      "2    [brasil, lav, alm, após, decepcion, empat, col...\n",
      "3    [final, encontr, ,, sen, tucan, diss, esp, gov...\n",
      "4    [fiz, compromiss, líd, bas, hoj, líd, opos, ,,...\n",
      "Name: stems, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\didia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))\n",
    "def tokeinizar(train, val, test):\n",
    "\n",
    "    #criar coluna tokens\n",
    "    train['tokens'] = train['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "    val['tokens']   = val['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "    test['tokens'] = test['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "    train_oversampling['tokens'] = train_oversampling['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "\n",
    "    #remover stopwords\n",
    "    train['tokens'] = train['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "    val['tokens']   = val['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "    test['tokens']  = test['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "    train_oversampling['tokens'] = train_oversampling['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "\n",
    "    #matizar\n",
    "    #nltk . download ('rslp')\n",
    "    stemmer = nltk . stem . RSLPStemmer ()\n",
    "    train['stems'] = train['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "    val['stems']   = val['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "    test['stems'] = test['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "    train_oversampling['stems'] = train_oversampling['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "\n",
    "    nltk . download ('rslp')\n",
    "    stemmer = nltk . stem . RSLPStemmer ()\n",
    "    print(train['stems'].head())\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "train, val, test = tokeinizar(train, val, test)\n",
    "train_oversampling, val_oversampling, test_oversampling = tokeinizar(train_oversampling, val_oversampling, test_oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41608aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= train['classe']\n",
    "y_train_oversampling= train_oversampling['classe']\n",
    "\n",
    "y_val=val['classe']\n",
    "y_val_oversampling = val_oversampling['classe']\n",
    "\n",
    "y_test= test['classe']\n",
    "y_test_oversampling = test_oversampling['classe']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b02c9",
   "metadata": {},
   "source": [
    "# Construção dos modelos de representação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799b632",
   "metadata": {},
   "source": [
    "## TF-IDF - fred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d13758dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_IDF(train, val, test):\n",
    "    tf_vect = TfidfVectorizer(ngram_range =(1, 2), min_df =3, max_df =0.5, max_features =500)\n",
    "\n",
    "        #juntar os tokens matizados em frases novvamente \n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val   = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_test = test['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    X_train = tf_vect.fit_transform(text_train)\n",
    "    X_val   = tf_vect.transform(text_val)\n",
    "    X_test  = tf_vect.transform(text_test)\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b98a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_vec, X_val_tfidf_vec, X_test_tfidf_vec = TF_IDF(train,val, test)\n",
    "X_train_oversampling_tfidf_vec, X_val_oversampling_tfidf_vec, X_test_oversampling_tfidf_vec = TF_IDF(train_oversampling, val_oversampling, test_oversampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eaac49",
   "metadata": {},
   "source": [
    "## CountVectorizer -didi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1399bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective_count_vec(trial, train, val):\n",
    "    # Parâmetros a otimizar\n",
    "    max_features = trial.suggest_int(\"max_features\", 500, 5000)\n",
    "    ngram_min = trial.suggest_int(\"ngram_min\", 1, 2)\n",
    "    ngram_max = trial.suggest_int(\"ngram_max\", ngram_min, 3)  # garante ngram_max >= ngram_min\n",
    "\n",
    "    # CountVectorizer com parâmetros sugeridos\n",
    "    c_vect = CountVectorizer(\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b|[^\\w\\s]\",\n",
    "        ngram_range=(ngram_min, ngram_max),\n",
    "        strip_accents='unicode',\n",
    "        max_features=max_features\n",
    "    )\n",
    "\n",
    "    # Transformar textos\n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val   = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    X_train = c_vect.fit_transform(text_train)\n",
    "    X_val   = c_vect.transform(text_val)\n",
    "\n",
    "    y_train = train['classe'] \n",
    "    y_val   = val['classe']\n",
    "\n",
    "    # Treinar Logistic Regression\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    # Métrica: F1 macro\n",
    "    score = f1_score(y_val, preds, average='macro')\n",
    "    return score \n",
    "\n",
    "def count_vec(train, val, test):\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective_count_vec(trial, train,val),\n",
    "                   n_trials=30, n_jobs=-1, show_progress_bar=False)\n",
    "    \n",
    "    best_params=study.best_params\n",
    "    print(\"Melhores parâmetros:\", study.best_params)\n",
    "    print(\"Melhor F1:\", study.best_value)\n",
    "    \n",
    "    c_vect = CountVectorizer(\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b|[^\\w\\s]\",\n",
    "        ngram_range=(best_params['ngram_min'], best_params['ngram_max']),\n",
    "        strip_accents='unicode',\n",
    "        max_features=best_params['max_features']\n",
    "    )\n",
    "\n",
    "    # Transformar textos\n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_test = test['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    # Fit no treino, transform nos outros conjuntos\n",
    "    X_train = c_vect.fit_transform(text_train)\n",
    "    X_val = c_vect.transform(text_val)\n",
    "    X_test = c_vect.transform(text_test)\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "666f038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:50:33,433] A new study created in memory with name: no-name-b18ffb05-35c7-4e35-af0f-faef80f57f35\n",
      "[I 2025-11-13 01:50:36,397] Trial 2 finished with value: 0.5237603313834623 and parameters: {'max_features': 521, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 2 with value: 0.5237603313834623.\n",
      "[I 2025-11-13 01:50:36,545] Trial 5 finished with value: 0.517647901007312 and parameters: {'max_features': 629, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 2 with value: 0.5237603313834623.\n",
      "[I 2025-11-13 01:50:36,751] Trial 0 finished with value: 0.541307907512978 and parameters: {'max_features': 1767, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 0 with value: 0.541307907512978.\n",
      "[I 2025-11-13 01:50:37,323] Trial 4 finished with value: 0.5578194611967199 and parameters: {'max_features': 2725, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 4 with value: 0.5578194611967199.\n",
      "[I 2025-11-13 01:50:37,566] Trial 1 finished with value: 0.5656060755070657 and parameters: {'max_features': 4340, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 1 with value: 0.5656060755070657.\n",
      "[I 2025-11-13 01:50:38,025] Trial 3 finished with value: 0.5426764315129551 and parameters: {'max_features': 4828, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 1 with value: 0.5656060755070657.\n",
      "[I 2025-11-13 01:50:38,594] Trial 6 finished with value: 0.6657890117605758 and parameters: {'max_features': 2514, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 6 with value: 0.6657890117605758.\n",
      "[I 2025-11-13 01:50:38,987] Trial 7 finished with value: 0.6554777558532481 and parameters: {'max_features': 1905, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 6 with value: 0.6657890117605758.\n",
      "[I 2025-11-13 01:50:39,911] Trial 15 finished with value: 0.5209560724383627 and parameters: {'max_features': 930, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 6 with value: 0.6657890117605758.\n",
      "[I 2025-11-13 01:50:39,919] Trial 9 finished with value: 0.630287966966628 and parameters: {'max_features': 756, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 6 with value: 0.6657890117605758.\n",
      "[I 2025-11-13 01:50:40,356] Trial 12 finished with value: 0.5582450660391142 and parameters: {'max_features': 4478, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 6 with value: 0.6657890117605758.\n",
      "[I 2025-11-13 01:50:40,854] Trial 13 finished with value: 0.6678685625480073 and parameters: {'max_features': 2057, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 13 with value: 0.6678685625480073.\n",
      "[I 2025-11-13 01:50:41,171] Trial 10 finished with value: 0.6646756418573709 and parameters: {'max_features': 4127, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 13 with value: 0.6678685625480073.\n",
      "[I 2025-11-13 01:50:41,357] Trial 14 finished with value: 0.6691221751971884 and parameters: {'max_features': 1730, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 14 with value: 0.6691221751971884.\n",
      "[I 2025-11-13 01:50:41,573] Trial 8 finished with value: 0.6473652127411714 and parameters: {'max_features': 4217, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 14 with value: 0.6691221751971884.\n",
      "[I 2025-11-13 01:50:41,860] Trial 11 finished with value: 0.6521114618509072 and parameters: {'max_features': 3687, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 14 with value: 0.6691221751971884.\n",
      "[I 2025-11-13 01:50:42,923] Trial 18 finished with value: 0.6622021679172502 and parameters: {'max_features': 2621, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 14 with value: 0.6691221751971884.\n",
      "[I 2025-11-13 01:50:43,698] Trial 16 finished with value: 0.6436305881055681 and parameters: {'max_features': 3599, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 14 with value: 0.6691221751971884.\n",
      "[I 2025-11-13 01:50:44,437] Trial 17 finished with value: 0.6460330437521146 and parameters: {'max_features': 3589, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 14 with value: 0.6691221751971884.\n",
      "[I 2025-11-13 01:50:44,800] Trial 19 finished with value: 0.6489091425931848 and parameters: {'max_features': 3307, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 14 with value: 0.6691221751971884.\n",
      "[I 2025-11-13 01:50:45,454] Trial 23 finished with value: 0.6697064751341765 and parameters: {'max_features': 1579, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:45,948] Trial 20 finished with value: 0.6428167620662851 and parameters: {'max_features': 3076, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:46,410] Trial 22 finished with value: 0.6500035227728745 and parameters: {'max_features': 3292, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:46,473] Trial 21 finished with value: 0.6479254933394404 and parameters: {'max_features': 3385, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:46,564] Trial 24 finished with value: 0.6606250827541241 and parameters: {'max_features': 1502, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:46,665] Trial 25 finished with value: 0.6681923419754837 and parameters: {'max_features': 1613, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:46,745] Trial 27 finished with value: 0.6527589815767155 and parameters: {'max_features': 1462, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:46,777] Trial 28 finished with value: 0.6527589815767155 and parameters: {'max_features': 1481, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:46,793] Trial 26 finished with value: 0.6483232047403769 and parameters: {'max_features': 1331, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 23 with value: 0.6697064751341765.\n",
      "[I 2025-11-13 01:50:46,808] Trial 29 finished with value: 0.6509353403905129 and parameters: {'max_features': 1453, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 23 with value: 0.6697064751341765.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'max_features': 1579, 'ngram_min': 1, 'ngram_max': 3}\n",
      "Melhor F1: 0.6697064751341765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:50:47,277] A new study created in memory with name: no-name-d8329e17-a60a-4e5e-8ccd-0273ce8e6440\n",
      "[I 2025-11-13 01:50:51,536] Trial 6 finished with value: 0.5601691366705105 and parameters: {'max_features': 915, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 6 with value: 0.5601691366705105.\n",
      "[I 2025-11-13 01:50:51,736] Trial 5 finished with value: 0.5526658953479552 and parameters: {'max_features': 2041, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 6 with value: 0.5601691366705105.\n",
      "[I 2025-11-13 01:50:52,080] Trial 4 finished with value: 0.5434527227464546 and parameters: {'max_features': 2218, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 6 with value: 0.5601691366705105.\n",
      "[I 2025-11-13 01:50:52,874] Trial 3 finished with value: 0.5095761863308149 and parameters: {'max_features': 4231, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 6 with value: 0.5601691366705105.\n",
      "[I 2025-11-13 01:50:53,333] Trial 1 finished with value: 0.5343507359623395 and parameters: {'max_features': 4006, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 6 with value: 0.5601691366705105.\n",
      "[I 2025-11-13 01:50:53,770] Trial 7 finished with value: 0.6466162790428006 and parameters: {'max_features': 657, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 7 with value: 0.6466162790428006.\n",
      "[I 2025-11-13 01:50:54,441] Trial 2 finished with value: 0.6330692981090241 and parameters: {'max_features': 547, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 7 with value: 0.6466162790428006.\n",
      "[I 2025-11-13 01:50:55,192] Trial 0 finished with value: 0.6608016165809855 and parameters: {'max_features': 4745, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 0 with value: 0.6608016165809855.\n",
      "[I 2025-11-13 01:50:55,485] Trial 9 finished with value: 0.5399982161774993 and parameters: {'max_features': 3258, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 0 with value: 0.6608016165809855.\n",
      "[I 2025-11-13 01:50:56,399] Trial 14 finished with value: 0.5395527764296528 and parameters: {'max_features': 2661, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 0 with value: 0.6608016165809855.\n",
      "[I 2025-11-13 01:50:56,667] Trial 8 finished with value: 0.6833664851835662 and parameters: {'max_features': 3298, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 8 with value: 0.6833664851835662.\n",
      "[I 2025-11-13 01:50:56,939] Trial 10 finished with value: 0.6696453673719396 and parameters: {'max_features': 4066, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 8 with value: 0.6833664851835662.\n",
      "[I 2025-11-13 01:50:57,356] Trial 15 finished with value: 0.5438461599192105 and parameters: {'max_features': 2236, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 8 with value: 0.6833664851835662.\n",
      "[I 2025-11-13 01:50:57,808] Trial 11 finished with value: 0.6557709041852643 and parameters: {'max_features': 4388, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 8 with value: 0.6833664851835662.\n",
      "[I 2025-11-13 01:50:58,017] Trial 16 finished with value: 0.5102963174825504 and parameters: {'max_features': 3654, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 8 with value: 0.6833664851835662.\n",
      "[I 2025-11-13 01:50:58,322] Trial 13 finished with value: 0.6546822833869178 and parameters: {'max_features': 2758, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 8 with value: 0.6833664851835662.\n",
      "[I 2025-11-13 01:50:58,633] Trial 12 finished with value: 0.6952896987736915 and parameters: {'max_features': 4713, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:00,473] Trial 19 finished with value: 0.6921653035688579 and parameters: {'max_features': 3474, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:01,209] Trial 20 finished with value: 0.6932399038941085 and parameters: {'max_features': 3591, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:01,685] Trial 18 finished with value: 0.6875313193388884 and parameters: {'max_features': 4890, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:02,057] Trial 17 finished with value: 0.6875313193388884 and parameters: {'max_features': 4977, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:02,433] Trial 24 finished with value: 0.6833664851835662 and parameters: {'max_features': 3301, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:02,637] Trial 21 finished with value: 0.6927073589577925 and parameters: {'max_features': 3520, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:02,685] Trial 22 finished with value: 0.6770855519560963 and parameters: {'max_features': 3248, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:02,992] Trial 23 finished with value: 0.6875313193388884 and parameters: {'max_features': 4980, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:03,700] Trial 27 finished with value: 0.6645523702495898 and parameters: {'max_features': 1359, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:03,824] Trial 25 finished with value: 0.6833484240946929 and parameters: {'max_features': 4938, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:03,938] Trial 26 finished with value: 0.6833484240946929 and parameters: {'max_features': 4909, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:04,047] Trial 28 finished with value: 0.6931983056586509 and parameters: {'max_features': 3611, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n",
      "[I 2025-11-13 01:51:04,063] Trial 29 finished with value: 0.6881939998436003 and parameters: {'max_features': 3700, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6952896987736915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'max_features': 4713, 'ngram_min': 1, 'ngram_max': 1}\n",
      "Melhor F1: 0.6952896987736915\n"
     ]
    }
   ],
   "source": [
    "X_train_count_vec, X_val_count_vec, X_test_count_vec = count_vec(train, val, test)\n",
    "X_train_oversampling_count_vec, X_val_oversampling_count_vec, X_test_oversampling_count_vec= count_vec(train_oversampling, val_oversampling, test_oversampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a974ef",
   "metadata": {},
   "source": [
    "## Glove -fred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec3f116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective_tfidf(trial):\n",
    "    # Parâmetros a otimizar\n",
    "    max_features = trial.suggest_int(\"max_features\", 500, 5000)\n",
    "    ngram_min = trial.suggest_int(\"ngram_min\", 1, 2)\n",
    "    ngram_max = trial.suggest_int(\"ngram_max\", ngram_min, 3) \n",
    "    min_df = trial.suggest_int(\"min_df\", 1, 10)\n",
    "    max_df = trial.suggest_float(\"max_df\", 0.3, 0.9)\n",
    "\n",
    "    tfidf_vect = TfidfVectorizer(\n",
    "        ngram_range=(ngram_min, ngram_max),\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        max_features=max_features,\n",
    "        strip_accents='unicode',\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b|[^\\w\\s]\"\n",
    "    )\n",
    "\n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    X_train = tfidf_vect.fit_transform(text_train)\n",
    "    X_val = tfidf_vect.transform(text_val)\n",
    "\n",
    "    y_train = train['classe']\n",
    "    y_val = val['classe']\n",
    "\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    score = f1_score(y_val, preds, average='macro')\n",
    "    return score\n",
    "\n",
    "def tfidf_optuna(train, val, test):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_tfidf, n_trials=30)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(\"Melhores parâmetros:\", best_params)\n",
    "\n",
    "    tfidf_vect = TfidfVectorizer(\n",
    "        ngram_range=(best_params['ngram_min'], best_params['ngram_max']),\n",
    "        min_df=best_params['min_df'],\n",
    "        max_df=best_params['max_df'],\n",
    "        max_features=best_params['max_features'],\n",
    "        strip_accents='unicode',\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b|[^\\w\\s]\"\n",
    "    )\n",
    "\n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_test = test['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    X_train = tfidf_vect.fit_transform(text_train)\n",
    "    X_val = tfidf_vect.transform(text_val)\n",
    "    X_test = tfidf_vect.transform(text_test)\n",
    "\n",
    "    return X_train, X_val, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd78bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:51:04,395] A new study created in memory with name: no-name-af6b8f7a-12fb-4d01-bef2-c9aae47b2817\n",
      "[I 2025-11-13 01:51:04,545] Trial 0 finished with value: 0.545130935729811 and parameters: {'max_features': 4373, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 4, 'max_df': 0.7646089010758795}. Best is trial 0 with value: 0.545130935729811.\n",
      "[I 2025-11-13 01:51:04,978] Trial 1 finished with value: 0.5400271529310162 and parameters: {'max_features': 1218, 'ngram_min': 1, 'ngram_max': 3, 'min_df': 7, 'max_df': 0.4481121131545343}. Best is trial 0 with value: 0.545130935729811.\n",
      "[I 2025-11-13 01:51:05,361] Trial 2 finished with value: 0.5361755059172814 and parameters: {'max_features': 1134, 'ngram_min': 1, 'ngram_max': 3, 'min_df': 8, 'max_df': 0.5670504407632962}. Best is trial 0 with value: 0.545130935729811.\n",
      "[I 2025-11-13 01:51:05,899] Trial 3 finished with value: 0.5475782148528766 and parameters: {'max_features': 3138, 'ngram_min': 1, 'ngram_max': 3, 'min_df': 8, 'max_df': 0.8191112747057494}. Best is trial 3 with value: 0.5475782148528766.\n",
      "[I 2025-11-13 01:51:06,649] Trial 4 finished with value: 0.5666016756770843 and parameters: {'max_features': 4672, 'ngram_min': 1, 'ngram_max': 3, 'min_df': 7, 'max_df': 0.3490525936306972}. Best is trial 4 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:07,928] Trial 5 finished with value: 0.5202817559647094 and parameters: {'max_features': 2381, 'ngram_min': 2, 'ngram_max': 3, 'min_df': 5, 'max_df': 0.8648476656572208}. Best is trial 4 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:08,867] Trial 6 finished with value: 0.5709164893486928 and parameters: {'max_features': 676, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 9, 'max_df': 0.5954948579929478}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:09,997] Trial 7 finished with value: 0.5004981787138475 and parameters: {'max_features': 4654, 'ngram_min': 2, 'ngram_max': 2, 'min_df': 7, 'max_df': 0.7552776076287346}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:10,817] Trial 8 finished with value: 0.501440718360318 and parameters: {'max_features': 4500, 'ngram_min': 2, 'ngram_max': 2, 'min_df': 8, 'max_df': 0.8732830024228839}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:11,494] Trial 9 finished with value: 0.5431771346943787 and parameters: {'max_features': 4293, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 1, 'max_df': 0.6653167601036893}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:12,110] Trial 10 finished with value: 0.4984594427301574 and parameters: {'max_features': 2289, 'ngram_min': 2, 'ngram_max': 2, 'min_df': 10, 'max_df': 0.5562749908792138}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:12,497] Trial 11 finished with value: 0.5640966121495227 and parameters: {'max_features': 503, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 10, 'max_df': 0.3089516409983674}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:13,590] Trial 12 finished with value: 0.525755171208005 and parameters: {'max_features': 3435, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 3, 'max_df': 0.3396988346722088}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:14,000] Trial 13 finished with value: 0.556202806050757 and parameters: {'max_features': 3573, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 6, 'max_df': 0.44925612810524623}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:14,559] Trial 14 finished with value: 0.5287096446566014 and parameters: {'max_features': 1830, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 9, 'max_df': 0.4428175396329188}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:14,863] Trial 15 finished with value: 0.556202806050757 and parameters: {'max_features': 2815, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 6, 'max_df': 0.6447520314072732}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:15,610] Trial 16 finished with value: 0.533581798457691 and parameters: {'max_features': 4980, 'ngram_min': 1, 'ngram_max': 3, 'min_df': 9, 'max_df': 0.5054428588799172}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:16,304] Trial 17 finished with value: 0.5202817559647094 and parameters: {'max_features': 3742, 'ngram_min': 2, 'ngram_max': 3, 'min_df': 5, 'max_df': 0.39577358664135287}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:16,806] Trial 18 finished with value: 0.5556755401568251 and parameters: {'max_features': 597, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 7, 'max_df': 0.7044940148415924}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:17,229] Trial 19 finished with value: 0.5287096446566014 and parameters: {'max_features': 1710, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 9, 'max_df': 0.5184905499103335}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:17,853] Trial 20 finished with value: 0.5280762808010503 and parameters: {'max_features': 2536, 'ngram_min': 2, 'ngram_max': 3, 'min_df': 3, 'max_df': 0.6308481983446973}. Best is trial 6 with value: 0.5709164893486928.\n",
      "[I 2025-11-13 01:51:18,093] Trial 21 finished with value: 0.5736877423826399 and parameters: {'max_features': 561, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 10, 'max_df': 0.31737701013310565}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:18,309] Trial 22 finished with value: 0.5610772996433946 and parameters: {'max_features': 1053, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 10, 'max_df': 0.3826407226106522}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:18,502] Trial 23 finished with value: 0.5509436639704839 and parameters: {'max_features': 1635, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 9, 'max_df': 0.3707286969385279}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:18,740] Trial 24 finished with value: 0.5488494219380547 and parameters: {'max_features': 854, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 8, 'max_df': 0.30323262890568337}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:18,989] Trial 25 finished with value: 0.5610772996433946 and parameters: {'max_features': 1487, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 10, 'max_df': 0.4194039947115744}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:19,269] Trial 26 finished with value: 0.559771812528956 and parameters: {'max_features': 2014, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 7, 'max_df': 0.49469161324048305}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:19,872] Trial 27 finished with value: 0.5287096446566014 and parameters: {'max_features': 3946, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 9, 'max_df': 0.33852953537261676}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:20,335] Trial 28 finished with value: 0.5581239891756647 and parameters: {'max_features': 719, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 8, 'max_df': 0.5906236579460244}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:20,560] Trial 29 finished with value: 0.5518116020560901 and parameters: {'max_features': 2935, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 6, 'max_df': 0.7252875124053144}. Best is trial 21 with value: 0.5736877423826399.\n",
      "[I 2025-11-13 01:51:20,726] A new study created in memory with name: no-name-c8d94f3b-fcc0-4c88-9e30-f2b487e22c04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'max_features': 561, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 10, 'max_df': 0.31737701013310565}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:51:21,135] Trial 0 finished with value: 0.5666016756770843 and parameters: {'max_features': 3384, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 7, 'max_df': 0.365130965123919}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:21,556] Trial 1 finished with value: 0.5287096446566014 and parameters: {'max_features': 3021, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 9, 'max_df': 0.3787835310609651}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:22,210] Trial 2 finished with value: 0.5426471454750078 and parameters: {'max_features': 2924, 'ngram_min': 1, 'ngram_max': 3, 'min_df': 5, 'max_df': 0.3346213445383555}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:23,024] Trial 3 finished with value: 0.5301951247756355 and parameters: {'max_features': 4343, 'ngram_min': 1, 'ngram_max': 3, 'min_df': 1, 'max_df': 0.4737387223967725}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:23,586] Trial 4 finished with value: 0.506190585699731 and parameters: {'max_features': 1093, 'ngram_min': 2, 'ngram_max': 3, 'min_df': 1, 'max_df': 0.8352222010146122}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:23,829] Trial 5 finished with value: 0.5465943095956834 and parameters: {'max_features': 3113, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 4, 'max_df': 0.4814017336966854}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:24,340] Trial 6 finished with value: 0.4991619421883335 and parameters: {'max_features': 1914, 'ngram_min': 2, 'ngram_max': 3, 'min_df': 8, 'max_df': 0.7216555703131662}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:24,806] Trial 7 finished with value: 0.5412072695288356 and parameters: {'max_features': 3557, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 6, 'max_df': 0.5213829762611161}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:25,374] Trial 8 finished with value: 0.5287096446566014 and parameters: {'max_features': 3144, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 9, 'max_df': 0.3579483269200604}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:26,152] Trial 9 finished with value: 0.5169013281650802 and parameters: {'max_features': 1965, 'ngram_min': 2, 'ngram_max': 3, 'min_df': 2, 'max_df': 0.7491897384179627}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:26,634] Trial 10 finished with value: 0.5004981787138475 and parameters: {'max_features': 4847, 'ngram_min': 2, 'ngram_max': 2, 'min_df': 7, 'max_df': 0.6100111702863368}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:26,969] Trial 11 finished with value: 0.5465943095956834 and parameters: {'max_features': 3984, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 4, 'max_df': 0.44941530466797647}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:27,223] Trial 12 finished with value: 0.5465943095956834 and parameters: {'max_features': 2243, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 4, 'max_df': 0.5716460628697791}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:27,417] Trial 13 finished with value: 0.5425931304383541 and parameters: {'max_features': 3698, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 3, 'max_df': 0.43724182795565586}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:27,576] Trial 14 finished with value: 0.5594155656746911 and parameters: {'max_features': 501, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 6, 'max_df': 0.6167297988904992}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:27,738] Trial 15 finished with value: 0.5516301225460537 and parameters: {'max_features': 502, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 7, 'max_df': 0.6461507165339111}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:28,049] Trial 16 finished with value: 0.5363911884279721 and parameters: {'max_features': 1436, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 10, 'max_df': 0.698254112259048}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:28,277] Trial 17 finished with value: 0.4984594427301574 and parameters: {'max_features': 515, 'ngram_min': 2, 'ngram_max': 2, 'min_df': 6, 'max_df': 0.8150832283225808}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:28,448] Trial 18 finished with value: 0.555689332553198 and parameters: {'max_features': 1156, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 7, 'max_df': 0.30236316919561196}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:28,626] Trial 19 finished with value: 0.5552208260497259 and parameters: {'max_features': 2344, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 8, 'max_df': 0.5656143642674633}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:29,101] Trial 20 finished with value: 0.5202817559647094 and parameters: {'max_features': 4897, 'ngram_min': 2, 'ngram_max': 3, 'min_df': 5, 'max_df': 0.652268389502229}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:29,284] Trial 21 finished with value: 0.5547459280853412 and parameters: {'max_features': 1259, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 7, 'max_df': 0.3041333480031021}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:29,465] Trial 22 finished with value: 0.5547459280853412 and parameters: {'max_features': 887, 'ngram_min': 1, 'ngram_max': 1, 'min_df': 6, 'max_df': 0.41613775656024987}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:29,763] Trial 23 finished with value: 0.5615232622603358 and parameters: {'max_features': 816, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 8, 'max_df': 0.3882084110153094}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:30,058] Trial 24 finished with value: 0.5382447972601425 and parameters: {'max_features': 1683, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 8, 'max_df': 0.5215772053064365}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:30,347] Trial 25 finished with value: 0.5378541729248639 and parameters: {'max_features': 2522, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 10, 'max_df': 0.390214398403379}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:30,633] Trial 26 finished with value: 0.5566478276376313 and parameters: {'max_features': 615, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 9, 'max_df': 0.5170987124708744}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:30,901] Trial 27 finished with value: 0.5605330515148771 and parameters: {'max_features': 838, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 8, 'max_df': 0.4039681222012067}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:31,158] Trial 28 finished with value: 0.5411504189000776 and parameters: {'max_features': 1628, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 8, 'max_df': 0.3947297578094456}. Best is trial 0 with value: 0.5666016756770843.\n",
      "[I 2025-11-13 01:51:31,418] Trial 29 finished with value: 0.5533702284660139 and parameters: {'max_features': 870, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 9, 'max_df': 0.3546711930980435}. Best is trial 0 with value: 0.5666016756770843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'max_features': 3384, 'ngram_min': 1, 'ngram_max': 2, 'min_df': 7, 'max_df': 0.365130965123919}\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf_vec, X_val_tfidf_vec, X_test_tfidf_vec = tfidf_optuna(train,val, test)\n",
    "X_train_oversampling_tfidf_vec, X_val_oversampling_tfidf_vec, X_test_oversampling_tfidf_vec = tfidf_optuna(train_oversampling, val_oversampling, test_oversampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72beca9e",
   "metadata": {},
   "source": [
    "## WORD2VEC -anaana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d7c7d",
   "metadata": {},
   "source": [
    "fontes : \n",
    "-   https://sites.google.com/view/nilc-usp/resources-and-tools?authuser=0\n",
    "-   https://huggingface.co/nilc-nlp/word2vec-skip-gram-300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bade9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install huggingface_hub\n",
    "#%pip install hf_hub_download\n",
    "#%pip install safetensors\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.numpy import load_file\n",
    "\n",
    "def carregar_word2vec():\n",
    "    path = hf_hub_download(repo_id=\"nilc-nlp/word2vec-skip-gram-300d\",\n",
    "                           filename=\"embeddings.safetensors\")\n",
    "\n",
    "    data = load_file(path)\n",
    "    vectors = data[\"embeddings\"]\n",
    "\n",
    "    vocab_path = hf_hub_download(repo_id=\"nilc-nlp/word2vec-skip-gram-300d\",\n",
    "                                 filename=\"vocab.txt\")\n",
    "    with open(vocab_path) as f:\n",
    "        vocab = [w.strip() for w in f]\n",
    "\n",
    "    print(vectors.shape)\n",
    "\n",
    "    model = KeyedVectors(vector_size=vectors.shape[1])\n",
    "    model.add_vectors(vocab, vectors)\n",
    "    model.fill_norms()\n",
    "\n",
    "    return model\n",
    "\n",
    "def vetor_frase(model, frase):\n",
    "    vectors = [model[w] for w in frase if w in model]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "def word2vec(train, val, test, coluna, model):\n",
    "    X_train = np.vstack([vetor_frase(model, tokens) for tokens in train[coluna]])\n",
    "    X_val   = np.vstack([vetor_frase(model, tokens) for tokens in val[coluna]])\n",
    "    X_test  = np.vstack([vetor_frase(model, tokens) for tokens in test[coluna]])\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07c9e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929606, 300)\n"
     ]
    }
   ],
   "source": [
    "model = carregar_word2vec()\n",
    "X_train_word2vec, X_val_word2vec, X_test_word2vec = word2vec(train, val, test, 'stems', model)\n",
    "X_train_oversampling_word2vec, X_val_oversampling_word2vec, X_test_oversampling_word2vec = word2vec(train_oversampling, val_oversampling, test_oversampling, 'stems', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e250c",
   "metadata": {},
   "source": [
    "## WORD2VEC treinado com os nossos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b6e3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#vetor médio da frase\n",
    "def vetor_frase_w2v(tokens, model):\n",
    "    vecs = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(model.vector_size)\n",
    "\n",
    "# matriz dos embeddings\n",
    "def prep_dados_w2v(dados, coluna, model):\n",
    "    return np.vstack([vetor_frase_w2v(tokens, model) for tokens in dados[coluna]])\n",
    "\n",
    "def objective_w2v(trial, train, val):\n",
    "    # Hiperparâmetros \n",
    "    vector_size = trial.suggest_int(\"vector_size\", 50, 300)\n",
    "    window = trial.suggest_int(\"window\", 3, 10)\n",
    "    min_count = trial.suggest_int(\"min_count\", 1, 5)\n",
    "    sg = trial.suggest_categorical(\"sg\", [0, 1])  # 0 = CBOW, 1 = Skip-gram\n",
    "    epochs = trial.suggest_int(\"epochs\", 5, 20)\n",
    "    C = trial.suggest_float(\"C\", 1e-3, 10, log=True)\n",
    "    use_scaler = trial.suggest_categorical(\"use_scaler\", [True, False])\n",
    "\n",
    "    # Treina Word2Vec com os parâmetros sugeridos\n",
    "    sentences = train[\"tokens\"]\n",
    "    model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        sg=sg,\n",
    "        workers=4,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    # Transformar dados nos embeddings médios\n",
    "    X_train = prep_dados_w2v(train, \"tokens\", model)\n",
    "    X_val = prep_dados_w2v(val, \"tokens\", model)\n",
    "    y_train = train[\"classe\"].values\n",
    "    y_val = val[\"classe\"].values\n",
    "\n",
    "    if use_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "    # Modelo de classificação (Logistic Regression)\n",
    "    clf = LogisticRegression(C=C, max_iter=500)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_val)\n",
    "\n",
    "    return f1_score(y_val, preds, average=\"macro\")\n",
    "\n",
    "def word2vec_vec(train, val, test):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective_w2v(trial, train, val),\n",
    "                   n_trials=30, n_jobs=-1, show_progress_bar=False)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(\"Melhores parâmetros:\", best_params)\n",
    "    print(\"Melhor F1:\", study.best_value)\n",
    "\n",
    "    best_model = Word2Vec(\n",
    "        sentences=train[\"tokens\"],\n",
    "        vector_size=best_params[\"vector_size\"],\n",
    "        window=best_params[\"window\"],\n",
    "        min_count=best_params[\"min_count\"],\n",
    "        sg=best_params[\"sg\"],\n",
    "        workers=4,\n",
    "        epochs=best_params[\"epochs\"]\n",
    "    )\n",
    "\n",
    "    # Criar embeddings médios para todos os conjuntos\n",
    "    X_train = prep_dados_w2v(train, \"tokens\", best_model)\n",
    "    X_val = prep_dados_w2v(val, \"tokens\", best_model)\n",
    "    X_test = prep_dados_w2v(test, \"tokens\", best_model)\n",
    "\n",
    "    if best_params[\"use_scaler\"]:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_val, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83eab317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:51:36,961] A new study created in memory with name: no-name-0f5c8fe1-72b8-4008-8929-1f071be82d0f\n",
      "[I 2025-11-13 01:51:42,151] Trial 0 finished with value: 0.271047227926078 and parameters: {'vector_size': 117, 'window': 5, 'min_count': 3, 'sg': 1, 'epochs': 6, 'C': 0.007853554557048038, 'use_scaler': False}. Best is trial 0 with value: 0.271047227926078.\n",
      "[I 2025-11-13 01:51:43,446] Trial 1 finished with value: 0.271047227926078 and parameters: {'vector_size': 203, 'window': 10, 'min_count': 3, 'sg': 1, 'epochs': 6, 'C': 0.006528666191206588, 'use_scaler': False}. Best is trial 0 with value: 0.271047227926078.\n",
      "[I 2025-11-13 01:51:46,921] Trial 3 finished with value: 0.4753718663084852 and parameters: {'vector_size': 158, 'window': 8, 'min_count': 3, 'sg': 1, 'epochs': 9, 'C': 0.1266292466348613, 'use_scaler': False}. Best is trial 3 with value: 0.4753718663084852.\n",
      "[I 2025-11-13 01:51:47,882] Trial 6 finished with value: 0.27463423725654645 and parameters: {'vector_size': 82, 'window': 3, 'min_count': 4, 'sg': 1, 'epochs': 17, 'C': 0.003738408155097925, 'use_scaler': False}. Best is trial 3 with value: 0.4753718663084852.\n",
      "[I 2025-11-13 01:51:48,777] Trial 2 finished with value: 0.4969186873948779 and parameters: {'vector_size': 139, 'window': 7, 'min_count': 5, 'sg': 0, 'epochs': 19, 'C': 0.0024326758236150963, 'use_scaler': True}. Best is trial 2 with value: 0.4969186873948779.\n",
      "[I 2025-11-13 01:51:49,813] Trial 4 finished with value: 0.49779266296133345 and parameters: {'vector_size': 298, 'window': 7, 'min_count': 4, 'sg': 1, 'epochs': 16, 'C': 0.3227941193454854, 'use_scaler': False}. Best is trial 4 with value: 0.49779266296133345.\n",
      "[I 2025-11-13 01:51:50,994] Trial 8 finished with value: 0.271047227926078 and parameters: {'vector_size': 249, 'window': 6, 'min_count': 5, 'sg': 1, 'epochs': 16, 'C': 0.0018356154877831518, 'use_scaler': False}. Best is trial 4 with value: 0.49779266296133345.\n",
      "[I 2025-11-13 01:51:52,073] Trial 10 finished with value: 0.5028132290380128 and parameters: {'vector_size': 52, 'window': 8, 'min_count': 3, 'sg': 0, 'epochs': 14, 'C': 0.05166463032014074, 'use_scaler': True}. Best is trial 10 with value: 0.5028132290380128.\n",
      "[I 2025-11-13 01:51:53,223] Trial 7 finished with value: 0.48852489417630024 and parameters: {'vector_size': 121, 'window': 6, 'min_count': 1, 'sg': 0, 'epochs': 13, 'C': 3.263002309963581, 'use_scaler': False}. Best is trial 10 with value: 0.5028132290380128.\n",
      "[I 2025-11-13 01:51:55,311] Trial 11 finished with value: 0.47978499363306887 and parameters: {'vector_size': 259, 'window': 6, 'min_count': 4, 'sg': 0, 'epochs': 12, 'C': 0.002352617244559737, 'use_scaler': True}. Best is trial 10 with value: 0.5028132290380128.\n",
      "[I 2025-11-13 01:51:57,002] Trial 15 finished with value: 0.271047227926078 and parameters: {'vector_size': 69, 'window': 7, 'min_count': 5, 'sg': 1, 'epochs': 17, 'C': 0.001797608114089989, 'use_scaler': False}. Best is trial 10 with value: 0.5028132290380128.\n",
      "[I 2025-11-13 01:51:58,271] Trial 5 finished with value: 0.5228003457216941 and parameters: {'vector_size': 259, 'window': 5, 'min_count': 2, 'sg': 1, 'epochs': 18, 'C': 4.661810620361233, 'use_scaler': False}. Best is trial 5 with value: 0.5228003457216941.\n",
      "[I 2025-11-13 01:51:58,969] Trial 13 finished with value: 0.49905636986800844 and parameters: {'vector_size': 200, 'window': 7, 'min_count': 1, 'sg': 0, 'epochs': 18, 'C': 0.005610103796434279, 'use_scaler': True}. Best is trial 5 with value: 0.5228003457216941.\n",
      "[I 2025-11-13 01:51:59,285] Trial 14 finished with value: 0.4321845817736156 and parameters: {'vector_size': 236, 'window': 9, 'min_count': 3, 'sg': 1, 'epochs': 19, 'C': 0.01275929595482405, 'use_scaler': False}. Best is trial 5 with value: 0.5228003457216941.\n",
      "[I 2025-11-13 01:51:59,917] Trial 16 finished with value: 0.4642697557462802 and parameters: {'vector_size': 211, 'window': 4, 'min_count': 5, 'sg': 0, 'epochs': 12, 'C': 0.0013467109694154044, 'use_scaler': True}. Best is trial 5 with value: 0.5228003457216941.\n",
      "[I 2025-11-13 01:52:00,252] Trial 17 finished with value: 0.4997691823256711 and parameters: {'vector_size': 58, 'window': 10, 'min_count': 1, 'sg': 0, 'epochs': 12, 'C': 0.024939076621454444, 'use_scaler': True}. Best is trial 5 with value: 0.5228003457216941.\n",
      "[I 2025-11-13 01:52:04,765] Trial 12 finished with value: 0.499347090352392 and parameters: {'vector_size': 278, 'window': 5, 'min_count': 5, 'sg': 1, 'epochs': 12, 'C': 0.05483782731525006, 'use_scaler': True}. Best is trial 5 with value: 0.5228003457216941.\n",
      "[I 2025-11-13 01:52:06,011] Trial 20 finished with value: 0.5076009275028653 and parameters: {'vector_size': 50, 'window': 4, 'min_count': 2, 'sg': 0, 'epochs': 13, 'C': 9.623627249283476, 'use_scaler': True}. Best is trial 5 with value: 0.5228003457216941.\n",
      "[I 2025-11-13 01:52:09,335] Trial 18 finished with value: 0.508301404853129 and parameters: {'vector_size': 299, 'window': 9, 'min_count': 2, 'sg': 0, 'epochs': 13, 'C': 0.11221883163638903, 'use_scaler': True}. Best is trial 5 with value: 0.5228003457216941.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:52:13,520] Trial 9 finished with value: 0.4954680706088815 and parameters: {'vector_size': 255, 'window': 8, 'min_count': 1, 'sg': 0, 'epochs': 5, 'C': 7.7455603729403295, 'use_scaler': True}. Best is trial 5 with value: 0.5228003457216941.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:52:16,790] Trial 19 finished with value: 0.5408646964721732 and parameters: {'vector_size': 201, 'window': 4, 'min_count': 1, 'sg': 0, 'epochs': 20, 'C': 8.32641537265998, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:52:16,832] Trial 21 finished with value: 0.5089943241593392 and parameters: {'vector_size': 291, 'window': 4, 'min_count': 2, 'sg': 0, 'epochs': 13, 'C': 9.400325576827953, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:52:17,376] Trial 22 finished with value: 0.5230668372142032 and parameters: {'vector_size': 287, 'window': 4, 'min_count': 2, 'sg': 0, 'epochs': 14, 'C': 9.03009917471275, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:52:17,720] Trial 23 finished with value: 0.5302571170266988 and parameters: {'vector_size': 290, 'window': 4, 'min_count': 2, 'sg': 0, 'epochs': 14, 'C': 4.096653354348818, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:52:19,173] Trial 24 finished with value: 0.530177743431221 and parameters: {'vector_size': 170, 'window': 8, 'min_count': 2, 'sg': 0, 'epochs': 14, 'C': 5.931906121449182, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:52:20,667] Trial 25 finished with value: 0.5121599961698556 and parameters: {'vector_size': 176, 'window': 3, 'min_count': 2, 'sg': 0, 'epochs': 9, 'C': 9.396274150298009, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "[I 2025-11-13 01:52:21,597] Trial 26 finished with value: 0.5038138423143169 and parameters: {'vector_size': 291, 'window': 9, 'min_count': 2, 'sg': 0, 'epochs': 10, 'C': 0.6811279721313349, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:52:25,383] Trial 27 finished with value: 0.5007506921120918 and parameters: {'vector_size': 293, 'window': 9, 'min_count': 2, 'sg': 0, 'epochs': 9, 'C': 1.3449874688394203, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "[I 2025-11-13 01:52:26,197] Trial 28 finished with value: 0.518586919241221 and parameters: {'vector_size': 289, 'window': 3, 'min_count': 2, 'sg': 0, 'epochs': 20, 'C': 1.1947719090399105, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n",
      "[I 2025-11-13 01:52:26,417] Trial 29 finished with value: 0.51557279132979 and parameters: {'vector_size': 226, 'window': 3, 'min_count': 2, 'sg': 0, 'epochs': 20, 'C': 1.7669923383232635, 'use_scaler': True}. Best is trial 19 with value: 0.5408646964721732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'vector_size': 201, 'window': 4, 'min_count': 1, 'sg': 0, 'epochs': 20, 'C': 8.32641537265998, 'use_scaler': True}\n",
      "Melhor F1: 0.5408646964721732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:52:28,445] A new study created in memory with name: no-name-c9c9034b-c711-4104-a43d-de4afb8ab373\n",
      "[I 2025-11-13 01:52:47,653] Trial 5 finished with value: 0.5836035839995114 and parameters: {'vector_size': 184, 'window': 9, 'min_count': 2, 'sg': 0, 'epochs': 10, 'C': 0.004466974781221183, 'use_scaler': False}. Best is trial 5 with value: 0.5836035839995114.\n",
      "[I 2025-11-13 01:52:47,668] Trial 6 finished with value: 0.5829833631119572 and parameters: {'vector_size': 98, 'window': 5, 'min_count': 1, 'sg': 1, 'epochs': 10, 'C': 0.1964791626801931, 'use_scaler': False}. Best is trial 5 with value: 0.5836035839995114.\n",
      "[I 2025-11-13 01:52:49,185] Trial 1 finished with value: 0.636032161671964 and parameters: {'vector_size': 129, 'window': 7, 'min_count': 3, 'sg': 0, 'epochs': 7, 'C': 0.00889598517719848, 'use_scaler': True}. Best is trial 1 with value: 0.636032161671964.\n",
      "[I 2025-11-13 01:53:01,933] Trial 3 finished with value: 0.6488409404595951 and parameters: {'vector_size': 261, 'window': 4, 'min_count': 4, 'sg': 1, 'epochs': 7, 'C': 0.03187982909342019, 'use_scaler': True}. Best is trial 3 with value: 0.6488409404595951.\n",
      "[I 2025-11-13 01:53:04,790] Trial 8 finished with value: 0.6145138365955338 and parameters: {'vector_size': 202, 'window': 5, 'min_count': 4, 'sg': 1, 'epochs': 20, 'C': 0.006235893012439806, 'use_scaler': False}. Best is trial 3 with value: 0.6488409404595951.\n",
      "[I 2025-11-13 01:53:05,207] Trial 9 finished with value: 0.6133909104434023 and parameters: {'vector_size': 119, 'window': 10, 'min_count': 3, 'sg': 1, 'epochs': 8, 'C': 0.37285726166448674, 'use_scaler': True}. Best is trial 3 with value: 0.6488409404595951.\n",
      "[I 2025-11-13 01:53:07,510] Trial 0 finished with value: 0.6094623566243793 and parameters: {'vector_size': 103, 'window': 3, 'min_count': 1, 'sg': 0, 'epochs': 14, 'C': 0.2889555906271951, 'use_scaler': True}. Best is trial 3 with value: 0.6488409404595951.\n",
      "[I 2025-11-13 01:53:11,394] Trial 4 finished with value: 0.6589625284404543 and parameters: {'vector_size': 225, 'window': 9, 'min_count': 4, 'sg': 0, 'epochs': 14, 'C': 0.04302140095196093, 'use_scaler': True}. Best is trial 4 with value: 0.6589625284404543.\n",
      "[I 2025-11-13 01:53:14,713] Trial 11 finished with value: 0.6582852948482705 and parameters: {'vector_size': 246, 'window': 10, 'min_count': 5, 'sg': 1, 'epochs': 5, 'C': 0.0044751212701990666, 'use_scaler': True}. Best is trial 4 with value: 0.6589625284404543.\n",
      "[I 2025-11-13 01:53:14,949] Trial 13 finished with value: 0.6634530247435025 and parameters: {'vector_size': 93, 'window': 8, 'min_count': 5, 'sg': 0, 'epochs': 19, 'C': 0.0028255668153162115, 'use_scaler': False}. Best is trial 13 with value: 0.6634530247435025.\n",
      "[I 2025-11-13 01:53:20,169] Trial 14 finished with value: 0.6368918072246034 and parameters: {'vector_size': 289, 'window': 5, 'min_count': 5, 'sg': 0, 'epochs': 15, 'C': 0.0045319911423662256, 'use_scaler': False}. Best is trial 13 with value: 0.6634530247435025.\n",
      "[I 2025-11-13 01:53:22,930] Trial 15 finished with value: 0.6244059175985269 and parameters: {'vector_size': 106, 'window': 4, 'min_count': 3, 'sg': 1, 'epochs': 16, 'C': 0.3166544338416608, 'use_scaler': False}. Best is trial 13 with value: 0.6634530247435025.\n",
      "[I 2025-11-13 01:53:24,927] Trial 12 finished with value: 0.6636590899077205 and parameters: {'vector_size': 207, 'window': 5, 'min_count': 5, 'sg': 0, 'epochs': 16, 'C': 0.586487135381389, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:26,238] Trial 2 finished with value: 0.5884776553983609 and parameters: {'vector_size': 247, 'window': 7, 'min_count': 1, 'sg': 1, 'epochs': 14, 'C': 3.4029023020142293, 'use_scaler': True}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:26,911] Trial 17 finished with value: 0.6009856071003284 and parameters: {'vector_size': 51, 'window': 7, 'min_count': 5, 'sg': 0, 'epochs': 20, 'C': 7.832900535739098, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:29,188] Trial 16 finished with value: 0.6184540009306138 and parameters: {'vector_size': 149, 'window': 4, 'min_count': 3, 'sg': 1, 'epochs': 12, 'C': 4.3886585899073305, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:40,370] Trial 18 finished with value: 0.6384377491808183 and parameters: {'vector_size': 60, 'window': 8, 'min_count': 4, 'sg': 0, 'epochs': 19, 'C': 4.278390794665921, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:41,028] Trial 10 finished with value: 0.584880480495451 and parameters: {'vector_size': 256, 'window': 7, 'min_count': 1, 'sg': 1, 'epochs': 19, 'C': 5.604245733814644, 'use_scaler': True}. Best is trial 12 with value: 0.6636590899077205.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-11-13 01:53:41,624] Trial 7 finished with value: 0.6371276579258055 and parameters: {'vector_size': 282, 'window': 10, 'min_count': 3, 'sg': 0, 'epochs': 12, 'C': 2.410119380500638, 'use_scaler': True}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:42,299] Trial 20 finished with value: 0.6348240699163904 and parameters: {'vector_size': 52, 'window': 7, 'min_count': 5, 'sg': 0, 'epochs': 19, 'C': 4.173472695477592, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:43,022] Trial 21 finished with value: 0.6374336885454251 and parameters: {'vector_size': 53, 'window': 8, 'min_count': 5, 'sg': 0, 'epochs': 19, 'C': 2.0127231184952543, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:44,614] Trial 23 finished with value: 0.6327608263669644 and parameters: {'vector_size': 61, 'window': 8, 'min_count': 5, 'sg': 0, 'epochs': 18, 'C': 1.4924239886659199, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:45,349] Trial 22 finished with value: 0.6472731518794771 and parameters: {'vector_size': 160, 'window': 8, 'min_count': 5, 'sg': 0, 'epochs': 18, 'C': 1.4606198635784367, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:49,647] Trial 24 finished with value: 0.6402275623459325 and parameters: {'vector_size': 160, 'window': 6, 'min_count': 5, 'sg': 0, 'epochs': 17, 'C': 0.0012171137322117141, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:53,245] Trial 25 finished with value: 0.6434733918188417 and parameters: {'vector_size': 154, 'window': 6, 'min_count': 5, 'sg': 0, 'epochs': 17, 'C': 0.0016913137628383416, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:53,398] Trial 26 finished with value: 0.652878195682231 and parameters: {'vector_size': 158, 'window': 6, 'min_count': 5, 'sg': 0, 'epochs': 17, 'C': 0.0016222509341895846, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:54,230] Trial 27 finished with value: 0.6529803690905932 and parameters: {'vector_size': 163, 'window': 6, 'min_count': 5, 'sg': 0, 'epochs': 17, 'C': 0.0016266221411560427, 'use_scaler': False}. Best is trial 12 with value: 0.6636590899077205.\n",
      "[I 2025-11-13 01:53:54,775] Trial 28 finished with value: 0.6656187485863588 and parameters: {'vector_size': 216, 'window': 9, 'min_count': 4, 'sg': 0, 'epochs': 17, 'C': 0.0012844517425825812, 'use_scaler': False}. Best is trial 28 with value: 0.6656187485863588.\n",
      "[I 2025-11-13 01:53:55,154] Trial 29 finished with value: 0.6279491993643437 and parameters: {'vector_size': 213, 'window': 9, 'min_count': 4, 'sg': 0, 'epochs': 17, 'C': 0.043502986467236084, 'use_scaler': False}. Best is trial 28 with value: 0.6656187485863588.\n",
      "[I 2025-11-13 01:53:55,565] Trial 19 finished with value: 0.6293550367051635 and parameters: {'vector_size': 217, 'window': 8, 'min_count': 4, 'sg': 0, 'epochs': 19, 'C': 5.589775748625508, 'use_scaler': False}. Best is trial 28 with value: 0.6656187485863588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'vector_size': 216, 'window': 9, 'min_count': 4, 'sg': 0, 'epochs': 17, 'C': 0.0012844517425825812, 'use_scaler': False}\n",
      "Melhor F1: 0.6656187485863588\n"
     ]
    }
   ],
   "source": [
    "X_train_w2v_trained, X_val_w2v_trained, X_test_w2v_trained = word2vec_vec(train, val, test)\n",
    "X_train_over_w2v_trained, X_val_over_w2v_trained, X_test_over_w2v_trained= word2vec_vec(train_oversampling, val_oversampling, test_oversampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955eb2ec",
   "metadata": {},
   "source": [
    "# Aplicar modelos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268c280",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc51ae",
   "metadata": {},
   "source": [
    "-   Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0229cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_naive_MN(trial, X_train, X_val, y_train, y_val):\n",
    "    # Hiperparâmetros a otimizar\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-3, 2.0, log=True)\n",
    "    \n",
    "    # Modelo\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_val_pred, average='weighted')  \n",
    "    \n",
    "    return f1\n",
    "\n",
    "def Naive_Bayes_MN(X_train, X_val, X_test, y_train, y_val, n_trials=30):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective_naive_MN(trial, X_train, X_val, y_train, y_val),\n",
    "                   n_trials=n_trials, n_jobs=-1, show_progress_bar=False)\n",
    "    \n",
    "    print(\"Melhores hiperparâmetros encontrados:\")\n",
    "    print(study.best_params)\n",
    "    print(f\"Melhor F1 (validação): {study.best_value:.4f}\")\n",
    "    \n",
    "    # Treinar o modelo final com o melhor alpha\n",
    "    best_model = MultinomialNB(**study.best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Previsão no conjunto de teste\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "222c6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective_naive_GS(trial, X_train, X_val, y_train, y_val):\n",
    "    # Definir o hiperparâmetro a otimizar\n",
    "    var_smoothing = trial.suggest_float(\"var_smoothing\", 1e-12, 1e-3, log=True)\n",
    "    # Criar o modelo\n",
    "    model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    # Treinar\n",
    "    model.fit(X_train, y_train)\n",
    "    # Avaliar no conjunto de validação\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
    "\n",
    "    return f1\n",
    "\n",
    "def naive_bayes_gs(X_train, X_val, X_test, y_train, y_val, n_trials=30):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective_naive_GS(trial, X_train, X_val, y_train, y_val),\n",
    "                   n_trials=n_trials, n_jobs=-1, show_progress_bar=False)\n",
    "    print(\"Melhores hiperparâmetros encontrados:\")\n",
    "    print(study.best_params)\n",
    "    # Treinar o melhor modelo com os melhores parâmetros\n",
    "    best_model = GaussianNB(**study.best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    # Avaliar no conjunto de teste\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df142687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:53:58,547] A new study created in memory with name: no-name-c8f2bab8-abf9-4842-a9f3-be9b9ff180b9\n",
      "[I 2025-11-13 01:53:58,632] Trial 1 finished with value: 0.7967883970630032 and parameters: {'alpha': 0.08061444366540682}. Best is trial 1 with value: 0.7967883970630032.\n",
      "[I 2025-11-13 01:53:58,644] Trial 3 finished with value: 0.7988139244481561 and parameters: {'alpha': 0.6421611341402095}. Best is trial 3 with value: 0.7988139244481561.\n",
      "[I 2025-11-13 01:53:58,654] Trial 0 finished with value: 0.7991709867422968 and parameters: {'alpha': 0.11350918398907865}. Best is trial 0 with value: 0.7991709867422968.\n",
      "[I 2025-11-13 01:53:58,656] Trial 5 finished with value: 0.7937552298987115 and parameters: {'alpha': 0.02571867002574687}. Best is trial 0 with value: 0.7991709867422968.\n",
      "[I 2025-11-13 01:53:58,659] Trial 6 finished with value: 0.8006345325187125 and parameters: {'alpha': 0.29550244094989003}. Best is trial 6 with value: 0.8006345325187125.\n",
      "[I 2025-11-13 01:53:58,659] Trial 2 finished with value: 0.795253953610198 and parameters: {'alpha': 0.858347870478012}. Best is trial 6 with value: 0.8006345325187125.\n",
      "[I 2025-11-13 01:53:58,666] Trial 4 finished with value: 0.7979593807230002 and parameters: {'alpha': 0.4731326211929258}. Best is trial 6 with value: 0.8006345325187125.\n",
      "[I 2025-11-13 01:53:58,686] Trial 7 finished with value: 0.7993013292629011 and parameters: {'alpha': 0.3749928046025872}. Best is trial 6 with value: 0.8006345325187125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:53:58,742] Trial 8 finished with value: 0.7965894621414867 and parameters: {'alpha': 0.06752041844677995}. Best is trial 6 with value: 0.8006345325187125.\n",
      "[I 2025-11-13 01:53:58,747] Trial 9 finished with value: 0.7938292666788604 and parameters: {'alpha': 0.006861775119224518}. Best is trial 6 with value: 0.8006345325187125.\n",
      "[I 2025-11-13 01:53:58,757] Trial 11 finished with value: 0.7902003244108369 and parameters: {'alpha': 0.0019490781505063421}. Best is trial 6 with value: 0.8006345325187125.\n",
      "[I 2025-11-13 01:53:58,760] Trial 10 finished with value: 0.8007643559307454 and parameters: {'alpha': 1.1692692779334497}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,781] Trial 12 finished with value: 0.7983682448724285 and parameters: {'alpha': 0.25575583355899384}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,794] Trial 13 finished with value: 0.7961807371272219 and parameters: {'alpha': 0.03657817046608279}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,821] Trial 14 finished with value: 0.795253953610198 and parameters: {'alpha': 0.7707522994727475}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,833] Trial 15 finished with value: 0.7943485527909515 and parameters: {'alpha': 0.9045584072248326}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,846] Trial 18 finished with value: 0.8007643559307454 and parameters: {'alpha': 1.1501865425743985}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,854] Trial 16 finished with value: 0.7904316409465459 and parameters: {'alpha': 0.0012876764700761746}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,867] Trial 19 finished with value: 0.8007643559307454 and parameters: {'alpha': 1.1481212809379693}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,879] Trial 20 finished with value: 0.8007643559307454 and parameters: {'alpha': 1.1612551718403672}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,883] Trial 17 finished with value: 0.8006738003028371 and parameters: {'alpha': 1.6366865260040317}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,900] Trial 21 finished with value: 0.7996825217468477 and parameters: {'alpha': 1.4296067519192701}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,925] Trial 22 finished with value: 0.7996595819060445 and parameters: {'alpha': 1.8730871764895134}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,935] Trial 23 finished with value: 0.7996349794564167 and parameters: {'alpha': 1.56040287406167}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,952] Trial 25 finished with value: 0.7987266629299039 and parameters: {'alpha': 1.704339752942732}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,960] Trial 24 finished with value: 0.8005094460696552 and parameters: {'alpha': 1.5473781608322137}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,971] Trial 26 finished with value: 0.7987266629299039 and parameters: {'alpha': 1.7447938769147442}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,974] Trial 27 finished with value: 0.7980581065236528 and parameters: {'alpha': 0.1865574847674857}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,980] Trial 29 finished with value: 0.7980581065236528 and parameters: {'alpha': 0.1618634258145106}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:58,985] Trial 28 finished with value: 0.7980581065236528 and parameters: {'alpha': 0.1714773527660575}. Best is trial 10 with value: 0.8007643559307454.\n",
      "[I 2025-11-13 01:53:59,005] A new study created in memory with name: no-name-a358eabc-1a82-4f4e-a3f4-af947972dbb6\n",
      "[I 2025-11-13 01:53:59,067] Trial 0 finished with value: 0.6891268013087232 and parameters: {'alpha': 1.4231606714545413}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,088] Trial 2 finished with value: 0.5660518506431648 and parameters: {'alpha': 0.005905759601663421}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,093] Trial 1 finished with value: 0.659396805366283 and parameters: {'alpha': 0.2818123740940762}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,096] Trial 4 finished with value: 0.5650478250762806 and parameters: {'alpha': 0.005713051072568882}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,098] Trial 5 finished with value: 0.5682052853762541 and parameters: {'alpha': 0.0077959514257561705}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,109] Trial 3 finished with value: 0.5692102054894574 and parameters: {'alpha': 0.008979641522728994}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,115] Trial 7 finished with value: 0.5542601390383541 and parameters: {'alpha': 0.003462119241247715}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,117] Trial 6 finished with value: 0.6737583784390905 and parameters: {'alpha': 0.44205473444891297}. Best is trial 0 with value: 0.6891268013087232.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'alpha': 1.1692692779334497}\n",
      "Melhor F1 (validação): 0.8008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.76      0.74       417\n",
      "           0       0.84      0.84      0.84      1273\n",
      "           1       0.26      0.23      0.24       168\n",
      "\n",
      "    accuracy                           0.77      1858\n",
      "   macro avg       0.61      0.61      0.61      1858\n",
      "weighted avg       0.76      0.77      0.76      1858\n",
      "\n",
      "[[ 316   90   11]\n",
      " [ 105 1068  100]\n",
      " [  16  114   38]]\n",
      "\n",
      "com oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:53:59,183] Trial 12 finished with value: 0.624195139311101 and parameters: {'alpha': 0.04959636003444992}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,200] Trial 10 finished with value: 0.5480403458805844 and parameters: {'alpha': 0.0019040775077448422}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,207] Trial 15 finished with value: 0.5987253185573506 and parameters: {'alpha': 0.029140077688549537}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,209] Trial 9 finished with value: 0.5476306819182895 and parameters: {'alpha': 0.0024752552302671287}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,222] Trial 13 finished with value: 0.6083190371747241 and parameters: {'alpha': 0.03708160194249976}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,233] Trial 8 finished with value: 0.556281223790249 and parameters: {'alpha': 0.003787939280054039}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,319] Trial 11 finished with value: 0.6241266084640522 and parameters: {'alpha': 0.06504741645632003}. Best is trial 0 with value: 0.6891268013087232.\n",
      "[I 2025-11-13 01:53:59,331] Trial 18 finished with value: 0.6971048317273464 and parameters: {'alpha': 1.9387849617749588}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,349] Trial 14 finished with value: 0.6477734178045297 and parameters: {'alpha': 0.22544987880977518}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,358] Trial 19 finished with value: 0.6921221173648359 and parameters: {'alpha': 1.6600436960633673}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,358] Trial 17 finished with value: 0.6955721099048358 and parameters: {'alpha': 1.9004266139343071}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,358] Trial 20 finished with value: 0.6886093540526754 and parameters: {'alpha': 1.519386260555616}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,392] Trial 21 finished with value: 0.69609520896788 and parameters: {'alpha': 1.8710423055431837}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,392] Trial 16 finished with value: 0.6950714999927587 and parameters: {'alpha': 1.7854134084490678}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,418] Trial 23 finished with value: 0.6971048317273464 and parameters: {'alpha': 1.9269526483047734}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,425] Trial 22 finished with value: 0.6971048317273464 and parameters: {'alpha': 1.928301551266442}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,430] Trial 24 finished with value: 0.6916011919935121 and parameters: {'alpha': 1.7172215020839505}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,432] Trial 25 finished with value: 0.674838156600722 and parameters: {'alpha': 0.6841704852713536}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,452] Trial 26 finished with value: 0.6808968207745144 and parameters: {'alpha': 0.5841422197564061}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,458] Trial 27 finished with value: 0.678892598883078 and parameters: {'alpha': 0.6938988978562453}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,458] Trial 28 finished with value: 0.6791389090889117 and parameters: {'alpha': 0.6089405940282452}. Best is trial 18 with value: 0.6971048317273464.\n",
      "[I 2025-11-13 01:53:59,458] Trial 29 finished with value: 0.678892598883078 and parameters: {'alpha': 0.6937567389472907}. Best is trial 18 with value: 0.6971048317273464.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'alpha': 1.9387849617749588}\n",
      "Melhor F1 (validação): 0.6971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.80      0.78      1273\n",
      "           0       0.57      0.75      0.65      1273\n",
      "           1       0.70      0.44      0.54      1273\n",
      "\n",
      "    accuracy                           0.66      3819\n",
      "   macro avg       0.68      0.66      0.65      3819\n",
      "weighted avg       0.68      0.66      0.65      3819\n",
      "\n",
      "[[1013  190   70]\n",
      " [ 142  961  170]\n",
      " [ 170  547  556]]\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_NB = Naive_Bayes_MN(X_train_count_vec,X_val_count_vec,X_test_count_vec,y_train,y_val)\n",
    "print(metrics.classification_report(y_test, count_vec_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_NB))\n",
    "\n",
    "print(\"\\ncom oversampling\")\n",
    "count_vec_over_predicted_NB = Naive_Bayes_MN(X_train_oversampling_count_vec,X_val_oversampling_count_vec,X_test_oversampling_count_vec,y_train_oversampling,y_val_oversampling)\n",
    "print(metrics.classification_report(y_test_oversampling, count_vec_over_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, count_vec_over_predicted_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10c2c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:53:59,502] A new study created in memory with name: no-name-f693ea1a-bb9f-41b0-9d62-98769c1cd461\n",
      "[I 2025-11-13 01:53:59,564] Trial 0 finished with value: 0.755673354280673 and parameters: {'alpha': 0.3807611873028814}. Best is trial 0 with value: 0.755673354280673.\n",
      "[I 2025-11-13 01:53:59,576] Trial 1 finished with value: 0.7582638282882935 and parameters: {'alpha': 0.2545124063301098}. Best is trial 1 with value: 0.7582638282882935.\n",
      "[I 2025-11-13 01:53:59,580] Trial 2 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.015475727854694844}. Best is trial 2 with value: 0.7593235332092246.\n",
      "[I 2025-11-13 01:53:59,596] Trial 5 finished with value: 0.7619920139669151 and parameters: {'alpha': 0.19465465144783933}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,611] Trial 4 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.0501774379265103}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,613] Trial 3 finished with value: 0.7397466293285448 and parameters: {'alpha': 1.5785741286278614}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,621] Trial 7 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.03454169027729023}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,628] Trial 6 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.008527358142976919}. Best is trial 5 with value: 0.7619920139669151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----TF-IDF ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:53:59,651] Trial 9 finished with value: 0.7606600986828669 and parameters: {'alpha': 0.16757134725510736}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,662] Trial 8 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.0048808107705348}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,684] Trial 10 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.002908113732422598}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,715] Trial 12 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.034292599355040136}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,717] Trial 11 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.05827912444958128}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,717] Trial 13 finished with value: 0.754703054254095 and parameters: {'alpha': 0.5304761953714479}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,724] Trial 15 finished with value: 0.754703054254095 and parameters: {'alpha': 0.4814642290242704}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,734] Trial 17 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.0014687926409383486}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,737] Trial 14 finished with value: 0.7606600986828669 and parameters: {'alpha': 0.1378169695561799}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,744] Trial 16 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.0014703405008775327}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,774] Trial 18 finished with value: 0.7606600986828669 and parameters: {'alpha': 0.1645843047622208}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,797] Trial 19 finished with value: 0.7606600986828669 and parameters: {'alpha': 0.15125108204202936}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,812] Trial 20 finished with value: 0.7424992074558324 and parameters: {'alpha': 1.3768305609139364}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,842] Trial 21 finished with value: 0.7383625914261442 and parameters: {'alpha': 1.6728529193300108}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,849] Trial 22 finished with value: 0.7383625914261442 and parameters: {'alpha': 1.7007739557635952}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,871] Trial 24 finished with value: 0.7465901576494146 and parameters: {'alpha': 0.7870686061614527}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,871] Trial 23 finished with value: 0.7383625914261442 and parameters: {'alpha': 1.6407494525759172}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,872] Trial 25 finished with value: 0.745231490748949 and parameters: {'alpha': 1.0188013329605319}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,875] Trial 26 finished with value: 0.7411254827356466 and parameters: {'alpha': 1.5097317343232934}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,876] Trial 27 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.10216741687806823}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,876] Trial 28 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.10532758975805177}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,900] Trial 29 finished with value: 0.7593235332092246 and parameters: {'alpha': 0.10713090200309475}. Best is trial 5 with value: 0.7619920139669151.\n",
      "[I 2025-11-13 01:53:59,918] A new study created in memory with name: no-name-6a688feb-345d-476d-a14c-ffd97f23e633\n",
      "[I 2025-11-13 01:53:59,990] Trial 2 finished with value: 0.6649427174259951 and parameters: {'alpha': 0.03236377815551112}. Best is trial 2 with value: 0.6649427174259951.\n",
      "[I 2025-11-13 01:53:59,995] Trial 1 finished with value: 0.6564044303852367 and parameters: {'alpha': 0.012036720709666767}. Best is trial 2 with value: 0.6649427174259951.\n",
      "[I 2025-11-13 01:53:59,997] Trial 0 finished with value: 0.6722693622924746 and parameters: {'alpha': 0.2092791283432211}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:53:59,997] Trial 4 finished with value: 0.6649427174259951 and parameters: {'alpha': 0.033853016883559905}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:53:59,998] Trial 5 finished with value: 0.6649427174259951 and parameters: {'alpha': 0.03245173624288703}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,009] Trial 3 finished with value: 0.6587964809592517 and parameters: {'alpha': 0.0643491566831932}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,014] Trial 7 finished with value: 0.6649427174259951 and parameters: {'alpha': 0.045409550290508784}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,036] Trial 6 finished with value: 0.6583111547330539 and parameters: {'alpha': 0.07485647964049752}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,080] Trial 8 finished with value: 0.6588298900522627 and parameters: {'alpha': 0.02379588503279869}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,092] Trial 9 finished with value: 0.642168710754768 and parameters: {'alpha': 0.001068451537242355}. Best is trial 0 with value: 0.6722693622924746.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'alpha': 0.19465465144783933}\n",
      "Melhor F1 (validação): 0.7620\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.52      0.63       417\n",
      "           0       0.77      0.96      0.86      1273\n",
      "           1       0.67      0.01      0.02       168\n",
      "\n",
      "    accuracy                           0.78      1858\n",
      "   macro avg       0.75      0.50      0.50      1858\n",
      "weighted avg       0.77      0.78      0.73      1858\n",
      "\n",
      "[[ 216  201    0]\n",
      " [  44 1228    1]\n",
      " [  10  156    2]]\n",
      "\n",
      " com oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:54:00,093] Trial 10 finished with value: 0.6441462860274292 and parameters: {'alpha': 0.0021406139175066284}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,114] Trial 11 finished with value: 0.6587964809592517 and parameters: {'alpha': 0.07196211688211081}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,114] Trial 12 finished with value: 0.6588298900522627 and parameters: {'alpha': 0.0130719674131724}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,127] Trial 15 finished with value: 0.642168710754768 and parameters: {'alpha': 0.0011256609474568473}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,140] Trial 14 finished with value: 0.656864470722834 and parameters: {'alpha': 0.04771117842303776}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,141] Trial 13 finished with value: 0.668937808637953 and parameters: {'alpha': 1.156350230496132}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,186] Trial 16 finished with value: 0.6702759851174157 and parameters: {'alpha': 1.7905812379600694}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,192] Trial 17 finished with value: 0.6707884156463461 and parameters: {'alpha': 1.6225579527966247}. Best is trial 0 with value: 0.6722693622924746.\n",
      "[I 2025-11-13 01:54:00,203] Trial 18 finished with value: 0.6796648077335082 and parameters: {'alpha': 0.6531169763798168}. Best is trial 18 with value: 0.6796648077335082.\n",
      "[I 2025-11-13 01:54:00,216] Trial 19 finished with value: 0.6718441386216323 and parameters: {'alpha': 0.9646461724909225}. Best is trial 18 with value: 0.6796648077335082.\n",
      "[I 2025-11-13 01:54:00,219] Trial 21 finished with value: 0.6707884156463461 and parameters: {'alpha': 1.3773577835656783}. Best is trial 18 with value: 0.6796648077335082.\n",
      "[I 2025-11-13 01:54:00,224] Trial 22 finished with value: 0.6718441386216323 and parameters: {'alpha': 1.0259374661696097}. Best is trial 18 with value: 0.6796648077335082.\n",
      "[I 2025-11-13 01:54:00,240] Trial 20 finished with value: 0.6754423206337733 and parameters: {'alpha': 0.736727798269065}. Best is trial 18 with value: 0.6796648077335082.\n",
      "[I 2025-11-13 01:54:00,262] Trial 23 finished with value: 0.6717558154200374 and parameters: {'alpha': 1.124527378863756}. Best is trial 18 with value: 0.6796648077335082.\n",
      "[I 2025-11-13 01:54:00,274] Trial 24 finished with value: 0.6660293764790871 and parameters: {'alpha': 0.37331735532974464}. Best is trial 18 with value: 0.6796648077335082.\n",
      "[I 2025-11-13 01:54:00,290] Trial 25 finished with value: 0.6666764410776781 and parameters: {'alpha': 0.341537672543259}. Best is trial 18 with value: 0.6796648077335082.\n",
      "[I 2025-11-13 01:54:00,292] Trial 27 finished with value: 0.6802877914721875 and parameters: {'alpha': 0.42044986968084547}. Best is trial 27 with value: 0.6802877914721875.\n",
      "[I 2025-11-13 01:54:00,292] Trial 26 finished with value: 0.6722693622924746 and parameters: {'alpha': 0.2218467035091499}. Best is trial 27 with value: 0.6802877914721875.\n",
      "[I 2025-11-13 01:54:00,300] Trial 28 finished with value: 0.6666764410776781 and parameters: {'alpha': 0.32703362901376987}. Best is trial 27 with value: 0.6802877914721875.\n",
      "[I 2025-11-13 01:54:00,305] Trial 29 finished with value: 0.6730838294218286 and parameters: {'alpha': 0.299837304311341}. Best is trial 27 with value: 0.6802877914721875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'alpha': 0.42044986968084547}\n",
      "Melhor F1 (validação): 0.6803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.77      0.76      1273\n",
      "           0       0.50      0.83      0.62      1273\n",
      "           1       0.70      0.24      0.36      1273\n",
      "\n",
      "    accuracy                           0.61      3819\n",
      "   macro avg       0.65      0.61      0.58      3819\n",
      "weighted avg       0.65      0.61      0.58      3819\n",
      "\n",
      "[[ 978  251   44]\n",
      " [ 134 1051   88]\n",
      " [ 176  791  306]]\n"
     ]
    }
   ],
   "source": [
    "print (\"----TF-IDF ----\")\n",
    "tfidf_vec_predicted_NB= Naive_Bayes_MN(X_train_tfidf_vec, X_val_tfidf_vec, X_test_tfidf_vec, y_train, y_val) \n",
    "print(metrics.classification_report(y_test, tfidf_vec_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_NB))\n",
    "\n",
    "print(\"\\n com oversampling\")\n",
    "tfidf_vec_oversampling_predicted_NB= Naive_Bayes_MN(X_train_oversampling_tfidf_vec, X_val_oversampling_tfidf_vec, X_test_oversampling_tfidf_vec, y_train_oversampling, y_val_oversampling) \n",
    "print(metrics.classification_report(y_test_oversampling, tfidf_vec_oversampling_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, tfidf_vec_oversampling_predicted_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c766d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:54:00,342] A new study created in memory with name: no-name-80c49c07-1442-4306-8761-be124b8ab988\n",
      "[I 2025-11-13 01:54:00,457] Trial 1 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 7.7428707460386e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,457] Trial 2 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.6274988999220486e-09}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,457] Trial 0 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.1053700796863899e-11}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,475] Trial 3 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 8.918620266709172e-07}. Best is trial 1 with value: 0.4016961525191454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----WORD2VEC ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:54:00,475] Trial 4 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.5849465941797246e-12}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,475] Trial 6 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.18492445068062e-07}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,475] Trial 5 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.6698348637013243e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,491] Trial 7 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.375418822320465e-07}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,584] Trial 8 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.2044607660800132e-10}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,592] Trial 9 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.392471157021167e-12}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,628] Trial 10 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 0.0006600759782037629}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,636] Trial 13 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.748619904064558e-10}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,637] Trial 14 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.336054233065876e-11}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,642] Trial 11 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.5483914014359079e-09}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,654] Trial 12 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.9748849519110227e-05}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,701] Trial 15 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.4339600882765587e-05}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,746] Trial 16 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.3702737866861533e-12}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,767] Trial 17 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 0.00027697885198426703}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,824] Trial 19 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 0.00042918077302699727}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,827] Trial 20 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 6.071459547885622e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,846] Trial 18 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.529646756521982e-05}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,860] Trial 21 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.077454957511883e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,893] Trial 22 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.3141429138987535e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,920] Trial 24 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.266987492268705e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,920] Trial 23 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.3034337435481842e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,936] Trial 25 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.283042254189953e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,955] Trial 26 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 8.073041828577352e-09}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,965] Trial 28 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.95293259814425e-09}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,975] Trial 29 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.418143435060885e-09}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:00,979] Trial 27 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 8.332735236127619e-09}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-13 01:54:01,028] A new study created in memory with name: no-name-1d68e599-40e5-49cf-8b96-d6d39b377712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'var_smoothing': 7.7428707460386e-08}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.42      0.43       417\n",
      "           0       0.84      0.32      0.47      1273\n",
      "           1       0.11      0.62      0.18       168\n",
      "\n",
      "    accuracy                           0.37      1858\n",
      "   macro avg       0.46      0.46      0.36      1858\n",
      "weighted avg       0.68      0.37      0.43      1858\n",
      "\n",
      "[[175  44 198]\n",
      " [196 410 667]\n",
      " [ 30  33 105]]\n",
      "oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:54:01,225] Trial 1 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.2943987400236919e-09}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,247] Trial 5 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.0187533802821353e-12}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,254] Trial 2 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 2.182726745055361e-05}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,277] Trial 0 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.8608119357196608e-10}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,293] Trial 6 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 2.6202759466833022e-06}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,294] Trial 4 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.7322099228760636e-06}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,301] Trial 3 finished with value: 0.4546441032920095 and parameters: {'var_smoothing': 0.0005797817321095518}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,332] Trial 7 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 4.731453885001192e-12}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,470] Trial 9 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 8.197293528662807e-10}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,479] Trial 8 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 4.527802545259024e-10}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,479] Trial 10 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 3.501200278933563e-07}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,513] Trial 12 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 4.724182932746703e-07}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,532] Trial 11 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 5.962315086424197e-10}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,563] Trial 13 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 5.209611769293607e-09}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,603] Trial 15 finished with value: 0.45535138345063336 and parameters: {'var_smoothing': 0.0004777430361694247}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,577] Trial 14 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.5152265321637275e-07}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,776] Trial 17 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.7792018053309098e-09}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,787] Trial 19 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.4781770911250657e-09}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,792] Trial 16 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 2.1032600608894155e-09}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,833] Trial 18 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.8466534199655766e-09}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,864] Trial 20 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 9.806152837473986e-09}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,885] Trial 22 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 2.866512192628752e-11}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,906] Trial 23 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 2.4981076733412392e-11}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,930] Trial 21 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 1.9826865743219335e-11}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,991] Trial 25 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 3.9150136641001646e-11}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:01,991] Trial 24 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 3.676981680703768e-11}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:02,009] Trial 26 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 4.028051757835908e-11}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:02,018] Trial 27 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 2.741498743896442e-11}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:02,026] Trial 28 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 6.64306444293427e-11}. Best is trial 1 with value: 0.4560574501374098.\n",
      "[I 2025-11-13 01:54:02,026] Trial 29 finished with value: 0.4560574501374098 and parameters: {'var_smoothing': 6.537926703183168e-11}. Best is trial 1 with value: 0.4560574501374098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'var_smoothing': 1.2943987400236919e-09}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.42      0.43       417\n",
      "           0       0.84      0.32      0.47      1273\n",
      "           1       0.11      0.62      0.18       168\n",
      "\n",
      "    accuracy                           0.37      1858\n",
      "   macro avg       0.46      0.46      0.36      1858\n",
      "weighted avg       0.68      0.37      0.43      1858\n",
      "\n",
      "[[175  44 198]\n",
      " [196 410 667]\n",
      " [ 30  33 105]]\n"
     ]
    }
   ],
   "source": [
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_NB= naive_bayes_gs(X_train_word2vec, X_val_word2vec, X_test_word2vec, y_train, y_val, n_trials=30) \n",
    "print(metrics.classification_report(y_test, word2vec_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_NB))\n",
    "\n",
    "print (\"oversampling\")\n",
    "word2vec_over_sampling_predicted_NB= naive_bayes_gs(X_train_oversampling_word2vec, X_val_oversampling_word2vec, X_test_oversampling_word2vec, y_train_oversampling, y_val_oversampling, n_trials=30) \n",
    "print(metrics.classification_report(y_test, word2vec_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_NB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d45c15f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:54:02,129] A new study created in memory with name: no-name-0e8e8f98-cff2-49e9-abec-6d97f25d5e6f\n",
      "[I 2025-11-13 01:54:02,204] Trial 1 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 3.181479933891035e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,223] Trial 5 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 3.723837377411133e-12}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,223] Trial 2 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 5.258673784328246e-08}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,235] Trial 0 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.961341122628346e-10}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,235] Trial 4 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 8.464156576860832e-06}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,241] Trial 3 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.679895942628976e-10}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,241] Trial 6 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 3.9365628420379014e-05}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,263] Trial 7 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.0744176371570535e-12}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,306] Trial 8 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 0.00026880504444673476}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,317] Trial 9 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 1.7157712885932446e-11}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,338] Trial 10 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.3719045961068847e-08}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,341] Trial 11 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 0.0008186794963665268}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,343] Trial 13 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 4.731762661216851e-10}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,359] Trial 12 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 3.5204610877358284e-11}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,369] Trial 14 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 5.19638143896831e-10}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,402] Trial 15 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 4.489943398906709e-11}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,411] Trial 16 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 1.6371931217913354e-08}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,442] Trial 17 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 6.588556812825965e-10}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,448] Trial 18 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.0797836325396322e-08}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,477] Trial 19 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.14171749623934e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,477] Trial 20 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.041423311958032e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,498] Trial 22 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 1.4178639728196491e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,501] Trial 21 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 1.4044746664671334e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,518] Trial 23 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 5.479944193885536e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,524] Trial 24 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 5.608455711681375e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,524] Trial 25 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 8.167291975060555e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,549] Trial 26 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 5.309568403552003e-07}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,561] Trial 27 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 1.098261553126309e-06}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,561] Trial 28 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.4257959193792084e-06}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,572] Trial 29 finished with value: 0.4332751972427922 and parameters: {'var_smoothing': 2.7600630410965526e-06}. Best is trial 1 with value: 0.4332751972427922.\n",
      "[I 2025-11-13 01:54:02,591] A new study created in memory with name: no-name-a411aa1b-0032-4deb-ab15-ddea0941b2ff\n",
      "[I 2025-11-13 01:54:02,744] Trial 1 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 4.5725467541008646e-10}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,758] Trial 5 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.4421688710568579e-05}. Best is trial 1 with value: 0.5861967367284407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'var_smoothing': 3.181479933891035e-07}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.66      0.54       417\n",
      "           0       0.85      0.32      0.47      1273\n",
      "           1       0.13      0.60      0.22       168\n",
      "\n",
      "    accuracy                           0.42      1858\n",
      "   macro avg       0.48      0.53      0.41      1858\n",
      "weighted avg       0.70      0.42      0.46      1858\n",
      "\n",
      "[[274  43 100]\n",
      " [293 411 569]\n",
      " [ 39  28 101]]\n",
      "oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:54:02,760] Trial 2 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 9.121403568322176e-05}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,768] Trial 6 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 8.442218744391615e-07}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,771] Trial 3 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.5066753350573997e-06}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,775] Trial 0 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 9.109247296548664e-05}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,782] Trial 4 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.25366301080702e-12}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,787] Trial 7 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.9396315154645752e-10}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,909] Trial 8 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 4.930515268279685e-12}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,922] Trial 9 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.9771253987500324e-05}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,927] Trial 10 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 4.230285578607004e-09}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,968] Trial 11 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 3.198779600082728e-12}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,978] Trial 13 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 0.00032136035323840275}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:02,998] Trial 12 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 3.559665501934234e-08}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:03,024] Trial 14 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 0.00022792486421950256}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:03,026] Trial 15 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 2.5254812334284223e-08}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:03,100] Trial 17 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.6092025920022604e-08}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:03,112] Trial 16 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.0651408348110188e-09}. Best is trial 1 with value: 0.5861967367284407.\n",
      "[I 2025-11-13 01:54:03,122] Trial 18 finished with value: 0.5867046008705512 and parameters: {'var_smoothing': 0.0008956152885288222}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,148] Trial 19 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.52523371631414e-08}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,178] Trial 20 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 1.037064395947531e-08}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,189] Trial 21 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 2.9997587527909085e-10}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,222] Trial 22 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 3.124869826315397e-10}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,235] Trial 23 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 2.182838345447734e-10}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,264] Trial 24 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 7.276847297692087e-11}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,271] Trial 25 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 9.390267806813362e-07}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,271] Trial 26 finished with value: 0.5861967367284407 and parameters: {'var_smoothing': 6.520749969046413e-07}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,291] Trial 27 finished with value: 0.5867046008705512 and parameters: {'var_smoothing': 0.000806603314036639}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,302] Trial 28 finished with value: 0.5867046008705512 and parameters: {'var_smoothing': 0.0009105039358380681}. Best is trial 18 with value: 0.5867046008705512.\n",
      "[I 2025-11-13 01:54:03,302] Trial 29 finished with value: 0.5867216005001563 and parameters: {'var_smoothing': 0.0007800408532648814}. Best is trial 29 with value: 0.5867216005001563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'var_smoothing': 0.0007800408532648814}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.66      0.54       417\n",
      "           0       0.85      0.32      0.47      1273\n",
      "           1       0.13      0.60      0.22       168\n",
      "\n",
      "    accuracy                           0.42      1858\n",
      "   macro avg       0.48      0.53      0.41      1858\n",
      "weighted avg       0.70      0.42      0.46      1858\n",
      "\n",
      "[[274  43 100]\n",
      " [293 411 569]\n",
      " [ 39  28 101]]\n"
     ]
    }
   ],
   "source": [
    "#word2vec treinado com os nossos dados\n",
    "word2vec_trained_predicted_NB= naive_bayes_gs(X_train_w2v_trained, X_val_w2v_trained, X_test_w2v_trained, y_train, y_val, n_trials=30) \n",
    "print(metrics.classification_report(y_test, word2vec_trained_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_trained_predicted_NB))\n",
    "\n",
    "print(\"oversampling\")\n",
    "word2vec_oversampling_trained_predicted_NB= naive_bayes_gs(X_train_over_w2v_trained, X_val_over_w2v_trained, X_test_over_w2v_trained, y_train_oversampling, y_val_oversampling, n_trials=30) \n",
    "print(metrics.classification_report(y_test, word2vec_trained_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_trained_predicted_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d8da10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----GLOVE ----\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Glove\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----GLOVE ----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m glove_predicted_NB\u001b[38;5;241m=\u001b[39m naive_bayes_gs(X_train_glove, X_val_glove, X_test_glove, y_train, y_val, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m) \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mclassification_report(y_test, glove_predicted_NB))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(y_test, glove_predicted_NB))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_glove' is not defined"
     ]
    }
   ],
   "source": [
    "#Glove\n",
    "print (\"----GLOVE ----\")\n",
    "glove_predicted_NB= naive_bayes_gs(X_train_glove, X_val_glove, X_test_glove, y_train, y_val, n_trials=30) \n",
    "print(metrics.classification_report(y_test, glove_predicted_NB))\n",
    "print(metrics.confusion_matrix(y_test, glove_predicted_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44bdd3",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab39b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, X_val, y_train, y_val):\n",
    "\n",
    "    #Definir hiperparâmetros a testar \n",
    "    C = trial.suggest_float('C', 0.01, 10.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "\n",
    "    #Criar modelo SVM \n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree)\n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree)\n",
    "\n",
    "    #treinar modelo com conjunto de treino\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #prever no conjunto de validação\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    #calcular f1\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "    return f1\n",
    "\n",
    "def svm(X_train, X_val, X_test, y_train, y_val, n_trials=30):\n",
    "    # Chamar o Optuna para otimizar os parâmetros\n",
    "    objeto_para_otimizar = optuna.create_study(direction='maximize')\n",
    "    objeto_para_otimizar.optimize(lambda trial: objective(trial, X_train, X_val, y_train, y_val),\n",
    "                   n_trials=n_trials, n_jobs=-1, show_progress_bar=False )\n",
    "\n",
    "    print(\"Melhores hiperparâmetros encontrados:\")\n",
    "    print(objeto_para_otimizar.best_params)\n",
    "\n",
    "    # Treinar o melhor modelo\n",
    "    best_model = SVC(**objeto_para_otimizar.best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    #  Avaliar no conjunto de teste\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8e61fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:55:28,543] A new study created in memory with name: no-name-fb4af387-d0a3-45df-9429-9c6e9f0d1220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:55:30,785] Trial 1 finished with value: 0.65764422131039 and parameters: {'C': 0.4671758860281262, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:30,810] Trial 4 finished with value: 0.271047227926078 and parameters: {'C': 3.3427900094228766, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:30,936] Trial 3 finished with value: 0.271047227926078 and parameters: {'C': 0.13641763630293263, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:31,446] Trial 5 finished with value: 0.5946632594446603 and parameters: {'C': 6.927975402821871, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:31,726] Trial 0 finished with value: 0.5278430679381149 and parameters: {'C': 0.485204926504187, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:31,738] Trial 2 finished with value: 0.32608024691358023 and parameters: {'C': 0.02048035472956563, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:31,744] Trial 6 finished with value: 0.3036116973760678 and parameters: {'C': 0.02555185098402539, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:32,405] Trial 7 finished with value: 0.414815720157258 and parameters: {'C': 0.13811446717880657, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:32,448] Trial 8 finished with value: 0.5217530778046032 and parameters: {'C': 0.055453084661562, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:33,410] Trial 11 finished with value: 0.4993569443938897 and parameters: {'C': 2.599683166226252, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:34,162] Trial 16 finished with value: 0.614698397227637 and parameters: {'C': 0.1716310592416826, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:34,667] Trial 10 finished with value: 0.49942614770459076 and parameters: {'C': 0.0863510651392179, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:35,031] Trial 13 finished with value: 0.391393062434487 and parameters: {'C': 0.11783956849641787, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:35,080] Trial 9 finished with value: 0.3529305328860702 and parameters: {'C': 0.06611240350284676, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:35,484] Trial 17 finished with value: 0.635522438235876 and parameters: {'C': 0.7422983095185112, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:35,678] Trial 12 finished with value: 0.4711833313247366 and parameters: {'C': 0.03441910387110033, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:35,709] Trial 14 finished with value: 0.4481902150086597 and parameters: {'C': 0.5675997875182969, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:36,136] Trial 18 finished with value: 0.6507142761967512 and parameters: {'C': 0.5489810919669337, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:37,079] Trial 20 finished with value: 0.6451670988187842 and parameters: {'C': 0.5602870818188654, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:37,329] Trial 19 finished with value: 0.635522438235876 and parameters: {'C': 0.7377580745800957, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:37,531] Trial 22 finished with value: 0.6368936887722066 and parameters: {'C': 0.7538146362667677, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:37,879] Trial 21 finished with value: 0.6355867392069062 and parameters: {'C': 0.7226338005503323, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:37,948] Trial 24 finished with value: 0.6162045024534256 and parameters: {'C': 1.076241253429555, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:37,994] Trial 15 finished with value: 0.5184010416296596 and parameters: {'C': 3.295839592248307, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:38,471] Trial 25 finished with value: 0.6160375208127614 and parameters: {'C': 1.4484965922107145, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:38,487] Trial 23 finished with value: 0.6377538091165385 and parameters: {'C': 0.6304791335769259, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:39,290] Trial 26 finished with value: 0.6080562063846361 and parameters: {'C': 1.8445690615798755, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:39,585] Trial 28 finished with value: 0.6084442753898821 and parameters: {'C': 1.636650181782647, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:39,637] Trial 29 finished with value: 0.6561176653149897 and parameters: {'C': 0.27011619107366813, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n",
      "[I 2025-11-13 01:55:39,701] Trial 27 finished with value: 0.6093944075581145 and parameters: {'C': 1.869006118970645, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.65764422131039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 0.4671758860281262, 'kernel': 'linear', 'gamma': 'scale'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:55:40,992] A new study created in memory with name: no-name-d2e28a6c-8b63-4494-a67d-538f5aa89962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.67      0.71       417\n",
      "           0       0.82      0.89      0.85      1273\n",
      "           1       0.27      0.15      0.19       168\n",
      "\n",
      "    accuracy                           0.78      1858\n",
      "   macro avg       0.61      0.57      0.58      1858\n",
      "weighted avg       0.75      0.78      0.76      1858\n",
      "\n",
      "[[ 281  127    9]\n",
      " [  79 1136   58]\n",
      " [  16  127   25]]\n",
      "\n",
      "com oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:55:50,085] Trial 7 finished with value: 0.6522857001263389 and parameters: {'C': 2.4330142197598836, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:55:51,529] Trial 6 finished with value: 0.5654073581351042 and parameters: {'C': 5.319987538389064, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:55:54,823] Trial 3 finished with value: 0.5673638925581178 and parameters: {'C': 1.6031991695603132, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:55:55,257] Trial 2 finished with value: 0.521647957662429 and parameters: {'C': 2.0723413854978, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:55:59,329] Trial 4 finished with value: 0.45724401602749404 and parameters: {'C': 0.4824754391616673, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:56:02,147] Trial 8 finished with value: 0.5649017446012289 and parameters: {'C': 5.526843354346876, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:56:04,374] Trial 5 finished with value: 0.22146112690501493 and parameters: {'C': 0.012743830788690819, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:56:09,285] Trial 1 finished with value: 0.2128023112716748 and parameters: {'C': 0.04734201247612899, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:56:09,326] Trial 0 finished with value: 0.16666666666666666 and parameters: {'C': 1.0434361310336864, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:56:17,291] Trial 11 finished with value: 0.3155019584740673 and parameters: {'C': 0.32156165684305954, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:56:20,390] Trial 9 finished with value: 0.2128023112716748 and parameters: {'C': 0.014179522676798352, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:56:27,255] Trial 10 finished with value: 0.1799704542178436 and parameters: {'C': 0.6837050620058198, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 7 with value: 0.6522857001263389.\n",
      "[I 2025-11-13 01:56:27,749] Trial 15 finished with value: 0.668756901759818 and parameters: {'C': 0.012929909152778994, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:27,790] Trial 13 finished with value: 0.6067931042638557 and parameters: {'C': 0.1770354253092183, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:29,703] Trial 18 finished with value: 0.6454284205949212 and parameters: {'C': 1.6739017999530317, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:29,935] Trial 17 finished with value: 0.6577468529378478 and parameters: {'C': 0.09451303161856148, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:31,854] Trial 12 finished with value: 0.1799704542178436 and parameters: {'C': 0.012493893618746477, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:33,259] Trial 14 finished with value: 0.1847313441829127 and parameters: {'C': 1.9905767609859621, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:35,409] Trial 16 finished with value: 0.4478751897913575 and parameters: {'C': 0.20906395801100955, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:38,504] Trial 20 finished with value: 0.6559563426424136 and parameters: {'C': 0.10277286610202195, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:38,718] Trial 19 finished with value: 0.6454284205949212 and parameters: {'C': 2.0514255524315907, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:40,586] Trial 22 finished with value: 0.6561723340411865 and parameters: {'C': 0.10716762081905556, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:41,812] Trial 21 finished with value: 0.6576631056761258 and parameters: {'C': 0.09977675836815429, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 15 with value: 0.668756901759818.\n",
      "[I 2025-11-13 01:56:41,854] Trial 23 finished with value: 0.6804618316736172 and parameters: {'C': 0.06610130820451961, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 23 with value: 0.6804618316736172.\n",
      "[I 2025-11-13 01:56:44,171] Trial 25 finished with value: 0.6572449485004848 and parameters: {'C': 0.09172586020856406, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 23 with value: 0.6804618316736172.\n",
      "[I 2025-11-13 01:56:45,879] Trial 24 finished with value: 0.6628726316766679 and parameters: {'C': 0.08096500406474477, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 23 with value: 0.6804618316736172.\n",
      "[I 2025-11-13 01:56:48,473] Trial 26 finished with value: 0.6810852399117063 and parameters: {'C': 0.06316711101442624, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 26 with value: 0.6810852399117063.\n",
      "[I 2025-11-13 01:56:49,623] Trial 28 finished with value: 0.6840256976947554 and parameters: {'C': 0.06193275276398259, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 28 with value: 0.6840256976947554.\n",
      "[I 2025-11-13 01:56:49,825] Trial 27 finished with value: 0.6960775047969262 and parameters: {'C': 0.03440564595122038, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 27 with value: 0.6960775047969262.\n",
      "[I 2025-11-13 01:56:50,882] Trial 29 finished with value: 0.6921201312896995 and parameters: {'C': 0.0335968431296376, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 27 with value: 0.6960775047969262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 0.03440564595122038, 'kernel': 'linear', 'gamma': 'auto'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.74      0.79      1273\n",
      "           0       0.52      0.83      0.64      1273\n",
      "           1       0.72      0.37      0.49      1273\n",
      "\n",
      "    accuracy                           0.65      3819\n",
      "   macro avg       0.69      0.65      0.64      3819\n",
      "weighted avg       0.69      0.65      0.64      3819\n",
      "\n",
      "[[ 941  264   68]\n",
      " [ 101 1057  115]\n",
      " [  78  724  471]]\n"
     ]
    }
   ],
   "source": [
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_SVM= svm(X_train_count_vec, X_val_count_vec, X_test_count_vec, y_train, y_val, n_trials=30) \n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_SVM))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_SVM))\n",
    "\n",
    "print(\"\\ncom oversampling\")\n",
    "count_vec_over_predicted_SVM = svm(X_train_oversampling_count_vec, X_val_oversampling_count_vec, X_test_oversampling_count_vec, y_train_oversampling, y_val_oversampling, n_trials=30)\n",
    "print(metrics.classification_report(y_test_oversampling, count_vec_over_predicted_SVM))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, count_vec_over_predicted_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e5930db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:56:58,800] A new study created in memory with name: no-name-beade782-90c7-4956-b6f1-cc658d410cdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- TF-IDF ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:57:00,308] Trial 7 finished with value: 0.5294004241372662 and parameters: {'C': 0.3464369309644731, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 7 with value: 0.5294004241372662.\n",
      "[I 2025-11-13 01:57:00,318] Trial 4 finished with value: 0.5382299327291854 and parameters: {'C': 0.4609419620479682, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 4 with value: 0.5382299327291854.\n",
      "[I 2025-11-13 01:57:01,168] Trial 2 finished with value: 0.5409567848592238 and parameters: {'C': 0.6933168454682551, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 2 with value: 0.5409567848592238.\n",
      "[I 2025-11-13 01:57:01,196] Trial 5 finished with value: 0.5031314993382492 and parameters: {'C': 0.10834002692134755, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 2 with value: 0.5409567848592238.\n",
      "[I 2025-11-13 01:57:01,538] Trial 6 finished with value: 0.5954805924095572 and parameters: {'C': 3.7133891205676353, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:01,603] Trial 8 finished with value: 0.271047227926078 and parameters: {'C': 0.05706514254701916, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:01,831] Trial 0 finished with value: 0.28170594837261503 and parameters: {'C': 0.04271624347758046, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:02,004] Trial 3 finished with value: 0.5047603591907389 and parameters: {'C': 0.9000342924512549, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:02,540] Trial 9 finished with value: 0.27463423725654645 and parameters: {'C': 0.017531606805547637, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:02,949] Trial 1 finished with value: 0.48810274692627625 and parameters: {'C': 0.14658377189086877, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:02,969] Trial 14 finished with value: 0.271047227926078 and parameters: {'C': 0.21800408930634765, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:03,270] Trial 13 finished with value: 0.28106227106227105 and parameters: {'C': 2.5921082789788312, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:03,365] Trial 10 finished with value: 0.5436605241905881 and parameters: {'C': 0.7888862006347838, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:03,439] Trial 11 finished with value: 0.47964932409572986 and parameters: {'C': 0.03724624426184116, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:03,975] Trial 12 finished with value: 0.5953542448147698 and parameters: {'C': 3.184673179791801, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:04,350] Trial 15 finished with value: 0.5437455538721362 and parameters: {'C': 1.087569762389996, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 0.5954805924095572.\n",
      "[I 2025-11-13 01:57:04,779] Trial 18 finished with value: 0.6356177224240719 and parameters: {'C': 8.26845694694628, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:04,970] Trial 19 finished with value: 0.6318899945245519 and parameters: {'C': 7.29604611255886, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:05,286] Trial 17 finished with value: 0.6072003979108295 and parameters: {'C': 6.728709396524819, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:05,517] Trial 16 finished with value: 0.6134490464551753 and parameters: {'C': 5.214622385863232, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:05,958] Trial 20 finished with value: 0.6286320258174839 and parameters: {'C': 9.976064351843897, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:05,964] Trial 21 finished with value: 0.6274973364878816 and parameters: {'C': 9.588093107461606, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:06,184] Trial 22 finished with value: 0.6244332155697524 and parameters: {'C': 6.940856307979944, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:06,257] Trial 23 finished with value: 0.6272824880255925 and parameters: {'C': 9.4481202064032, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:06,428] Trial 24 finished with value: 0.6311338857757282 and parameters: {'C': 7.527297711424232, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:06,756] Trial 25 finished with value: 0.6249576921994546 and parameters: {'C': 9.174441212258369, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:07,156] Trial 26 finished with value: 0.6286371023617024 and parameters: {'C': 9.322994174303368, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:07,165] Trial 27 finished with value: 0.6286371023617024 and parameters: {'C': 9.282818750990838, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:07,178] Trial 28 finished with value: 0.5734453781512605 and parameters: {'C': 1.8346110204054675, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n",
      "[I 2025-11-13 01:57:07,197] Trial 29 finished with value: 0.5818831828608928 and parameters: {'C': 2.1449697137109744, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.6356177224240719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 8.26845694694628, 'kernel': 'linear', 'gamma': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:57:08,161] A new study created in memory with name: no-name-aca92602-44ba-40ba-801a-53a998405e55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.63      0.66       417\n",
      "           0       0.81      0.88      0.84      1273\n",
      "           1       0.29      0.14      0.19       168\n",
      "\n",
      "    accuracy                           0.76      1858\n",
      "   macro avg       0.59      0.55      0.56      1858\n",
      "weighted avg       0.73      0.76      0.74      1858\n",
      "\n",
      "[[ 263  149    5]\n",
      " [  98 1123   52]\n",
      " [  22  123   23]]\n",
      "---- TF-IDF ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:57:15,893] Trial 3 finished with value: 0.6352366538983385 and parameters: {'C': 8.59045015882756, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6352366538983385.\n",
      "[I 2025-11-13 01:57:18,811] Trial 2 finished with value: 0.6480906603060672 and parameters: {'C': 1.686126762740429, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:19,026] Trial 5 finished with value: 0.6395929445035851 and parameters: {'C': 1.7949434600913086, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:24,900] Trial 6 finished with value: 0.47781320557889617 and parameters: {'C': 6.3202577896582826, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:25,756] Trial 1 finished with value: 0.5256072333453886 and parameters: {'C': 2.0247503945046943, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:26,823] Trial 0 finished with value: 0.5674131569624613 and parameters: {'C': 0.4055603293919751, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:31,269] Trial 9 finished with value: 0.6397206482367274 and parameters: {'C': 7.612152985645162, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:37,813] Trial 4 finished with value: 0.1878249798027268 and parameters: {'C': 0.010622923576836262, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:38,084] Trial 8 finished with value: 0.49018645851805887 and parameters: {'C': 0.422342474180308, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:40,452] Trial 7 finished with value: 0.43790047391071224 and parameters: {'C': 2.7030622039432863, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:41,994] Trial 10 finished with value: 0.5256072333453886 and parameters: {'C': 3.1470866303164873, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:49,960] Trial 12 finished with value: 0.526103062862589 and parameters: {'C': 3.0180197823294566, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:52,662] Trial 15 finished with value: 0.5266547263834559 and parameters: {'C': 8.507306673851769, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:55,968] Trial 16 finished with value: 0.5411992428013165 and parameters: {'C': 0.6883452291235813, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:57:58,745] Trial 13 finished with value: 0.6383022700669115 and parameters: {'C': 0.0438910427552508, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.6480906603060672.\n",
      "[I 2025-11-13 01:58:04,771] Trial 17 finished with value: 0.6708091848923914 and parameters: {'C': 0.057933046878297874, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 17 with value: 0.6708091848923914.\n",
      "[I 2025-11-13 01:58:07,371] Trial 11 finished with value: 0.674375851241936 and parameters: {'C': 0.74595519983088, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 11 with value: 0.674375851241936.\n",
      "[I 2025-11-13 01:58:11,827] Trial 18 finished with value: 0.7065013093953659 and parameters: {'C': 0.08803736481584912, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 18 with value: 0.7065013093953659.\n",
      "[I 2025-11-13 01:58:11,921] Trial 14 finished with value: 0.595900772311704 and parameters: {'C': 0.01961659103730925, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 18 with value: 0.7065013093953659.\n",
      "[I 2025-11-13 01:58:15,112] Trial 20 finished with value: 0.7129642560296644 and parameters: {'C': 0.1009571660498973, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.7129642560296644.\n",
      "[I 2025-11-13 01:58:16,905] Trial 19 finished with value: 0.7124453801645197 and parameters: {'C': 0.0999029368386299, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.7129642560296644.\n",
      "[I 2025-11-13 01:58:18,388] Trial 21 finished with value: 0.70981051455361 and parameters: {'C': 0.08955534197317959, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.7129642560296644.\n",
      "[I 2025-11-13 01:58:20,238] Trial 22 finished with value: 0.7124453801645197 and parameters: {'C': 0.0995382191678469, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.7129642560296644.\n",
      "[I 2025-11-13 01:58:25,417] Trial 23 finished with value: 0.7065866295445536 and parameters: {'C': 0.09351468928385376, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.7129642560296644.\n",
      "[I 2025-11-13 01:58:32,330] Trial 27 finished with value: 0.7010726816030924 and parameters: {'C': 0.13979982347603961, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.7129642560296644.\n",
      "[I 2025-11-13 01:58:35,724] Trial 29 finished with value: 0.7074070979161604 and parameters: {'C': 0.1324219233246027, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.7129642560296644.\n",
      "[I 2025-11-13 01:58:36,733] Trial 28 finished with value: 0.7016205867133912 and parameters: {'C': 0.14489443573163563, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.7129642560296644.\n",
      "[I 2025-11-13 01:58:37,770] Trial 24 finished with value: 0.674375851241936 and parameters: {'C': 0.11805322930155511, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 20 with value: 0.7129642560296644.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(y_test, tfidf_vec_predicted_SVM))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---- TF-IDF ----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m tfidf_vec_predicted_SVM_oversampling\u001b[38;5;241m=\u001b[39m svm(X_train_oversampling_tfidf_vec, X_val_oversampling_tfidf_vec, X_test_oversampling_tfidf_vec, y_train_oversampling, y_val_oversampling, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mclassification_report(y_test_oversampling, tfidf_vec_predicted_SVM_oversampling))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(y_test_oversampling, tfidf_vec_predicted_SVM_oversampling))\n",
      "Cell \u001b[1;32mIn[28], line 27\u001b[0m, in \u001b[0;36msvm\u001b[1;34m(X_train, X_val, X_test, y_train, y_val, n_trials)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msvm\u001b[39m(X_train, X_val, X_test, y_train, y_val, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Chamar o Optuna para otimizar os parâmetros\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     objeto_para_otimizar \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m     objeto_para_otimizar\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, X_train, X_val, y_train, y_val),\n\u001b[0;32m     28\u001b[0m                    n_trials\u001b[38;5;241m=\u001b[39mn_trials, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMelhores hiperparâmetros encontrados:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(objeto_para_otimizar\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32mc:\\Users\\didia\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     _optimize(\n\u001b[0;32m    491\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    492\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    493\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    494\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    495\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    496\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    497\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    498\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    499\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    500\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\didia\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:82\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     79\u001b[0m time_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     80\u001b[0m futures: \u001b[38;5;28mset\u001b[39m[Future] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mn_jobs) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_submitted_trials \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcount():\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_stop_flag:\n",
      "File \u001b[1;32mc:\\Users\\didia\\anaconda3\\Lib\\concurrent\\futures\\_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m--> 647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshutdown(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\didia\\anaconda3\\Lib\\concurrent\\futures\\thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[1;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[1;32m--> 235\u001b[0m         t\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[1;32mc:\\Users\\didia\\anaconda3\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\didia\\anaconda3\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[0;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print (\"---- TF-IDF ----\")\n",
    "tfidf_vec_predicted_SVM= svm(X_train_tfidf_vec, X_val_tfidf_vec, X_test_tfidf_vec, y_train, y_val, n_trials=30) \n",
    "print(metrics.classification_report(y_test, tfidf_vec_predicted_SVM))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_SVM))\n",
    "\n",
    "print (\"---- TF-IDF ----\")\n",
    "tfidf_vec_predicted_SVM_oversampling= svm(X_train_oversampling_tfidf_vec, X_val_oversampling_tfidf_vec, X_test_oversampling_tfidf_vec, y_train_oversampling, y_val_oversampling, n_trials=30) \n",
    "print(metrics.classification_report(y_test_oversampling, tfidf_vec_predicted_SVM_oversampling))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, tfidf_vec_predicted_SVM_oversampling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9f769d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:58:46,111] A new study created in memory with name: no-name-ec09b9b4-2a4e-468d-87f9-a659d39b7e2c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----WORD2VEC ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:58:49,013] Trial 6 finished with value: 0.271047227926078 and parameters: {'C': 0.07187061322314273, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 6 with value: 0.271047227926078.\n",
      "[I 2025-11-13 01:58:49,102] Trial 1 finished with value: 0.271047227926078 and parameters: {'C': 0.37545669617878075, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 6 with value: 0.271047227926078.\n",
      "[I 2025-11-13 01:58:50,609] Trial 5 finished with value: 0.46050810369165934 and parameters: {'C': 2.8951189673999336, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:51,330] Trial 0 finished with value: 0.271047227926078 and parameters: {'C': 0.42492607272941557, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:51,347] Trial 4 finished with value: 0.271047227926078 and parameters: {'C': 0.020508090358132967, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:51,893] Trial 2 finished with value: 0.271047227926078 and parameters: {'C': 0.031106849452012572, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:53,071] Trial 7 finished with value: 0.4074486054463808 and parameters: {'C': 0.4301615519921688, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:53,366] Trial 9 finished with value: 0.2845155664974099 and parameters: {'C': 0.07286796906688998, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:53,382] Trial 8 finished with value: 0.4147461461510045 and parameters: {'C': 0.5358165635359134, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:53,614] Trial 3 finished with value: 0.271047227926078 and parameters: {'C': 0.6350593231043528, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:54,875] Trial 10 finished with value: 0.4496776630676181 and parameters: {'C': 1.2693290221532496, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:56,378] Trial 16 finished with value: 0.271047227926078 and parameters: {'C': 0.21789048679771214, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 5 with value: 0.46050810369165934.\n",
      "[I 2025-11-13 01:58:57,311] Trial 13 finished with value: 0.4632047819849452 and parameters: {'C': 8.890897416545576, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.4632047819849452.\n",
      "[I 2025-11-13 01:58:57,445] Trial 15 finished with value: 0.271047227926078 and parameters: {'C': 0.014541304878751797, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.4632047819849452.\n",
      "[I 2025-11-13 01:58:58,311] Trial 11 finished with value: 0.46324882359738145 and parameters: {'C': 3.5285420036213524, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 11 with value: 0.46324882359738145.\n",
      "[I 2025-11-13 01:58:58,840] Trial 12 finished with value: 0.271047227926078 and parameters: {'C': 4.373027985195138, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 11 with value: 0.46324882359738145.\n",
      "[I 2025-11-13 01:59:00,796] Trial 18 finished with value: 0.468064452145099 and parameters: {'C': 5.017932561667569, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 18 with value: 0.468064452145099.\n",
      "[I 2025-11-13 01:59:01,136] Trial 14 finished with value: 0.271047227926078 and parameters: {'C': 0.02949249208655769, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 18 with value: 0.468064452145099.\n",
      "[I 2025-11-13 01:59:01,487] Trial 17 finished with value: 0.4632047819849452 and parameters: {'C': 8.504138819718023, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 18 with value: 0.468064452145099.\n",
      "[I 2025-11-13 01:59:01,577] Trial 19 finished with value: 0.468064452145099 and parameters: {'C': 4.840172573212314, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 18 with value: 0.468064452145099.\n",
      "[I 2025-11-13 01:59:02,834] Trial 20 finished with value: 0.4632047819849452 and parameters: {'C': 8.17316499100988, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 18 with value: 0.468064452145099.\n",
      "[I 2025-11-13 01:59:03,359] Trial 21 finished with value: 0.46821727999611734 and parameters: {'C': 9.871815641594475, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n",
      "[I 2025-11-13 01:59:05,354] Trial 22 finished with value: 0.46488413547237073 and parameters: {'C': 9.244976892938615, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n",
      "[I 2025-11-13 01:59:05,403] Trial 23 finished with value: 0.46488413547237073 and parameters: {'C': 9.312552602275705, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n",
      "[I 2025-11-13 01:59:05,413] Trial 27 finished with value: 0.4571547342365323 and parameters: {'C': 1.4649232156732388, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n",
      "[I 2025-11-13 01:59:06,069] Trial 25 finished with value: 0.46176812803231543 and parameters: {'C': 2.090862932289729, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n",
      "[I 2025-11-13 01:59:06,152] Trial 24 finished with value: 0.46488413547237073 and parameters: {'C': 9.689646090346553, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n",
      "[I 2025-11-13 01:59:06,190] Trial 26 finished with value: 0.45995024145610586 and parameters: {'C': 1.919852531860518, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n",
      "[I 2025-11-13 01:59:06,545] Trial 28 finished with value: 0.46176812803231543 and parameters: {'C': 2.105600107317015, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n",
      "[I 2025-11-13 01:59:06,752] Trial 29 finished with value: 0.4598756684239366 and parameters: {'C': 1.6633500044498513, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.46821727999611734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 9.871815641594475, 'kernel': 'linear', 'gamma': 'scale'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "[I 2025-11-13 01:59:09,781] A new study created in memory with name: no-name-07f4aa2c-5713-4e1c-8a93-5b7f61d79f55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.37      0.46       417\n",
      "           0       0.74      0.93      0.83      1273\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.72      1858\n",
      "   macro avg       0.44      0.43      0.43      1858\n",
      "weighted avg       0.64      0.72      0.67      1858\n",
      "\n",
      "[[ 155  262    0]\n",
      " [  86 1187    0]\n",
      " [  22  146    0]]\n",
      "C/ oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:59:44,201] Trial 1 finished with value: 0.6035837021889409 and parameters: {'C': 0.4288125541741209, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 01:59:53,631] Trial 7 finished with value: 0.5548040892811187 and parameters: {'C': 0.9367374235572089, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 01:59:55,874] Trial 6 finished with value: 0.16666666666666666 and parameters: {'C': 0.5813849136939024, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 01:59:56,483] Trial 3 finished with value: 0.5694246468847518 and parameters: {'C': 0.28598963655566506, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 01:59:58,507] Trial 5 finished with value: 0.548775617422446 and parameters: {'C': 5.200370753016041, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:01,279] Trial 2 finished with value: 0.439868177924623 and parameters: {'C': 1.68627402189971, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:14,904] Trial 4 finished with value: 0.5646084771489432 and parameters: {'C': 0.09286667548414648, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:21,601] Trial 0 finished with value: 0.22326636747192774 and parameters: {'C': 0.03485396049083614, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:31,199] Trial 13 finished with value: 0.5670221413605853 and parameters: {'C': 2.2460583235296108, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:38,591] Trial 8 finished with value: 0.5185310872928137 and parameters: {'C': 0.038411611477595885, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:40,788] Trial 12 finished with value: 0.5295220680396318 and parameters: {'C': 0.028804470737045344, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:45,993] Trial 10 finished with value: 0.5087917137901422 and parameters: {'C': 3.225128361438443, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:51,297] Trial 9 finished with value: 0.16666666666666666 and parameters: {'C': 0.09033359231774371, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:52,719] Trial 15 finished with value: 0.5113379965410694 and parameters: {'C': 8.213243811663586, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:53,186] Trial 11 finished with value: 0.1988086720778064 and parameters: {'C': 0.11657205880845807, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 1 with value: 0.6035837021889409.\n",
      "[I 2025-11-13 02:00:58,416] Trial 14 finished with value: 0.6161263775873486 and parameters: {'C': 1.2815684820923778, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:01:22,978] Trial 16 finished with value: 0.5602168858565495 and parameters: {'C': 0.08711348343711843, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:01:24,499] Trial 19 finished with value: 0.5920861905464753 and parameters: {'C': 0.22712032392992654, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:01:25,262] Trial 17 finished with value: 0.2214015711298869 and parameters: {'C': 0.010708721785856504, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:01:29,158] Trial 18 finished with value: 0.16666666666666666 and parameters: {'C': 0.21515483770513588, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:01:42,293] Trial 20 finished with value: 0.570938694944971 and parameters: {'C': 0.18585496866575568, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:01:44,589] Trial 22 finished with value: 0.5686257009054082 and parameters: {'C': 0.23745080852773248, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:01:56,312] Trial 23 finished with value: 0.42760821685069145 and parameters: {'C': 0.28543932849702114, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:01:59,764] Trial 21 finished with value: 0.1988086720778064 and parameters: {'C': 0.23746917547530466, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:02:03,033] Trial 25 finished with value: 0.46644732454666205 and parameters: {'C': 0.6172975049640759, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:02:03,156] Trial 26 finished with value: 0.47055657052261085 and parameters: {'C': 0.7090515937561572, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:02:03,271] Trial 24 finished with value: 0.42960680380749244 and parameters: {'C': 0.33858206352574854, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 14 with value: 0.6161263775873486.\n",
      "[I 2025-11-13 02:02:04,723] Trial 27 finished with value: 0.6165810686883705 and parameters: {'C': 0.6687703852448794, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 27 with value: 0.6165810686883705.\n",
      "[I 2025-11-13 02:02:11,103] Trial 28 finished with value: 0.6289867190467779 and parameters: {'C': 0.6395215591998831, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 28 with value: 0.6289867190467779.\n",
      "[I 2025-11-13 02:02:11,616] Trial 29 finished with value: 0.628445351302538 and parameters: {'C': 0.6274963606452174, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 28 with value: 0.6289867190467779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 0.6395215591998831, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.56      0.59      1273\n",
      "           0       0.47      0.73      0.57      1273\n",
      "           1       0.55      0.31      0.40      1273\n",
      "\n",
      "    accuracy                           0.53      3819\n",
      "   macro avg       0.55      0.53      0.52      3819\n",
      "weighted avg       0.55      0.53      0.52      3819\n",
      "\n",
      "[[718 407 148]\n",
      " [178 925 170]\n",
      " [254 624 395]]\n"
     ]
    }
   ],
   "source": [
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_SVM= svm(X_train_word2vec, X_val_word2vec, X_test_word2vec, y_train, y_val, n_trials=30) \n",
    "print(metrics.classification_report(y_test, word2vec_predicted_SVM))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_SVM))\n",
    "\n",
    "print (\"C/ oversampling\")\n",
    "word2vec_predicted_SVM_oversampling= svm(X_train_oversampling_word2vec, X_val_oversampling_word2vec, X_test_oversampling_word2vec, y_train_oversampling, y_val_oversampling, n_trials=30) \n",
    "print(metrics.classification_report(y_test_oversampling, word2vec_predicted_SVM_oversampling))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, word2vec_predicted_SVM_oversampling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e589a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 02:02:23,149] A new study created in memory with name: no-name-caaaacff-4eee-46a0-8d5a-564ee4bc789c\n",
      "[I 2025-11-13 02:02:27,384] Trial 5 finished with value: 0.49823426290894046 and parameters: {'C': 0.32997100246459843, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.49823426290894046.\n",
      "[I 2025-11-13 02:02:29,452] Trial 3 finished with value: 0.42679952550415184 and parameters: {'C': 0.6216029700021876, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 5 with value: 0.49823426290894046.\n",
      "[I 2025-11-13 02:02:29,860] Trial 6 finished with value: 0.41787638113991904 and parameters: {'C': 0.44537311508120203, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 5 with value: 0.49823426290894046.\n",
      "[I 2025-11-13 02:02:31,812] Trial 4 finished with value: 0.43993691493691495 and parameters: {'C': 2.0396742409740773, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 5 with value: 0.49823426290894046.\n",
      "[I 2025-11-13 02:02:31,892] Trial 9 finished with value: 0.34992640376029355 and parameters: {'C': 0.016019589927845836, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 5 with value: 0.49823426290894046.\n",
      "[I 2025-11-13 02:02:32,267] Trial 8 finished with value: 0.42598614595269807 and parameters: {'C': 0.697794598708643, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 5 with value: 0.49823426290894046.\n",
      "[I 2025-11-13 02:02:35,119] Trial 12 finished with value: 0.32098044682049015 and parameters: {'C': 0.010693921531203332, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 5 with value: 0.49823426290894046.\n",
      "[I 2025-11-13 02:02:36,073] Trial 11 finished with value: 0.4150971299396833 and parameters: {'C': 0.30413396070670357, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 5 with value: 0.49823426290894046.\n",
      "[I 2025-11-13 02:02:40,465] Trial 0 finished with value: 0.5040532236717716 and parameters: {'C': 0.05282277305231815, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.5040532236717716.\n",
      "[I 2025-11-13 02:02:41,003] Trial 7 finished with value: 0.5040532236717716 and parameters: {'C': 0.051435803299691524, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 0.5040532236717716.\n",
      "[I 2025-11-13 02:02:43,137] Trial 16 finished with value: 0.48259986969015634 and parameters: {'C': 0.0981899651071717, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5040532236717716.\n",
      "[I 2025-11-13 02:02:56,526] Trial 17 finished with value: 0.5036359013475719 and parameters: {'C': 0.06325703319307444, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.5040532236717716.\n",
      "[I 2025-11-13 02:02:56,768] Trial 13 finished with value: 0.5115167366396388 and parameters: {'C': 0.27976692790873015, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 13 with value: 0.5115167366396388.\n",
      "[I 2025-11-13 02:02:57,537] Trial 18 finished with value: 0.5040532236717716 and parameters: {'C': 0.0528233233625137, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 13 with value: 0.5115167366396388.\n",
      "[I 2025-11-13 02:02:57,709] Trial 1 finished with value: 0.5148921149009399 and parameters: {'C': 0.3706146528436145, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.5148921149009399.\n",
      "[I 2025-11-13 02:03:10,612] Trial 19 finished with value: 0.5040532236717716 and parameters: {'C': 0.05057151464989182, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.5148921149009399.\n",
      "[I 2025-11-13 02:03:22,997] Trial 20 finished with value: 0.5066556882118841 and parameters: {'C': 0.15732971796590117, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.5148921149009399.\n",
      "[I 2025-11-13 02:03:44,109] Trial 15 finished with value: 0.5083467584429627 and parameters: {'C': 1.267087500727822, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.5148921149009399.\n"
     ]
    }
   ],
   "source": [
    "#word2vec treinado com os nossos dados\n",
    "word2vec_trained_predicted_svm= svm(X_train_w2v_trained, X_val_w2v_trained, X_test_w2v_trained, y_train, y_val, n_trials=30) \n",
    "print(metrics.classification_report(y_test, word2vec_trained_predicted_svm))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_trained_predicted_svm))\n",
    "\n",
    "print(\"oversampling\")\n",
    "word2vec_trained_predicted_svm_over= svm(X_train_over_w2v_trained, X_val_over_w2v_trained, X_test_over_w2v_trained, y_train_oversampling, y_val_oversampling, n_trials=30) \n",
    "print(metrics.classification_report(y_test_oversampling, word2vec_trained_predicted_svm_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, word2vec_trained_predicted_svm_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"----GLOVE ----\")\n",
    "glove_predicted_SVM= svm(X_train_glove, X_val_glove, X_test_glove, y_train, y_val, n_trials=30) \n",
    "print(metrics.classification_report(y_test, glove_predicted_SVM))\n",
    "print(metrics.confusion_matrix(y_test, glove_predicted_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791a4e1",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def KNN(X_train, y_train, X_val, y_val, X_test):\n",
    "    k_values = range(1, 200,10)  # Determinar  intervalo de valores a testar para k\n",
    "    best_k = 1\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    k_list = []\n",
    "    accuracy_list = [] \n",
    "\n",
    "    for k in k_values:\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)  \n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_KNN = knn.predict(X_val) \n",
    "        accuracy = accuracy_score(y_val, y_pred_KNN)  \n",
    "\n",
    "        k_list.append(k)\n",
    "        accuracy_list.append(accuracy)  \n",
    "\n",
    "        if accuracy > best_accuracy: \n",
    "            best_accuracy = accuracy\n",
    "            best_k = k\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k)  \n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_KNN= knn.predict(X_test) \n",
    "    print(f\"Best k: {best_k}\")\n",
    "\n",
    "    return y_pred_KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fead510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Best k: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.60      0.66       417\n",
      "           0       0.79      0.94      0.85      1273\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.78      1858\n",
      "   macro avg       0.51      0.51      0.51      1858\n",
      "weighted avg       0.70      0.78      0.73      1858\n",
      "\n",
      "[[ 250  167    0]\n",
      " [  80 1193    0]\n",
      " [   9  159    0]]\n",
      "c/ oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.76      0.62      1273\n",
      "           0       0.46      0.63      0.54      1273\n",
      "           1       0.55      0.11      0.18      1273\n",
      "\n",
      "    accuracy                           0.50      3819\n",
      "   macro avg       0.51      0.50      0.44      3819\n",
      "weighted avg       0.51      0.50      0.44      3819\n",
      "\n",
      "[[965 265  43]\n",
      " [401 806  66]\n",
      " [473 665 135]]\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_KNN= KNN(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "print(metrics.classification_report(y_test, count_vec_predicted_KNN))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_KNN))\n",
    "\n",
    "print (\"c/ oversampling\")\n",
    "count_vec_predicted_KNN_oversampling= KNN(X_train_oversampling_count_vec, y_train_oversampling, X_val_oversampling_count_vec, y_val_oversampling, X_test_oversampling_count_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, count_vec_predicted_KNN_oversampling))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, count_vec_predicted_KNN_oversampling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----TF-IDF ----\n",
      "Best k: 181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.60      0.66       417\n",
      "           0       0.79      0.94      0.86      1273\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.78      1858\n",
      "   macro avg       0.51      0.51      0.51      1858\n",
      "weighted avg       0.71      0.78      0.74      1858\n",
      "\n",
      "[[ 251  166    0]\n",
      " [  78 1195    0]\n",
      " [   9  159    0]]\n",
      "c/oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.76      0.76      1273\n",
      "           0       0.53      0.70      0.60      1273\n",
      "           1       0.60      0.40      0.48      1273\n",
      "\n",
      "    accuracy                           0.62      3819\n",
      "   macro avg       0.62      0.62      0.61      3819\n",
      "weighted avg       0.62      0.62      0.61      3819\n",
      "\n",
      "[[973 179 121]\n",
      " [162 889 222]\n",
      " [169 599 505]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "print (\"----TF-IDF ----\")\n",
    "tfidf_vec_predicted_KNN= KNN(X_train_tfidf_vec, y_train, X_val_tfidf_vec, y_val, X_test_tfidf_vec) \n",
    "print(metrics.classification_report(y_test, tfidf_vec_predicted_KNN))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_KNN))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "tfidf_vec_predicted_KNN_oversampling= KNN(X_train_oversampling_tfidf_vec, y_train_oversampling, X_val_oversampling_tfidf_vec, y_val_oversampling, X_test_oversampling_tfidf_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, tfidf_vec_predicted_KNN_oversampling))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, tfidf_vec_predicted_KNN_oversampling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3c7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----WORD2VEC ----\n",
      "Best k: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.27      0.37       417\n",
      "           0       0.73      0.95      0.82      1273\n",
      "           1       0.20      0.01      0.02       168\n",
      "\n",
      "    accuracy                           0.71      1858\n",
      "   macro avg       0.51      0.41      0.41      1858\n",
      "weighted avg       0.65      0.71      0.65      1858\n",
      "\n",
      "[[ 112  304    1]\n",
      " [  56 1210    7]\n",
      " [  13  153    2]]\n",
      "c/oversampling\n",
      "Best k: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.47      0.50      1273\n",
      "           0       0.48      0.39      0.43      1273\n",
      "           1       0.41      0.53      0.46      1273\n",
      "\n",
      "    accuracy                           0.46      3819\n",
      "   macro avg       0.47      0.46      0.46      3819\n",
      "weighted avg       0.47      0.46      0.46      3819\n",
      "\n",
      "[[597 202 474]\n",
      " [252 496 525]\n",
      " [258 335 680]]\n"
     ]
    }
   ],
   "source": [
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_KNN= KNN(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "print(metrics.classification_report(y_test, word2vec_predicted_KNN))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_KNN))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "word2vec_predicted_KNN_oversampling= KNN(X_train_oversampling_word2vec, y_train_oversampling, X_val_oversampling_word2vec, y_val_oversampling, X_test_oversampling_word2vec) \n",
    "print(metrics.classification_report(y_test_oversampling, word2vec_predicted_KNN_oversampling))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, word2vec_predicted_KNN_oversampling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove\n",
    "print (\"----GLOVE ----\")\n",
    "glove_predicted_KNN= KNN(X_train_glove, y_train, X_val_glove, y_val, X_test_glove) \n",
    "print(metrics.classification_report(y_test, glove_predicted_KNN))\n",
    "print(metrics.confusion_matrix(y_test, glove_predicted_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49589df2",
   "metadata": {},
   "source": [
    "## Decison Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar um classificador de árvore de decisão baseado em entropia\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree(X_train, y_train, X_val, y_val, X_test):\n",
    "    alphas = np.linspace(0.000, 0.01, 20)  # Testar 20 valores entre 0 e 0.01\n",
    "    best_alpha = 0\n",
    "    best_acc = 0\n",
    "\n",
    "    for alpha in alphas:\n",
    "        clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_val = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_alpha = alpha\n",
    "\n",
    "    print(f\"Melhor alpha: {best_alpha:.4f} \")\n",
    "\n",
    "    # Treinar modelo final com o melhor alpha\n",
    "    final_clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=best_alpha, random_state=42)\n",
    "    final_clf.fit(X_train, y_train)\n",
    "    y_pred_test = final_clf.predict(X_test)\n",
    "\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b899214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Melhor alpha: 0.0021 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.63      0.68       417\n",
      "           0       0.80      0.91      0.85      1273\n",
      "           1       0.21      0.04      0.07       168\n",
      "\n",
      "    accuracy                           0.77      1858\n",
      "   macro avg       0.58      0.53      0.53      1858\n",
      "weighted avg       0.73      0.77      0.74      1858\n",
      "\n",
      "[[ 264  149    4]\n",
      " [  87 1163   23]\n",
      " [  11  150    7]]\n",
      "c/oversampling\n",
      "Melhor alpha: 0.0032 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.69      0.74      1273\n",
      "           0       0.50      0.54      0.52      1273\n",
      "           1       0.52      0.56      0.54      1273\n",
      "\n",
      "    accuracy                           0.60      3819\n",
      "   macro avg       0.61      0.60      0.60      3819\n",
      "weighted avg       0.61      0.60      0.60      3819\n",
      "\n",
      "[[882 223 168]\n",
      " [117 683 473]\n",
      " [107 458 708]]\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_DT= decision_tree(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "print(metrics.classification_report(y_test, count_vec_predicted_DT))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_DT))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "count_vec_predicted_DT_oversampling= decision_tree(X_train_oversampling_count_vec, y_train_oversampling, X_val_oversampling_count_vec, y_val_oversampling, X_test_oversampling_count_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, count_vec_predicted_DT_oversampling))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, count_vec_predicted_DT_oversampling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b119b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----TF-IDF ----\n",
      "Melhor alpha: 0.0032 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.66      0.67       417\n",
      "           0       0.80      0.91      0.85      1273\n",
      "           1       0.40      0.01      0.02       168\n",
      "\n",
      "    accuracy                           0.77      1858\n",
      "   macro avg       0.63      0.53      0.51      1858\n",
      "weighted avg       0.73      0.77      0.73      1858\n",
      "\n",
      "[[ 274  142    1]\n",
      " [ 115 1156    2]\n",
      " [  12  154    2]]\n",
      "c/oversampling\n",
      "Melhor alpha: 0.0089 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.67      0.74      1273\n",
      "           0       0.61      0.26      0.36      1273\n",
      "           1       0.45      0.80      0.58      1273\n",
      "\n",
      "    accuracy                           0.58      3819\n",
      "   macro avg       0.63      0.58      0.56      3819\n",
      "weighted avg       0.63      0.58      0.56      3819\n",
      "\n",
      "[[ 855   28  390]\n",
      " [ 103  328  842]\n",
      " [  69  183 1021]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "print (\"----TF-IDF ----\")\n",
    "tfidf_vec_predicted_DT= decision_tree(X_train_tfidf_vec, y_train, X_val_tfidf_vec, y_val, X_test_tfidf_vec) \n",
    "print(metrics.classification_report(y_test, tfidf_vec_predicted_DT))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_DT))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "tfidf_vec_predicted_DT_oversampling= decision_tree(X_train_oversampling_tfidf_vec, y_train_oversampling, X_val_oversampling_tfidf_vec, y_val_oversampling, X_test_oversampling_tfidf_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, tfidf_vec_predicted_DT_oversampling))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, tfidf_vec_predicted_DT_oversampling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----WORD2VEC ----\n",
      "Melhor alpha: 0.0047 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.30      0.35       417\n",
      "           0       0.72      0.88      0.79      1273\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.67      1858\n",
      "   macro avg       0.38      0.39      0.38      1858\n",
      "weighted avg       0.59      0.67      0.62      1858\n",
      "\n",
      "[[ 126  291    0]\n",
      " [ 153 1120    0]\n",
      " [  26  142    0]]\n",
      "c/oversampling\n",
      "Melhor alpha: 0.0037 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.42      0.49      0.46      1273\n",
      "           0       0.39      0.53      0.45      1273\n",
      "           1       0.42      0.19      0.26      1273\n",
      "\n",
      "    accuracy                           0.41      3819\n",
      "   macro avg       0.41      0.41      0.39      3819\n",
      "weighted avg       0.41      0.41      0.39      3819\n",
      "\n",
      "[[630 492 151]\n",
      " [410 679 184]\n",
      " [453 579 241]]\n"
     ]
    }
   ],
   "source": [
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_DT= decision_tree(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "print(metrics.classification_report(y_test, word2vec_predicted_DT))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_DT))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "word2vec_predicted_DT_over= decision_tree(X_train_oversampling_word2vec, y_train_oversampling, X_val_oversampling_word2vec, y_val_oversampling, X_test_oversampling_word2vec) \n",
    "print(metrics.classification_report(y_test_oversampling, word2vec_predicted_DT_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, word2vec_predicted_DT_over))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove\n",
    "print (\"---- GLOVE ----\")\n",
    "glove_predicted_DT= decision_tree(X_train_glove, y_train, X_val_glove, y_val, X_test_glove) \n",
    "print(metrics.classification_report(y_test, glove_predicted_DT))\n",
    "print(metrics.confusion_matrix(y_test, glove_predicted_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b484c",
   "metadata": {},
   "source": [
    "## Random Florest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a7257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, make_scorer\n",
    "\n",
    "def objective(X_train, y_train, X_val, y_val, trial):\n",
    "    n_estimators = trial.suggest_categorical('n_estimators', [50, 100, 200, 300])\n",
    "    max_depth = trial.suggest_categorical('max_depth', [5, 10, 15, 20])\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        max_features=max_features,\n",
    "        criterion=criterion,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predictions_rf = clf.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, predictions_rf, pos_label=1,average='macro')\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def random_florest(X_train, y_train, X_val, y_val, X_test):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(X_train, y_train, X_val, y_val, trial),\n",
    "                   n_trials=50, n_jobs=-1)\n",
    "\n",
    "    print(\"Melhores hiperparâmetros Random Forest:\")\n",
    "    print(study.best_params)\n",
    "\n",
    "    best_rf = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions_rf = best_rf.predict(X_test)\n",
    "    \n",
    "    return predictions_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1030113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:43:51,007] A new study created in memory with name: no-name-a459fa79-5b88-45fb-9c47-6506fa72bbf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:43:52,214] Trial 1 finished with value: 0.27818696949559824 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 1 with value: 0.27818696949559824.\n",
      "[I 2025-11-13 01:43:52,251] Trial 3 finished with value: 0.27818696949559824 and parameters: {'n_estimators': 50, 'max_depth': 15, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 1 with value: 0.27818696949559824.\n",
      "[I 2025-11-13 01:43:52,788] Trial 5 finished with value: 0.271047227926078 and parameters: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 1 with value: 0.27818696949559824.\n",
      "[I 2025-11-13 01:43:53,166] Trial 4 finished with value: 0.38263800100197937 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.38263800100197937.\n",
      "[I 2025-11-13 01:43:53,705] Trial 9 finished with value: 0.271047227926078 and parameters: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 4 with value: 0.38263800100197937.\n",
      "[I 2025-11-13 01:43:54,022] Trial 10 finished with value: 0.271047227926078 and parameters: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.38263800100197937.\n",
      "[I 2025-11-13 01:43:54,121] Trial 0 finished with value: 0.271047227926078 and parameters: {'n_estimators': 200, 'max_depth': 5, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.38263800100197937.\n",
      "[I 2025-11-13 01:43:55,164] Trial 13 finished with value: 0.271047227926078 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 4 with value: 0.38263800100197937.\n",
      "[I 2025-11-13 01:43:55,538] Trial 14 finished with value: 0.4063033920799426 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 14 with value: 0.4063033920799426.\n",
      "[I 2025-11-13 01:43:55,810] Trial 15 finished with value: 0.271047227926078 and parameters: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 14 with value: 0.4063033920799426.\n",
      "[I 2025-11-13 01:43:56,626] Trial 16 finished with value: 0.271047227926078 and parameters: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 14 with value: 0.4063033920799426.\n",
      "[I 2025-11-13 01:43:57,496] Trial 12 finished with value: 0.271047227926078 and parameters: {'n_estimators': 300, 'max_depth': 5, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 14 with value: 0.4063033920799426.\n",
      "[I 2025-11-13 01:43:59,278] Trial 2 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:43:59,610] Trial 18 finished with value: 0.39407253647004553 and parameters: {'n_estimators': 300, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:02,444] Trial 8 finished with value: 0.5523313947556372 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'entropy'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:02,532] Trial 7 finished with value: 0.5154379437209574 and parameters: {'n_estimators': 200, 'max_depth': 5, 'max_features': None, 'criterion': 'entropy'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:03,012] Trial 6 finished with value: 0.529512057524579 and parameters: {'n_estimators': 100, 'max_depth': 10, 'max_features': None, 'criterion': 'entropy'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:04,200] Trial 11 finished with value: 0.552780640193783 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:08,912] Trial 22 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:10,621] Trial 23 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:10,714] Trial 25 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:11,088] Trial 24 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:15,317] Trial 26 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:17,299] Trial 28 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:18,606] Trial 27 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:18,940] Trial 29 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:21,805] Trial 30 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:23,874] Trial 31 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:26,066] Trial 21 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:27,071] Trial 32 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:31,822] Trial 20 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:35,003] Trial 19 finished with value: 0.539847730265041 and parameters: {'n_estimators': 200, 'max_depth': 15, 'max_features': None, 'criterion': 'entropy'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:36,196] Trial 17 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:43,150] Trial 38 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:43,387] Trial 40 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:44,646] Trial 39 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:45,297] Trial 43 finished with value: 0.46706294618254934 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:49,818] Trial 44 finished with value: 0.5309265725476665 and parameters: {'n_estimators': 50, 'max_depth': 10, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:50,599] Trial 42 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:51,311] Trial 41 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:51,859] Trial 35 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:54,756] Trial 33 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:57,553] Trial 46 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:58,015] Trial 45 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:44:58,143] Trial 48 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:45:01,370] Trial 49 finished with value: 0.5546148570120941 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:45:02,027] Trial 34 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:45:05,345] Trial 36 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:45:09,378] Trial 37 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n",
      "[I 2025-11-13 01:45:15,431] Trial 47 finished with value: 0.5541728055389257 and parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.5546148570120941.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros Random Forest:\n",
      "{'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:45:18,169] A new study created in memory with name: no-name-7e79c942-d2c7-4eec-8a3e-9e0f74a6561e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.64      0.70       417\n",
      "           0       0.80      0.94      0.86      1273\n",
      "           1       0.36      0.02      0.04       168\n",
      "\n",
      "    accuracy                           0.79      1858\n",
      "   macro avg       0.64      0.53      0.54      1858\n",
      "weighted avg       0.75      0.79      0.75      1858\n",
      "\n",
      "[[ 266  150    1]\n",
      " [  70 1197    6]\n",
      " [   8  156    4]]\n",
      "c/oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:45:19,943] Trial 3 finished with value: 0.6992281720698618 and parameters: {'n_estimators': 200, 'max_depth': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:20,427] Trial 7 finished with value: 0.6860094103376161 and parameters: {'n_estimators': 200, 'max_depth': 15, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:20,801] Trial 9 finished with value: 0.6664953691346399 and parameters: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:21,196] Trial 8 finished with value: 0.6578222288752466 and parameters: {'n_estimators': 100, 'max_depth': 20, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:24,191] Trial 10 finished with value: 0.654196321436459 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:28,059] Trial 12 finished with value: 0.6601176524071772 and parameters: {'n_estimators': 300, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:33,935] Trial 0 finished with value: 0.6075828968513924 and parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:36,294] Trial 13 finished with value: 0.5568851118972453 and parameters: {'n_estimators': 100, 'max_depth': 5, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:38,773] Trial 5 finished with value: 0.5589272134220669 and parameters: {'n_estimators': 300, 'max_depth': 5, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:40,100] Trial 16 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:40,845] Trial 15 finished with value: 0.6601176524071772 and parameters: {'n_estimators': 300, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:41,994] Trial 18 finished with value: 0.6799564666522554 and parameters: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:42,394] Trial 6 finished with value: 0.5589272134220669 and parameters: {'n_estimators': 300, 'max_depth': 5, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:42,423] Trial 17 finished with value: 0.6622559128662592 and parameters: {'n_estimators': 200, 'max_depth': 10, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:44,026] Trial 21 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:44,981] Trial 19 finished with value: 0.671199338782714 and parameters: {'n_estimators': 200, 'max_depth': 10, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:45,361] Trial 20 finished with value: 0.671199338782714 and parameters: {'n_estimators': 200, 'max_depth': 10, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:46,164] Trial 22 finished with value: 0.687112950086398 and parameters: {'n_estimators': 200, 'max_depth': 5, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:46,282] Trial 4 finished with value: 0.5971995589385982 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': None, 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:46,453] Trial 23 finished with value: 0.663544734349287 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:46,548] Trial 24 finished with value: 0.6489380120931793 and parameters: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:47,090] Trial 26 finished with value: 0.6459134651138577 and parameters: {'n_estimators': 50, 'max_depth': 15, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:47,202] Trial 27 finished with value: 0.6143485637120968 and parameters: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:47,712] Trial 25 finished with value: 0.663544734349287 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:48,467] Trial 28 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:48,853] Trial 29 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:49,046] Trial 30 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:49,464] Trial 31 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:50,024] Trial 1 finished with value: 0.6120988793780723 and parameters: {'n_estimators': 100, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:50,558] Trial 32 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:50,923] Trial 33 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:54,133] Trial 34 finished with value: 0.654196321436459 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:54,275] Trial 35 finished with value: 0.654196321436459 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:54,567] Trial 38 finished with value: 0.6672652922303808 and parameters: {'n_estimators': 200, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:55,146] Trial 36 finished with value: 0.654196321436459 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:55,817] Trial 37 finished with value: 0.654196321436459 and parameters: {'n_estimators': 200, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:56,273] Trial 40 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:56,436] Trial 39 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:56,677] Trial 41 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:45:59,751] Trial 14 finished with value: 0.5554505628801922 and parameters: {'n_estimators': 300, 'max_depth': 5, 'max_features': None, 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:03,429] Trial 47 finished with value: 0.5568851118972453 and parameters: {'n_estimators': 50, 'max_depth': 5, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:03,760] Trial 44 finished with value: 0.5568851118972453 and parameters: {'n_estimators': 100, 'max_depth': 5, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:05,129] Trial 48 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:05,368] Trial 49 finished with value: 0.6896320647596892 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:18,478] Trial 46 finished with value: 0.5589272134220669 and parameters: {'n_estimators': 300, 'max_depth': 5, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:21,603] Trial 45 finished with value: 0.5589272134220669 and parameters: {'n_estimators': 300, 'max_depth': 5, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:23,650] Trial 42 finished with value: 0.5971995589385982 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': None, 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:26,608] Trial 43 finished with value: 0.5971995589385982 and parameters: {'n_estimators': 100, 'max_depth': 15, 'max_features': None, 'criterion': 'entropy'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:34,213] Trial 11 finished with value: 0.5930214427608324 and parameters: {'n_estimators': 300, 'max_depth': 15, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n",
      "[I 2025-11-13 01:46:44,196] Trial 2 finished with value: 0.6122287581310842 and parameters: {'n_estimators': 300, 'max_depth': 20, 'max_features': None, 'criterion': 'gini'}. Best is trial 3 with value: 0.6992281720698618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros Random Forest:\n",
      "{'n_estimators': 200, 'max_depth': 5, 'max_features': 'sqrt', 'criterion': 'gini'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.74      0.75      1273\n",
      "           0       0.50      0.76      0.61      1273\n",
      "           1       0.69      0.37      0.48      1273\n",
      "\n",
      "    accuracy                           0.62      3819\n",
      "   macro avg       0.66      0.62      0.61      3819\n",
      "weighted avg       0.66      0.62      0.61      3819\n",
      "\n",
      "[[942 296  35]\n",
      " [133 965 175]\n",
      " [149 653 471]]\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_RF= random_florest(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "print(metrics.classification_report(y_test, count_vec_predicted_RF))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_RF))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "count_vec_predicted_RF_over= random_florest(X_train_oversampling_count_vec, y_train_oversampling, X_val_oversampling_count_vec, y_val_oversampling, X_test_oversampling_count_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, count_vec_predicted_RF_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, count_vec_predicted_RF_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80463ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "print (\"----TF-IDF ----\")\n",
    "tfidf_vec_predicted_RF= random_florest(X_train_tfidf_vec, y_train, X_val_tfidf_vec, y_val, X_test_tfidf_vec) \n",
    "print(metrics.classification_report(y_test, tfidf_vec_predicted_RF))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_RF))\n",
    "\n",
    "#TF-IDF\n",
    "print (\"c/oversampling\")\n",
    "tfidf_vec_predicted_RF_over= random_florest(X_train_oversampling_tfidf_vec, y_train_oversampling, X_val_oversampling_tfidf_vec, y_val_oversampling, X_test_oversampling_tfidf_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, tfidf_vec_predicted_RF_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, tfidf_vec_predicted_RF_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_RF= random_florest(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "print(metrics.classification_report(y_test, word2vec_predicted_RF))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_RF))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "word2vec_predicted_RF_over= random_florest(X_train_oversampling_word2vec, y_train_oversampling, X_val_oversampling_word2vec, y_val_oversampling, X_test_oversampling_word2vec) \n",
    "print(metrics.classification_report(y_test_oversampling, word2vec_predicted_RF_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, word2vec_predicted_RF_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove\n",
    "print (\"---- GLOVE ----\")\n",
    "glove_predicted_DT= random_florest(X_train_glove, y_train, X_val_glove, y_val, X_test_glove, y_test) \n",
    "print(metrics.classification_report(y_test, glove_predicted_DT))\n",
    "print(metrics.confusion_matrix(y_test, glove_predicted_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01765274",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a144959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "\n",
    "def objective(X_train, y_train, X_val, y_val, trial):\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (100, 50)])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "    learning_rate_init = trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True)\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_val)\n",
    "    f1 = f1_score(y_val, preds, average='macro')\n",
    "    return f1\n",
    "\n",
    "def neural_network (X_train, y_train, X_val, y_val, X_test):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(X_train, y_train, X_val, y_val, trial), n_trials=30)\n",
    "    print(\"Melhores parâmetros:\", study.best_params)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_model = MLPClassifier(\n",
    "        hidden_layer_sizes=best_params['hidden_layer_sizes'],\n",
    "        activation=best_params['activation'],\n",
    "        learning_rate_init=best_params['learning_rate_init'],\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    previsoes = best_model.predict(X_test)\n",
    "    \n",
    "    return previsoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0898740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_NN= neural_network(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "print(metrics.classification_report(y_test, count_vec_predicted_NN))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_NN))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "count_vec_predicted_NN_over= neural_network(X_train_oversampling_count_vec, y_train_oversampling, X_val_oversampling_count_vec, y_val_oversampling, X_test_oversampling_count_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, count_vec_predicted_NN_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, count_vec_predicted_NN_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "print (\"----TF-IDF ----\")\n",
    "tfidf_vec_predicted_NN= neural_network(X_train_tfidf_vec, y_train, X_val_tfidf_vec, y_val, X_test_tfidf_vec) \n",
    "print(metrics.classification_report(y_test, tfidf_vec_predicted_NN))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_NN))\n",
    "\n",
    "#TF-IDF\n",
    "print (\"c/oversampling\")\n",
    "tfidf_vec_predicted_NN_over= neural_network(X_train_oversampling_tfidf_vec, y_train_oversampling, X_val_oversampling_tfidf_vec, y_val_oversampling, X_test_oversampling_tfidf_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, tfidf_vec_predicted_NN_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, tfidf_vec_predicted_NN_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_NN= neural_network(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "print(metrics.classification_report(y_test, word2vec_predicted_NN))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_NN))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "word2vec_predicted_NN_over= neural_network(X_train_oversampling_word2vec, y_train_oversampling, X_val_oversampling_word2vec, y_val_oversampling, X_test_oversampling_word2vec) \n",
    "print(metrics.classification_report(y_test_oversampling, word2vec_predicted_NN_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, word2vec_predicted_NN_over))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove\n",
    "print (\"----GLOVE ----\")\n",
    "glove_predicted_NN= neural_network(X_train_glove, y_train, X_val_glove, y_val, X_test_glove) \n",
    "print(metrics.classification_report(y_test, glove_predicted_NN))\n",
    "print(metrics.confusion_matrix(y_test, glove_predicted_NN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f827bcd",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d051225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "\n",
    "def objective(X_train, y_train, X_val, y_val, trial):\n",
    "    # Hiperparâmetros a otimizar\n",
    "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])  # compatíveis com L1 e L2\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, preds, average='macro')\n",
    "    return f1\n",
    "\n",
    "\n",
    "def logistic_regression(X_train, y_train, X_val, y_val, X_test):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(X_train, y_train, X_val, y_val, trial), n_trials=30)\n",
    "\n",
    "    print(\"Melhores parâmetros encontrados:\")\n",
    "    print(study.best_params)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_model = LogisticRegression(\n",
    "        **best_params,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    previsoes = best_model.predict(X_test)\n",
    "\n",
    "    return previsoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e03c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:38:47,774] A new study created in memory with name: no-name-f804a6c1-a9ec-4956-92ee-a72dd1f88037\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:47,815] Trial 0 finished with value: 0.5759647633129582 and parameters: {'C': 0.5702975431962373, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 434}. Best is trial 0 with value: 0.5759647633129582.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:47,838] Trial 1 finished with value: 0.4817582369487045 and parameters: {'C': 0.024178449537411693, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 958}. Best is trial 0 with value: 0.5759647633129582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:48,033] Trial 2 finished with value: 0.6556576016190188 and parameters: {'C': 100.62436324687397, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 135}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:48,752] Trial 3 finished with value: 0.6504041189506938 and parameters: {'C': 162.82595003814305, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 567}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:49,360] Trial 4 finished with value: 0.48280955931962644 and parameters: {'C': 0.020068665251334997, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 452}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:49,472] Trial 5 finished with value: 0.6133551317639342 and parameters: {'C': 39.57151379943558, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 615}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:49,508] Trial 6 finished with value: 0.5098039215686274 and parameters: {'C': 0.294397046750876, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 992}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:49,547] Trial 7 finished with value: 0.5705119006104282 and parameters: {'C': 0.20205435998066762, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 776}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:49,559] Trial 8 finished with value: 0.4234293621241545 and parameters: {'C': 0.003557600040672028, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 275}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:49,743] Trial 9 finished with value: 0.6077744553829092 and parameters: {'C': 553.2979230436213, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 537}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:38:59,219] Trial 10 finished with value: 0.6552789886034468 and parameters: {'C': 9.916768695437854, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 127}. Best is trial 2 with value: 0.6556576016190188.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:39:07,423] Trial 11 finished with value: 0.6647095405734628 and parameters: {'C': 15.282658311116817, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 104}. Best is trial 11 with value: 0.6647095405734628.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:39:16,389] Trial 12 finished with value: 0.6637222489559013 and parameters: {'C': 9.85712118634492, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 114}. Best is trial 11 with value: 0.6647095405734628.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:39:36,151] Trial 13 finished with value: 0.6622131951818232 and parameters: {'C': 14.088989037426721, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 252}. Best is trial 11 with value: 0.6647095405734628.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:39:48,662] Trial 14 finished with value: 0.6770186152390382 and parameters: {'C': 3.4457245926565587, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 277}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:39:58,891] Trial 15 finished with value: 0.6650737387526919 and parameters: {'C': 2.361814418410887, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 277}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:40:10,975] Trial 16 finished with value: 0.6650737387526919 and parameters: {'C': 2.3236036584634028, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 308}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:40:22,669] Trial 17 finished with value: 0.6594394079862055 and parameters: {'C': 1.9281679823370776, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 380}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:40:23,784] Trial 18 finished with value: 0.4211064817524936 and parameters: {'C': 0.048462891612876466, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 664}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:40:34,035] Trial 19 finished with value: 0.6677610475806594 and parameters: {'C': 3.068460582723694, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 220}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:41:07,142] Trial 20 finished with value: 0.6496410997208824 and parameters: {'C': 722.5038133378972, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 366}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:41:16,031] Trial 21 finished with value: 0.6647007988963143 and parameters: {'C': 2.2792048244156153, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 234}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:41:16,399] Trial 22 finished with value: 0.47707987986016515 and parameters: {'C': 0.10833353334598418, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 174}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:41:20,878] Trial 23 finished with value: 0.6345127108226912 and parameters: {'C': 1.121590028412787, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 207}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:41:37,844] Trial 24 finished with value: 0.6659089482536446 and parameters: {'C': 3.941867775587999, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 334}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:42:01,263] Trial 25 finished with value: 0.662745322386999 and parameters: {'C': 5.689394883043907, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 374}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:42:42,737] Trial 26 finished with value: 0.6481329413472314 and parameters: {'C': 56.76384691306071, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 475}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:42:45,786] Trial 27 finished with value: 0.5909131725514046 and parameters: {'C': 0.5544105718153584, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 322}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:00,598] Trial 28 finished with value: 0.6622350604364993 and parameters: {'C': 26.528181254690583, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 193}. Best is trial 14 with value: 0.6770186152390382.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:21,725] Trial 29 finished with value: 0.6580010632642211 and parameters: {'C': 4.299736531448158, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 402}. Best is trial 14 with value: 0.6770186152390382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados:\n",
      "{'C': 3.4457245926565587, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 277}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:34,711] A new study created in memory with name: no-name-8b78f7ef-34bf-4cd4-ae02-5e635fa2a503\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:34,881] Trial 0 finished with value: 0.677824372328581 and parameters: {'C': 1.6684911551814994, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 894}. Best is trial 0 with value: 0.677824372328581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.64      0.70       417\n",
      "           0       0.81      0.91      0.86      1273\n",
      "           1       0.34      0.18      0.24       168\n",
      "\n",
      "    accuracy                           0.78      1858\n",
      "   macro avg       0.64      0.58      0.60      1858\n",
      "weighted avg       0.76      0.78      0.77      1858\n",
      "\n",
      "[[ 268  139   10]\n",
      " [  67 1159   47]\n",
      " [  13  125   30]]\n",
      "c/oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 01:43:36,823] Trial 1 finished with value: 0.7002086643251745 and parameters: {'C': 0.01636145823939285, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 969}. Best is trial 1 with value: 0.7002086643251745.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:37,006] Trial 2 finished with value: 0.6204439095503163 and parameters: {'C': 41.268624677841466, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 568}. Best is trial 1 with value: 0.7002086643251745.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:37,040] Trial 3 finished with value: 0.6221880187008261 and parameters: {'C': 0.0012823722959344008, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 808}. Best is trial 1 with value: 0.7002086643251745.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:39,220] Trial 4 finished with value: 0.6401537638542519 and parameters: {'C': 122.8421119866404, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 649}. Best is trial 1 with value: 0.7002086643251745.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:39,356] Trial 5 finished with value: 0.6570220088060158 and parameters: {'C': 2.294571552068283, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 665}. Best is trial 1 with value: 0.7002086643251745.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:39,867] Trial 6 finished with value: 0.6667492440822625 and parameters: {'C': 0.0038026738684157663, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 169}. Best is trial 1 with value: 0.7002086643251745.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:40,007] Trial 7 finished with value: 0.7006355543663503 and parameters: {'C': 1.3062076911105878, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 870}. Best is trial 7 with value: 0.7006355543663503.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:40,085] Trial 8 finished with value: 0.7168878035705196 and parameters: {'C': 0.1084583216913827, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 263}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:41,991] Trial 9 finished with value: 0.6401537638542519 and parameters: {'C': 837.6202799019968, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 623}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:42,055] Trial 10 finished with value: 0.6193004947549531 and parameters: {'C': 0.05931491306642158, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 286}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:42,122] Trial 11 finished with value: 0.6989057396281192 and parameters: {'C': 0.13776121438497146, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 394}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:42,207] Trial 12 finished with value: 0.6854682321308969 and parameters: {'C': 0.3379765746526792, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 415}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:42,483] Trial 13 finished with value: 0.6720197336223274 and parameters: {'C': 5.657299044318926, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 102}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:42,754] Trial 14 finished with value: 0.6537956850376825 and parameters: {'C': 10.997328673340208, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 798}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:46,933] Trial 15 finished with value: 0.6862934565285325 and parameters: {'C': 0.5011213472790349, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 448}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:46,999] Trial 16 finished with value: 0.5647387556533549 and parameters: {'C': 0.02273326883194768, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 274}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:47,089] Trial 17 finished with value: 0.6855694753307763 and parameters: {'C': 0.11777143518743549, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 756}. Best is trial 8 with value: 0.7168878035705196.\n",
      "[I 2025-11-13 01:43:47,362] Trial 18 finished with value: 0.473367223901145 and parameters: {'C': 0.011088350124596877, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 995}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:47,539] Trial 19 finished with value: 0.6350408393593395 and parameters: {'C': 16.868490702339628, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 517}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:47,731] Trial 20 finished with value: 0.7082776325765678 and parameters: {'C': 0.7359353818334339, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 338}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:47,938] Trial 21 finished with value: 0.7104264295013126 and parameters: {'C': 0.9945873004294815, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 284}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:48,059] Trial 22 finished with value: 0.6905250105198041 and parameters: {'C': 0.36801697067916017, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 280}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:48,132] Trial 23 finished with value: 0.6276268943316103 and parameters: {'C': 0.060651641125637805, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 214}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:48,541] Trial 24 finished with value: 0.6704927005304944 and parameters: {'C': 4.4153442890075265, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 349}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:48,726] Trial 25 finished with value: 0.6924120556187446 and parameters: {'C': 0.563047911345828, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 193}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:50,030] Trial 26 finished with value: 0.706282382316446 and parameters: {'C': 0.1922270598084053, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 345}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:50,107] Trial 27 finished with value: 0.5882229614576487 and parameters: {'C': 0.04035278692823199, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 497}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:50,172] Trial 28 finished with value: 0.670307613404951 and parameters: {'C': 0.006543860084360959, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 102}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "[I 2025-11-13 01:43:50,303] Trial 29 finished with value: 0.6835157979056753 and parameters: {'C': 1.625244943582272, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 361}. Best is trial 8 with value: 0.7168878035705196.\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados:\n",
      "{'C': 0.1084583216913827, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 263}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.77      0.80      1273\n",
      "           0       0.54      0.83      0.65      1273\n",
      "           1       0.72      0.40      0.51      1273\n",
      "\n",
      "    accuracy                           0.67      3819\n",
      "   macro avg       0.70      0.67      0.66      3819\n",
      "weighted avg       0.70      0.67      0.66      3819\n",
      "\n",
      "[[ 979  219   75]\n",
      " [  96 1058  119]\n",
      " [  89  681  503]]\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_LR= logistic_regression(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "print(metrics.classification_report(y_test, count_vec_predicted_LR))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_LR))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "count_vec_predicted_LR_over= logistic_regression(X_train_oversampling_count_vec, y_train_oversampling, X_val_oversampling_count_vec, y_val_oversampling, X_test_oversampling_count_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, count_vec_predicted_LR_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, count_vec_predicted_LR_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "print (\"----TF-IDF ----\")\n",
    "tfidf_vec_predicted_LR= logistic_regression(X_train_tfidf_vec, y_train, X_val_tfidf_vec, y_val, X_test_tfidf_vec) \n",
    "print(metrics.classification_report(y_test, tfidf_vec_predicted_LR))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_LR))\n",
    "\n",
    "#TF-IDF\n",
    "print (\"c/oversampling\")\n",
    "tfidf_vec_predicted_LR_over= logistic_regression(X_train_oversampling_tfidf_vec, y_train_oversampling, X_val_oversampling_tfidf_vec, y_val_oversampling, X_test_oversampling_tfidf_vec) \n",
    "print(metrics.classification_report(y_test_oversampling, tfidf_vec_predicted_LR_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, tfidf_vec_predicted_LR_over))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_LR= logistic_regression(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "print(metrics.classification_report(y_test, word2vec_predicted_LR))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_LR))\n",
    "\n",
    "print (\"c/oversampling\")\n",
    "word2vec_predicted_LR_over= logistic_regression(X_train_oversampling_word2vec, y_train_oversampling, X_val_oversampling_word2vec, y_val_oversampling, X_test_oversampling_word2vec) \n",
    "print(metrics.classification_report(y_test_oversampling, word2vec_predicted_LR_over))\n",
    "print(metrics.confusion_matrix(y_test_oversampling, word2vec_predicted_LR_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove\n",
    "print (\"----GLOVE ----\")\n",
    "glove_predicted_LR= logistic_regression(X_train_glove, y_train, X_val_glove, y_val, X_test_glove, y_test) \n",
    "print(metrics.classification_report(y_test, glove_predicted_LR))\n",
    "print(metrics.confusion_matrix(y_test, glove_predicted_LR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
