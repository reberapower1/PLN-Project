{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5874fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fddcf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file          0\n",
       "id_sente      0\n",
       "id_article    0\n",
       "domain        0\n",
       "year          0\n",
       "sentences     0\n",
       "classe        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carregar dataset\n",
    "df = pd.read_csv('factnews_dataset.csv')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa80a44",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b710fb",
   "metadata": {},
   "source": [
    "divisão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d457cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#criar grupo treino, validação e teste\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['classe'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['classe'])\n",
    "\n",
    "#guardar conjuntos em memória\n",
    "train_df.to_csv(\"train.csv\", index=False) \n",
    "val_df.to_csv(\"val.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1708b8",
   "metadata": {},
   "source": [
    "balanceamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f65b63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')\n",
    "val= pd.read_csv('val.csv')\n",
    "test= pd.read_csv('test.csv')\n",
    "train_oversampling= pd.read_csv('train_oversampling.csv')\n",
    "\n",
    "y_test= test['classe']\n",
    "y_train= train['classe']\n",
    "y_train_oversampling= train_oversampling['classe']\n",
    "y_val=val['classe']\n",
    "classes = test['classe'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce488a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto de treino:  classe\n",
      "-1     779\n",
      " 0    2375\n",
      " 1     312\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de validação:  classe\n",
      "-1    195\n",
      " 0    594\n",
      " 1     78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de teste:  classe\n",
      "-1     417\n",
      " 0    1273\n",
      " 1     168\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de teste:  classe\n",
      "-1    2375\n",
      " 0    2375\n",
      " 1    2375\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes em cada conjunto\n",
    "print (\"conjunto de treino: \",y_train.value_counts().sort_index())\n",
    "print(\"\\nconjunto de validação: \",y_val.value_counts().sort_index())\n",
    "print(\"\\nconjunto de teste: \", y_test.value_counts().sort_index())\n",
    "print(\"\\nconjunto de teste: \", y_train_oversampling.value_counts().sort_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b76d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe\n",
      " 1    2375\n",
      " 0    2375\n",
      "-1    2375\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''from sklearn.utils import resample\n",
    "\n",
    "# Separar cada classe\n",
    "class_min = train[train['classe'] == -1]\n",
    "class_med = train[train['classe'] == 1]\n",
    "class_max = train[train['classe'] == 0]\n",
    "\n",
    "# Número da classe maior\n",
    "n_samples = len(class_max)\n",
    "\n",
    "# Replicar as classes menores até o tamanho da maior\n",
    "class_min_upsampled = resample(class_min, \n",
    "                            replace=True, \n",
    "                            n_samples=n_samples, \n",
    "                            random_state=42)\n",
    "\n",
    "class_med_upsampled = resample(class_med, \n",
    "                            replace=True, \n",
    "                            n_samples=n_samples, \n",
    "                          random_state=42)\n",
    "\n",
    "train_oversampling = pd.concat([class_min_upsampled, class_med_upsampled, class_max])\n",
    "\n",
    "# baralhar o conjunto de treino\n",
    "train_oversampling = train_oversampling.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(train_oversampling['classe'].value_counts())\n",
    "\n",
    "train_oversampling.to_csv('train_oversampling.csv', index=False)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262d8a4",
   "metadata": {},
   "source": [
    "tokeinização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d610e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [neym, ,, part, 20, novembr, vai, lider, seleç...\n",
      "1    [forç, internac, transform, quest, taiwan, ass...\n",
      "2    [alianç, mai, quant, parlament, eleit, nome, p...\n",
      "3    [ger, mort, '', ,, declar, cabr, ,, 16ª, entre...\n",
      "4    [bisp, barr, (, ba, ), ,, dom, luiz, flávi, ca...\n",
      "Name: stems, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\didia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "#criar coluna tokens\n",
    "train['tokens'] = train['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "val['tokens']   = val['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "test['tokens'] = test['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "train_oversampling['tokens'] = train_oversampling['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "\n",
    "#remover stopwords\n",
    "train['tokens'] = train['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "val['tokens']   = val['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "test['tokens']  = test['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "train_oversampling['tokens'] = train_oversampling['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "\n",
    "#matizar\n",
    "#nltk . download ('rslp')\n",
    "stemmer = nltk . stem . RSLPStemmer ()\n",
    "train['stems'] = train['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "val['stems']   = val['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "test['stems'] = test['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "train_oversampling['stems'] = train_oversampling['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "\n",
    "nltk . download ('rslp')\n",
    "stemmer = nltk . stem . RSLPStemmer ()\n",
    "print(train['stems'].head())\n",
    "\n",
    "y_test= test['classe']\n",
    "y_train= train['classe']\n",
    "y_val=val['classe']\n",
    "classes = test['classe'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b02c9",
   "metadata": {},
   "source": [
    "# Construção dos modelos de representação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799b632",
   "metadata": {},
   "source": [
    "## TF-IDF - fred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d13758dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_IDF(train, train_oversampling, val, test):\n",
    "    tf_vect = TfidfVectorizer(ngram_range =(1, 2), min_df =3, max_df =0.5, max_features =500)\n",
    "\n",
    "        #juntar os tokens matizados em frases novvamente \n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_train_oversampling = train_oversampling['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val   = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_test = test['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    X_train = tf_vect.fit_transform(text_train)\n",
    "    X_train_oversampling = tf_vect.fit_transform(text_train_oversampling)\n",
    "    X_val   = tf_vect.transform(text_val)\n",
    "    X_test  = tf_vect.transform(text_test)\n",
    "    return X_train, X_train_oversampling, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b98a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_vec,X_train_oversampling_tfidf_vec, X_val_tfidf_vec, X_test_tfidf_vec = TF_IDF(train,train_oversampling, val, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eaac49",
   "metadata": {},
   "source": [
    "## CountVectorizer -didi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1399bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Parâmetros a otimizar\n",
    "    max_features = trial.suggest_int(\"max_features\", 500, 5000)\n",
    "    ngram_min = trial.suggest_int(\"ngram_min\", 1, 2)\n",
    "    ngram_max = trial.suggest_int(\"ngram_max\", ngram_min, 3)  # garante ngram_max >= ngram_min\n",
    "\n",
    "    # CountVectorizer com parâmetros sugeridos\n",
    "    c_vect = CountVectorizer(\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b|[^\\w\\s]\",\n",
    "        ngram_range=(ngram_min, ngram_max),\n",
    "        strip_accents='unicode',\n",
    "        max_features=max_features\n",
    "    )\n",
    "\n",
    "    # Transformar textos\n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val   = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    X_train = c_vect.fit_transform(text_train)\n",
    "    X_val   = c_vect.transform(text_val)\n",
    "\n",
    "    y_train = train['classe'] \n",
    "    y_val   = val['classe']\n",
    "\n",
    "    # Treinar Logistic Regression\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    # Métrica: F1 macro\n",
    "    score = f1_score(y_val, preds, average='macro')\n",
    "    return score \n",
    "\n",
    "def count_vec(train, val, test, best_params):\n",
    "    c_vect = CountVectorizer(\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b|[^\\w\\s]\",\n",
    "        ngram_range=(best_params['ngram_min'], best_params['ngram_max']),\n",
    "        strip_accents='unicode',\n",
    "        max_features=best_params['max_features']\n",
    "    )\n",
    "\n",
    "    # Transformar textos\n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_test = test['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    # Fit no treino original, transform nos outros conjuntos\n",
    "    X_train = c_vect.fit_transform(text_train)\n",
    "    X_val = c_vect.transform(text_val)\n",
    "    X_test = c_vect.transform(text_test)\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "666f038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 16:23:21,980] A new study created in memory with name: no-name-80f90efb-00dc-4f64-b5cc-8f9c119539c8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 16:23:23,202] Trial 0 finished with value: 0.6678669805741629 and parameters: {'max_features': 3592, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:23,736] Trial 1 finished with value: 0.5451519057036222 and parameters: {'max_features': 4635, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:24,121] Trial 2 finished with value: 0.5490473585263653 and parameters: {'max_features': 1237, 'ngram_min': 2, 'ngram_max': 2}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:24,736] Trial 3 finished with value: 0.5341143213473796 and parameters: {'max_features': 1028, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:25,370] Trial 4 finished with value: 0.659430995946509 and parameters: {'max_features': 2169, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:26,121] Trial 5 finished with value: 0.6665016127441175 and parameters: {'max_features': 1702, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:26,507] Trial 6 finished with value: 0.663658126711282 and parameters: {'max_features': 1216, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:27,437] Trial 7 finished with value: 0.6671387806209516 and parameters: {'max_features': 2012, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:28,108] Trial 8 finished with value: 0.5472762800433703 and parameters: {'max_features': 3006, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 0 with value: 0.6678669805741629.\n",
      "[I 2025-11-11 16:23:29,262] Trial 9 finished with value: 0.6714719493178478 and parameters: {'max_features': 4879, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 9 with value: 0.6714719493178478.\n",
      "[I 2025-11-11 16:23:29,960] Trial 10 finished with value: 0.6438024743762099 and parameters: {'max_features': 4975, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 9 with value: 0.6714719493178478.\n",
      "[I 2025-11-11 16:23:31,265] Trial 11 finished with value: 0.6722587522169818 and parameters: {'max_features': 3772, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 11 with value: 0.6722587522169818.\n",
      "[I 2025-11-11 16:23:32,463] Trial 12 finished with value: 0.6734990715087125 and parameters: {'max_features': 4081, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:33,432] Trial 13 finished with value: 0.6692363480082731 and parameters: {'max_features': 3863, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:34,458] Trial 14 finished with value: 0.6691082714050406 and parameters: {'max_features': 4004, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:35,126] Trial 15 finished with value: 0.6700652505885248 and parameters: {'max_features': 3235, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:36,219] Trial 16 finished with value: 0.663319140727622 and parameters: {'max_features': 4288, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:36,950] Trial 17 finished with value: 0.5392211515764299 and parameters: {'max_features': 2617, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:37,211] Trial 18 finished with value: 0.6245436628910033 and parameters: {'max_features': 505, 'ngram_min': 1, 'ngram_max': 1}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:38,034] Trial 19 finished with value: 0.6674169930072326 and parameters: {'max_features': 3483, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:38,839] Trial 20 finished with value: 0.5656060755070657 and parameters: {'max_features': 4350, 'ngram_min': 2, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:39,800] Trial 21 finished with value: 0.6660688948891641 and parameters: {'max_features': 4668, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:40,976] Trial 22 finished with value: 0.6650567806057858 and parameters: {'max_features': 4923, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:42,141] Trial 23 finished with value: 0.6688108829627105 and parameters: {'max_features': 4161, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:42,980] Trial 24 finished with value: 0.6648036969916341 and parameters: {'max_features': 3724, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:44,014] Trial 25 finished with value: 0.6694682114486685 and parameters: {'max_features': 4499, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:44,899] Trial 26 finished with value: 0.6651859050510867 and parameters: {'max_features': 2678, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:45,421] Trial 27 finished with value: 0.6691405547234428 and parameters: {'max_features': 3293, 'ngram_min': 1, 'ngram_max': 2}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:46,426] Trial 28 finished with value: 0.6691082714050406 and parameters: {'max_features': 4019, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n",
      "[I 2025-11-11 16:23:47,517] Trial 29 finished with value: 0.668615354332748 and parameters: {'max_features': 3653, 'ngram_min': 1, 'ngram_max': 3}. Best is trial 12 with value: 0.6734990715087125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'max_features': 4081, 'ngram_min': 1, 'ngram_max': 3}\n",
      "Melhor F1: 0.6734990715087125\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  \n",
    "study.optimize(objective, n_trials=30) \n",
    "print(\"Melhores parâmetros:\", study.best_params)\n",
    "print(\"Melhor F1:\", study.best_value)\n",
    "X_train_count_vec, X_val_count_vec, X_test_count_vec = count_vec(train, val, test, study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a974ef",
   "metadata": {},
   "source": [
    "## Glove -fred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f116c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72beca9e",
   "metadata": {},
   "source": [
    "## WORD2VEC -anaana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d7c7d",
   "metadata": {},
   "source": [
    "fontes : \n",
    "-   https://sites.google.com/view/nilc-usp/resources-and-tools?authuser=0\n",
    "-   https://huggingface.co/nilc-nlp/word2vec-skip-gram-300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bade9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install huggingface_hub\n",
    "#%pip install hf_hub_download\n",
    "#%pip install safetensors\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.numpy import load_file\n",
    "\n",
    "def carregar_word2vec():\n",
    "    path = hf_hub_download(repo_id=\"nilc-nlp/word2vec-skip-gram-300d\",\n",
    "                           filename=\"embeddings.safetensors\")\n",
    "\n",
    "    data = load_file(path)\n",
    "    vectors = data[\"embeddings\"]\n",
    "\n",
    "    vocab_path = hf_hub_download(repo_id=\"nilc-nlp/word2vec-skip-gram-300d\",\n",
    "                                 filename=\"vocab.txt\")\n",
    "    with open(vocab_path) as f:\n",
    "        vocab = [w.strip() for w in f]\n",
    "\n",
    "    print(vectors.shape)\n",
    "\n",
    "    model = KeyedVectors(vector_size=vectors.shape[1])\n",
    "    model.add_vectors(vocab, vectors)\n",
    "    model.fill_norms()\n",
    "\n",
    "    return model\n",
    "\n",
    "def vetor_frase(model, frase):\n",
    "    vectors = [model[w] for w in frase if w in model]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "def word2vec(train, val, test, coluna, model):\n",
    "    X_train = np.vstack([vetor_frase(model, tokens) for tokens in train[coluna]])\n",
    "    X_val   = np.vstack([vetor_frase(model, tokens) for tokens in val[coluna]])\n",
    "    X_test  = np.vstack([vetor_frase(model, tokens) for tokens in test[coluna]])\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929606, 300)\n"
     ]
    }
   ],
   "source": [
    "model = carregar_word2vec()\n",
    "X_train_word2vec, X_val_word2vec, X_test_word2vec = word2vec(train, val, test, 'stems', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "certos = (test_df['classe'] == test_df['Previsto4']).sum()\n",
    "total = len(test_df)\n",
    "\n",
    "matriz = confusion_matrix(test_df['classe'], test_df['Previsto4'], labels=classes)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matriz, display_labels=classes)\n",
    "disp.plot()\n",
    "plt.title(\"Matriz de confusão do teste\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(test_df['classe'], test_df['Previsto4'], labels=classes, digits=4)\n",
    "print(report)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955eb2ec",
   "metadata": {},
   "source": [
    "# Aplicar modelos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268c280",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc51ae",
   "metadata": {},
   "source": [
    "-   Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0229cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_MN(X_train, y_train, X_val, y_val, X_test, alphas):\n",
    "    best_alpha = None\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Procurar o melhor alpha com o conjunto de validação\n",
    "    for alpha in alphas:\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    print(f\"Melhor alpha encontrado: {best_alpha} (F1 val = {best_f1:.4f})\")\n",
    "\n",
    "    # Treinar o modelo final \n",
    "    final_clf = MultinomialNB(alpha=best_alpha)\n",
    "    final_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = final_clf.predict(X_test)\n",
    "\n",
    "    return y_test_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "222c6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def objective_naive_GS(trial, X_train, X_val, y_train, y_val):\n",
    "    # Definir o hiperparâmetro a otimizar\n",
    "    var_smoothing = trial.suggest_float(\"var_smoothing\", 1e-12, 1e-3, log=True)\n",
    "    # Criar o modelo\n",
    "    model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    # Treinar\n",
    "    model.fit(X_train, y_train)\n",
    "    # Avaliar no conjunto de validação\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
    "\n",
    "    return f1\n",
    "\n",
    "def naive_bayes_gs(X_train, X_val, X_test, y_train, y_val, n_trials=30):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective_naive_GS(trial, X_train, X_val, y_train, y_val),\n",
    "                   n_trials=n_trials, n_jobs=-1, show_progress_bar=False)\n",
    "    print(\"Melhores hiperparâmetros encontrados:\")\n",
    "    print(study.best_params)\n",
    "    # Treinar o melhor modelo com os melhores parâmetros\n",
    "    best_model = GaussianNB(**study.best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    # Avaliar no conjunto de teste\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df142687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Melhor alpha encontrado: 1.0 (F1 val = 0.8018)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.78      0.75       417\n",
      "           0       0.85      0.85      0.85      1273\n",
      "          -1       0.30      0.24      0.27       168\n",
      "\n",
      "    accuracy                           0.78      1858\n",
      "   macro avg       0.62      0.62      0.62      1858\n",
      "weighted avg       0.77      0.78      0.77      1858\n",
      "\n",
      "[[ 327   82    8]\n",
      " [ 108 1080   85]\n",
      " [  22  106   40]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\ncom oversampling\")\\ncount_vec_oversampling_predicted_NB= Naive_Bayes_MN(X_train_oversampling_count_vec, y_train_oversampling, X_val_count_vec,y_val , X_test_count_vec, \\n                                    alphas=[0.01, 0.1, 0.5, 1.0, 3.0,5.0, 6.0, 7.0]) \\nlista_y = [str(c) for c in (test[\\'classe\\'].unique())]\\nprint(metrics.classification_report(\\ny_test, count_vec_oversampling_predicted_NB, target_names=set(lista_y)))\\nprint(metrics.confusion_matrix(y_test, count_vec_oversampling_predicted_NB))'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_NB= Naive_Bayes_MN(X_train_count_vec, y_train, X_val_count_vec,y_val , X_test_count_vec, \n",
    "                                    alphas=[0.01, 0.1, 0.5, 1.0, 3.0,5.0, 6.0, 7.0]) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_NB, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_NB))\n",
    "print(\"\\ncom oversampling\")\n",
    "count_vec_oversampling_predicted_NB= Naive_Bayes_MN(X_train_oversampling_count_vec, y_train_oversampling, X_val_count_vec,y_val , X_test_count_vec, \n",
    "                                    alphas=[0.01, 0.1, 0.5, 1.0, 3.0,5.0, 6.0, 7.0]) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_oversampling_predicted_NB, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_oversampling_predicted_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10c2c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----TF-IDF ----\n",
      "Melhor alpha encontrado: 0.01 (F1 val = 0.5645)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.07      0.11       417\n",
      "           0       0.69      0.92      0.79      1273\n",
      "          -1       0.14      0.03      0.05       168\n",
      "\n",
      "    accuracy                           0.65      1858\n",
      "   macro avg       0.36      0.34      0.32      1858\n",
      "weighted avg       0.54      0.65      0.57      1858\n",
      "\n",
      "[[  13  402    2]\n",
      " [  32 1240    1]\n",
      " [   9  159    0]]\n",
      "\n",
      " com oversampling\n",
      "Melhor alpha encontrado: 7.0 (F1 val = 0.6631)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.65      0.57       417\n",
      "           0       0.84      0.61      0.71      1273\n",
      "          -1       0.19      0.45      0.27       168\n",
      "\n",
      "    accuracy                           0.61      1858\n",
      "   macro avg       0.51      0.57      0.52      1858\n",
      "weighted avg       0.71      0.61      0.64      1858\n",
      "\n",
      "[[269  91  57]\n",
      " [224 782 267]\n",
      " [ 37  55  76]]\n"
     ]
    }
   ],
   "source": [
    "print (\"----TF-IDF ----\")\n",
    "tfidf_vec_predicted_NB= Naive_Bayes_MN(X_train_tfidf_vec, y_train, X_val_tfidf_vec,y_val , X_test_tfidf_vec, \n",
    "                                    alphas=[0.01, 0.1, 0.5, 1.0, 3.0,5.0, 6.0, 7.0]) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_NB, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_NB))\n",
    "print(\"\\n com oversampling\")\n",
    "\n",
    "tfidf_vec_oversampling_predicted_NB= Naive_Bayes_MN(X_train_oversampling_tfidf_vec, y_train_oversampling, X_val_tfidf_vec,y_val , X_test_tfidf_vec, \n",
    "                                    alphas=[0.01, 0.1, 0.5, 1.0, 3.0,5.0, 6.0, 7.0]) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, tfidf_vec_oversampling_predicted_NB, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_oversampling_predicted_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c766d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 15:08:18,378] A new study created in memory with name: no-name-a36bd325-c3a6-4635-81e9-bfcfb3605e6a\n",
      "[I 2025-11-11 15:08:18,482] Trial 1 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.949569882446841e-07}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,499] Trial 5 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.1263800014039e-05}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,509] Trial 2 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.1213165208214825e-12}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,511] Trial 6 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.609319623025647e-12}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,528] Trial 0 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.2947520782381067e-06}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,537] Trial 3 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 0.00012272414569220304}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,554] Trial 4 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 5.6252497559820717e-11}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,567] Trial 7 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.726155618010365e-11}. Best is trial 1 with value: 0.4016961525191454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----WORD2VEC ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 15:08:18,610] Trial 8 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.4834192983414675e-05}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,636] Trial 9 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 8.577984109736401e-12}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,651] Trial 11 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.63028177776144e-10}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,657] Trial 10 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.3349879436850483e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,706] Trial 13 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 7.244245988120601e-12}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,719] Trial 14 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.2185137420959065e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,753] Trial 16 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.0977107754021276e-09}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,756] Trial 12 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.3591190722944524e-08}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,799] Trial 17 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.240726801104606e-07}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,824] Trial 18 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 5.922450913643709e-07}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,849] Trial 15 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 6.453172512219295e-12}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,849] Trial 19 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.1910381889896535e-07}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,915] Trial 22 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.080965460038084e-07}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,926] Trial 24 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.257578027281206e-06}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,973] Trial 25 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.355372925962922e-06}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,990] Trial 27 finished with value: 0.40095722126515704 and parameters: {'var_smoothing': 0.0009749129759409843}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:18,997] Trial 20 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.4038434901360066e-06}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:19,018] Trial 23 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.5355981659293048e-06}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:19,023] Trial 21 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 7.03800464798588e-07}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:19,034] Trial 28 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.645793406862215e-06}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:19,040] Trial 26 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.491041573326979e-06}. Best is trial 1 with value: 0.4016961525191454.\n",
      "[I 2025-11-11 15:08:19,042] Trial 29 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 5.313860370086089e-06}. Best is trial 1 with value: 0.4016961525191454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'var_smoothing': 2.949569882446841e-07}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.42      0.43       417\n",
      "           0       0.84      0.32      0.47      1273\n",
      "          -1       0.11      0.62      0.18       168\n",
      "\n",
      "    accuracy                           0.37      1858\n",
      "   macro avg       0.46      0.46      0.36      1858\n",
      "weighted avg       0.68      0.37      0.43      1858\n",
      "\n",
      "[[175  44 198]\n",
      " [196 410 667]\n",
      " [ 30  33 105]]\n"
     ]
    }
   ],
   "source": [
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_NB= naive_bayes_gs(X_train_word2vec, X_val_word2vec, X_test_word2vec, y_train, y_val, n_trials=30) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, word2vec_predicted_NB, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_NB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8da10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44bdd3",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab39b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, X_val, y_train, y_val):\n",
    "\n",
    "    #Definir hiperparâmetros a testar \n",
    "    C = trial.suggest_float('C', 0.01, 10.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "\n",
    "    #Criar modelo SVM \n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree)\n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree)\n",
    "\n",
    "    #treinar modelo com conjunto de treino\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #prever no conjunto de validação\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    #calcular f1\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "    return f1\n",
    "\n",
    "def svm(X_train, X_val, X_test, y_train, y_val, n_trials=30):\n",
    "    # Chamar o Optuna para otimizar os parâmetros\n",
    "    objeto_para_otimizar = optuna.create_study(direction='maximize')\n",
    "    objeto_para_otimizar.optimize(lambda trial: objective(trial, X_train, X_val, y_train, y_val),\n",
    "                   n_trials=n_trials, n_jobs=-1, show_progress_bar=False )\n",
    "\n",
    "    print(\"Melhores hiperparâmetros encontrados:\")\n",
    "    print(objeto_para_otimizar.best_params)\n",
    "\n",
    "    # Treinar o melhor modelo\n",
    "    best_model = SVC(**objeto_para_otimizar.best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    #  Avaliar no conjunto de teste\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8e61fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 15:08:41,414] A new study created in memory with name: no-name-b383358a-4d3a-48f6-9f6e-1f4d8622cc66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 15:08:42,662] Trial 6 finished with value: 0.271047227926078 and parameters: {'C': 4.348664013511701, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 6 with value: 0.271047227926078.\n",
      "[I 2025-11-11 15:08:43,060] Trial 5 finished with value: 0.2728571162413656 and parameters: {'C': 0.4128041026288293, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 5 with value: 0.2728571162413656.\n",
      "[I 2025-11-11 15:08:43,193] Trial 0 finished with value: 0.272029175469006 and parameters: {'C': 0.20074550984619463, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 5 with value: 0.2728571162413656.\n",
      "[I 2025-11-11 15:08:43,251] Trial 7 finished with value: 0.26886900665290203 and parameters: {'C': 0.06227384659617249, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.2728571162413656.\n",
      "[I 2025-11-11 15:08:43,403] Trial 2 finished with value: 0.2782224244910812 and parameters: {'C': 2.106516381508683, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 2 with value: 0.2782224244910812.\n",
      "[I 2025-11-11 15:08:43,441] Trial 1 finished with value: 0.2938061020705649 and parameters: {'C': 1.6297803650019551, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:43,657] Trial 3 finished with value: 0.2802034731448211 and parameters: {'C': 0.5582907082632435, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:44,232] Trial 9 finished with value: 0.271047227926078 and parameters: {'C': 1.4717969958909345, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:44,281] Trial 8 finished with value: 0.271047227926078 and parameters: {'C': 0.09169345564242656, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:44,615] Trial 4 finished with value: 0.27836431637201725 and parameters: {'C': 0.037943787715574946, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:44,629] Trial 11 finished with value: 0.271047227926078 and parameters: {'C': 0.15419453177183115, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:44,994] Trial 12 finished with value: 0.27050491204021015 and parameters: {'C': 2.7497722269854328, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:45,716] Trial 14 finished with value: 0.2912274174380817 and parameters: {'C': 1.2064294344114692, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:45,731] Trial 10 finished with value: 0.2655563266250289 and parameters: {'C': 1.6859302333699038, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:45,761] Trial 15 finished with value: 0.27982550059832484 and parameters: {'C': 0.2873380188457096, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.2938061020705649.\n",
      "[I 2025-11-11 15:08:45,775] Trial 13 finished with value: 0.30036179681035474 and parameters: {'C': 2.693135793140319, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.30036179681035474.\n",
      "[I 2025-11-11 15:08:46,028] Trial 17 finished with value: 0.271047227926078 and parameters: {'C': 0.013313851595965173, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 13 with value: 0.30036179681035474.\n",
      "[I 2025-11-11 15:08:46,231] Trial 16 finished with value: 0.2916078774226795 and parameters: {'C': 1.0587964148173983, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 13 with value: 0.30036179681035474.\n",
      "[I 2025-11-11 15:08:46,555] Trial 18 finished with value: 0.2909536845894073 and parameters: {'C': 0.7301203409767312, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.30036179681035474.\n",
      "[I 2025-11-11 15:08:46,944] Trial 19 finished with value: 0.2806604355665439 and parameters: {'C': 0.5403396612831302, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.30036179681035474.\n",
      "[I 2025-11-11 15:08:49,824] Trial 21 finished with value: 0.3019237775396059 and parameters: {'C': 9.205442433993218, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3019237775396059.\n",
      "[I 2025-11-11 15:08:49,960] Trial 22 finished with value: 0.3014834289352185 and parameters: {'C': 9.26849600949291, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3019237775396059.\n",
      "[I 2025-11-11 15:08:50,070] Trial 24 finished with value: 0.29869048446019 and parameters: {'C': 8.801167043157115, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.3019237775396059.\n",
      "[I 2025-11-11 15:08:50,136] Trial 20 finished with value: 0.30183224414180093 and parameters: {'C': 8.17319333940897, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3019237775396059.\n",
      "[I 2025-11-11 15:08:50,219] Trial 23 finished with value: 0.29869048446019 and parameters: {'C': 8.797926552649633, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.3019237775396059.\n",
      "[I 2025-11-11 15:08:50,460] Trial 26 finished with value: 0.3006031707802672 and parameters: {'C': 9.809268787881521, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.3019237775396059.\n",
      "[I 2025-11-11 15:08:50,595] Trial 25 finished with value: 0.3016020568291074 and parameters: {'C': 9.976393740180791, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.3019237775396059.\n",
      "[I 2025-11-11 15:08:50,887] Trial 27 finished with value: 0.30002960002960005 and parameters: {'C': 8.589927996213936, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.3019237775396059.\n",
      "[I 2025-11-11 15:08:52,335] Trial 28 finished with value: 0.3073278291017554 and parameters: {'C': 7.739094578920957, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 28 with value: 0.3073278291017554.\n",
      "[I 2025-11-11 15:08:52,528] Trial 29 finished with value: 0.3010432291880993 and parameters: {'C': 9.985439987344373, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 28 with value: 0.3073278291017554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 7.739094578920957, 'kernel': 'linear', 'gamma': 'auto'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.12      0.15       417\n",
      "           0       0.68      0.78      0.73      1273\n",
      "          -1       0.13      0.11      0.12       168\n",
      "\n",
      "    accuracy                           0.57      1858\n",
      "   macro avg       0.34      0.34      0.33      1858\n",
      "weighted avg       0.52      0.57      0.54      1858\n",
      "\n",
      "[[ 50 341  26]\n",
      " [173 996 104]\n",
      " [ 26 123  19]]\n"
     ]
    }
   ],
   "source": [
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_SVM= svm(X_train_count_vec, X_val_count_vec, X_test_count_vec, y_train, y_val, n_trials=30) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_SVM, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e5930db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 15:08:54,499] A new study created in memory with name: no-name-d4b27d55-029c-47c2-b536-e77953e56d19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- TF-IDF ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 15:08:55,173] Trial 1 finished with value: 0.271047227926078 and parameters: {'C': 0.012325279805459869, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 1 with value: 0.271047227926078.\n",
      "[I 2025-11-11 15:08:55,293] Trial 0 finished with value: 0.271047227926078 and parameters: {'C': 0.9277300707410308, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 1 with value: 0.271047227926078.\n",
      "[I 2025-11-11 15:08:55,432] Trial 4 finished with value: 0.271047227926078 and parameters: {'C': 0.012977477690234215, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.271047227926078.\n",
      "[I 2025-11-11 15:08:55,467] Trial 5 finished with value: 0.271047227926078 and parameters: {'C': 0.21656092956323936, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.271047227926078.\n",
      "[I 2025-11-11 15:08:55,671] Trial 7 finished with value: 0.280653324131585 and parameters: {'C': 0.27235873079065787, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 7 with value: 0.280653324131585.\n",
      "[I 2025-11-11 15:08:56,090] Trial 2 finished with value: 0.271047227926078 and parameters: {'C': 0.05603349288077428, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 7 with value: 0.280653324131585.\n",
      "[I 2025-11-11 15:08:56,304] Trial 8 finished with value: 0.271047227926078 and parameters: {'C': 5.662938384818802, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.280653324131585.\n",
      "[I 2025-11-11 15:08:56,535] Trial 9 finished with value: 0.30477127228175527 and parameters: {'C': 1.9093604865531002, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:56,605] Trial 10 finished with value: 0.3005712365591398 and parameters: {'C': 0.7074188811471185, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:56,754] Trial 6 finished with value: 0.29696829719388895 and parameters: {'C': 7.627736084970971, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:56,851] Trial 12 finished with value: 0.27760268466652205 and parameters: {'C': 0.34104328355968905, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:56,936] Trial 3 finished with value: 0.29885561315972714 and parameters: {'C': 2.897803826016868, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:57,016] Trial 13 finished with value: 0.271047227926078 and parameters: {'C': 0.11077326621703923, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:57,107] Trial 14 finished with value: 0.271047227926078 and parameters: {'C': 1.0060835303449194, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:57,584] Trial 11 finished with value: 0.271047227926078 and parameters: {'C': 0.10835045768865317, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:57,848] Trial 16 finished with value: 0.271047227926078 and parameters: {'C': 0.0980558540522299, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:58,116] Trial 17 finished with value: 0.2999761113094801 and parameters: {'C': 2.319596239876496, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:58,352] Trial 20 finished with value: 0.30248847470265705 and parameters: {'C': 1.4745146166223773, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 9 with value: 0.30477127228175527.\n",
      "[I 2025-11-11 15:08:58,434] Trial 21 finished with value: 0.3074600172209327 and parameters: {'C': 1.655623583140748, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3074600172209327.\n",
      "[I 2025-11-11 15:08:58,449] Trial 18 finished with value: 0.30453699908566384 and parameters: {'C': 1.520178311746689, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3074600172209327.\n",
      "[I 2025-11-11 15:08:58,469] Trial 19 finished with value: 0.3042766128267987 and parameters: {'C': 1.364272315748104, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3074600172209327.\n",
      "[I 2025-11-11 15:08:58,862] Trial 22 finished with value: 0.305334449590864 and parameters: {'C': 1.7449367771613504, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3074600172209327.\n",
      "[I 2025-11-11 15:08:59,311] Trial 15 finished with value: 0.271047227926078 and parameters: {'C': 0.0647311637118137, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 21 with value: 0.3074600172209327.\n",
      "[I 2025-11-11 15:08:59,326] Trial 23 finished with value: 0.30453699908566384 and parameters: {'C': 1.535569120206925, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3074600172209327.\n",
      "[I 2025-11-11 15:08:59,558] Trial 24 finished with value: 0.3017222633173108 and parameters: {'C': 1.0513974790963998, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3074600172209327.\n",
      "[I 2025-11-11 15:08:59,773] Trial 26 finished with value: 0.30199936778884146 and parameters: {'C': 3.8037522451802515, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.3074600172209327.\n",
      "[I 2025-11-11 15:08:59,779] Trial 25 finished with value: 0.30929306250770144 and parameters: {'C': 2.653216629374672, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 25 with value: 0.30929306250770144.\n",
      "[I 2025-11-11 15:08:59,917] Trial 28 finished with value: 0.3086837913505284 and parameters: {'C': 3.4202512992279024, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 25 with value: 0.30929306250770144.\n",
      "[I 2025-11-11 15:09:00,027] Trial 27 finished with value: 0.3027955979763209 and parameters: {'C': 4.05811110547899, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 25 with value: 0.30929306250770144.\n",
      "[I 2025-11-11 15:09:00,068] Trial 29 finished with value: 0.30703340045074096 and parameters: {'C': 3.677527274080437, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 25 with value: 0.30929306250770144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 2.653216629374672, 'kernel': 'linear', 'gamma': 'scale'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.11      0.14       417\n",
      "           0       0.69      0.88      0.77      1273\n",
      "          -1       0.11      0.02      0.03       168\n",
      "\n",
      "    accuracy                           0.63      1858\n",
      "   macro avg       0.34      0.33      0.32      1858\n",
      "weighted avg       0.53      0.63      0.56      1858\n",
      "\n",
      "[[  44  365    8]\n",
      " [ 135 1121   17]\n",
      " [  15  150    3]]\n"
     ]
    }
   ],
   "source": [
    "print (\"---- TF-IDF ----\")\n",
    "tfidf_vec_predicted_SVM= svm(X_train_tfidf_vec, X_val_tfidf_vec, X_test_tfidf_vec, y_train, y_val, n_trials=30) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, tfidf_vec_predicted_SVM, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, tfidf_vec_predicted_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9f769d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 15:09:35,410] A new study created in memory with name: no-name-c5f44939-d87b-45d7-b70b-c822e11faef4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----WORD2VEC ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 15:09:37,628] Trial 1 finished with value: 0.271047227926078 and parameters: {'C': 0.3853407159473238, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 1 with value: 0.271047227926078.\n",
      "[I 2025-11-11 15:09:37,951] Trial 4 finished with value: 0.271047227926078 and parameters: {'C': 0.038993382676786, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 1 with value: 0.271047227926078.\n",
      "[I 2025-11-11 15:09:38,323] Trial 6 finished with value: 0.271047227926078 and parameters: {'C': 0.013677459196437055, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.271047227926078.\n",
      "[I 2025-11-11 15:09:38,518] Trial 5 finished with value: 0.4338411420906391 and parameters: {'C': 0.8597224524711686, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.4338411420906391.\n",
      "[I 2025-11-11 15:09:38,936] Trial 2 finished with value: 0.271047227926078 and parameters: {'C': 1.365233127757608, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.4338411420906391.\n",
      "[I 2025-11-11 15:09:39,718] Trial 7 finished with value: 0.39702198393931587 and parameters: {'C': 0.6561387716264788, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 5 with value: 0.4338411420906391.\n",
      "[I 2025-11-11 15:09:40,245] Trial 0 finished with value: 0.4553696084895877 and parameters: {'C': 1.3046244370929754, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:40,280] Trial 3 finished with value: 0.42876186162583646 and parameters: {'C': 0.8790574967877959, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:42,198] Trial 11 finished with value: 0.271047227926078 and parameters: {'C': 0.2579750782240642, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:42,240] Trial 12 finished with value: 0.3163987389339502 and parameters: {'C': 0.15031455828277632, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:42,481] Trial 8 finished with value: 0.271047227926078 and parameters: {'C': 0.017922746242219876, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:42,507] Trial 9 finished with value: 0.271047227926078 and parameters: {'C': 4.498925312999959, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:42,990] Trial 10 finished with value: 0.271047227926078 and parameters: {'C': 0.018586058173651894, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:43,065] Trial 14 finished with value: 0.271047227926078 and parameters: {'C': 0.3051004570800181, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:43,131] Trial 15 finished with value: 0.271047227926078 and parameters: {'C': 0.09789714207092337, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:44,780] Trial 13 finished with value: 0.27818696949559824 and parameters: {'C': 0.014611625291959057, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 0 with value: 0.4553696084895877.\n",
      "[I 2025-11-11 15:09:47,175] Trial 20 finished with value: 0.4650106837606838 and parameters: {'C': 3.642100537825549, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 20 with value: 0.4650106837606838.\n",
      "[I 2025-11-11 15:09:47,299] Trial 19 finished with value: 0.46635479041916167 and parameters: {'C': 4.725968949656242, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 19 with value: 0.46635479041916167.\n",
      "[I 2025-11-11 15:09:47,489] Trial 16 finished with value: 0.36636734105088536 and parameters: {'C': 0.4431813442095457, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 19 with value: 0.46635479041916167.\n",
      "[I 2025-11-11 15:09:47,543] Trial 21 finished with value: 0.4650106837606838 and parameters: {'C': 3.6770363610242187, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 19 with value: 0.46635479041916167.\n",
      "[I 2025-11-11 15:09:47,619] Trial 18 finished with value: 0.4632047819849452 and parameters: {'C': 7.884833014796289, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 19 with value: 0.46635479041916167.\n",
      "[I 2025-11-11 15:09:47,791] Trial 22 finished with value: 0.46050810369165934 and parameters: {'C': 2.5876824437614303, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 19 with value: 0.46635479041916167.\n",
      "[I 2025-11-11 15:09:48,559] Trial 17 finished with value: 0.548954739838943 and parameters: {'C': 9.082446685549941, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 17 with value: 0.548954739838943.\n",
      "[I 2025-11-11 15:09:49,329] Trial 23 finished with value: 0.46318735767474406 and parameters: {'C': 2.9221783005543487, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 17 with value: 0.548954739838943.\n",
      "[I 2025-11-11 15:09:51,131] Trial 28 finished with value: 0.4632227317687258 and parameters: {'C': 3.0378082003457108, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 17 with value: 0.548954739838943.\n",
      "[I 2025-11-11 15:09:51,767] Trial 25 finished with value: 0.4632047819849452 and parameters: {'C': 8.000395844933031, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 17 with value: 0.548954739838943.\n",
      "[I 2025-11-11 15:09:51,867] Trial 26 finished with value: 0.46488413547237073 and parameters: {'C': 9.385557709746092, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 17 with value: 0.548954739838943.\n",
      "[I 2025-11-11 15:09:51,879] Trial 24 finished with value: 0.46488413547237073 and parameters: {'C': 8.997171400748961, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 17 with value: 0.548954739838943.\n",
      "[I 2025-11-11 15:09:51,894] Trial 27 finished with value: 0.4663286564675224 and parameters: {'C': 6.686673827363753, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 17 with value: 0.548954739838943.\n",
      "[I 2025-11-11 15:09:52,018] Trial 29 finished with value: 0.4632047819849452 and parameters: {'C': 7.8252424978119395, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 17 with value: 0.548954739838943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 9.082446685549941, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.44      0.51       417\n",
      "           0       0.76      0.90      0.83      1273\n",
      "          -1       0.33      0.09      0.14       168\n",
      "\n",
      "    accuracy                           0.72      1858\n",
      "   macro avg       0.56      0.48      0.49      1858\n",
      "weighted avg       0.69      0.72      0.69      1858\n",
      "\n",
      "[[ 185  225    7]\n",
      " [ 104 1146   23]\n",
      " [  22  131   15]]\n"
     ]
    }
   ],
   "source": [
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_SVM= svm(X_train_word2vec, X_val_word2vec, X_test_word2vec, y_train, y_val, n_trials=30) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, word2vec_predicted_SVM, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791a4e1",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21c7661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def KNN(X_train, y_train, X_val, y_val, X_test):\n",
    "    k_values = range(1, 200,10)  # Determinar  intervalo de valores a testar para k\n",
    "    best_k = 1\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    k_list = []\n",
    "    accuracy_list = [] \n",
    "\n",
    "    for k in k_values:\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)  \n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_KNN = knn.predict(X_val) \n",
    "        accuracy = accuracy_score(y_val, y_pred_KNN)  \n",
    "\n",
    "        k_list.append(k)\n",
    "        accuracy_list.append(accuracy)  \n",
    "\n",
    "        if accuracy > best_accuracy: \n",
    "            best_accuracy = accuracy\n",
    "            best_k = k\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k)  \n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_KNN= knn.predict(X_test) \n",
    "    print(f\"Best k: {best_k}\")\n",
    "\n",
    "    return y_pred_KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fead510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Best k: 151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       417\n",
      "           1       0.68      0.98      0.80      1273\n",
      "           0       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.67      1858\n",
      "   macro avg       0.23      0.33      0.27      1858\n",
      "weighted avg       0.47      0.67      0.55      1858\n",
      "\n",
      "[[   0  417    0]\n",
      " [  29 1244    0]\n",
      " [   0  168    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_KNN= KNN(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_KNN, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3c7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Best k: 151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       417\n",
      "           1       0.68      0.98      0.80      1273\n",
      "           0       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.67      1858\n",
      "   macro avg       0.23      0.33      0.27      1858\n",
      "weighted avg       0.47      0.67      0.55      1858\n",
      "\n",
      "[[   0  417    0]\n",
      " [  29 1244    0]\n",
      " [   0  168    0]]\n",
      "----WORD2VEC ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.27      0.37       417\n",
      "           1       0.73      0.95      0.82      1273\n",
      "           0       0.20      0.01      0.02       168\n",
      "\n",
      "    accuracy                           0.71      1858\n",
      "   macro avg       0.51      0.41      0.41      1858\n",
      "weighted avg       0.65      0.71      0.65      1858\n",
      "\n",
      "[[ 112  304    1]\n",
      " [  56 1210    7]\n",
      " [  13  153    2]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "\n",
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_KNN= KNN(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, word2vec_predicted_KNN, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_KNN))\n",
    "\n",
    "#Glove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49589df2",
   "metadata": {},
   "source": [
    "## Decison Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d53d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar um classificador de árvore de decisão baseado em entropia\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree(X_train, y_train, X_val, y_val, X_test):\n",
    "    alphas = np.linspace(0.000, 0.01, 20)  # Testar 20 valores entre 0 e 0.01\n",
    "    best_alpha = 0\n",
    "    best_acc = 0\n",
    "\n",
    "    for alpha in alphas:\n",
    "        clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_val = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_alpha = alpha\n",
    "\n",
    "    print(f\"Melhor alpha: {best_alpha:.4f} \")\n",
    "\n",
    "    # Treinar modelo final com o melhor alpha\n",
    "    final_clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=best_alpha, random_state=42)\n",
    "    final_clf.fit(X_train, y_train)\n",
    "    y_pred_test = final_clf.predict(X_test)\n",
    "\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b899214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_DT= decision_tree(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_DT, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_DT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Melhor alpha: 0.0037 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.08      0.03      0.04       417\n",
      "           1       0.67      0.90      0.77      1273\n",
      "           0       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.62      1858\n",
      "   macro avg       0.25      0.31      0.27      1858\n",
      "weighted avg       0.48      0.62      0.54      1858\n",
      "\n",
      "[[  12  405    0]\n",
      " [ 126 1147    0]\n",
      " [   4  164    0]]\n",
      "----COUNT VECTORIZER ----\n",
      "Melhor alpha: 0.0047 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.30      0.35       417\n",
      "           1       0.72      0.88      0.79      1273\n",
      "           0       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.67      1858\n",
      "   macro avg       0.38      0.39      0.38      1858\n",
      "weighted avg       0.59      0.67      0.62      1858\n",
      "\n",
      "[[ 126  291    0]\n",
      " [ 153 1120    0]\n",
      " [  26  142    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TF-IDF\n",
    "\n",
    "#Word2vec\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "word2vec_predicted_DT= decision_tree(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "lista_y = [str(c) for c in (test['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, word2vec_predicted_DT, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_DT))\n",
    "\n",
    "\n",
    "#Glove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b484c",
   "metadata": {},
   "source": [
    "## Random Florest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a7257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, make_scorer\n",
    "\n",
    "def objective(X_train, y_train, X_val, y_val, trial):\n",
    "    n_estimators = trial.suggest_categorical('n_estimators', [50, 100, 200, 300])\n",
    "    max_depth = trial.suggest_categorical('max_depth', [5, 10, 15, 20])\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        max_features=max_features,\n",
    "        criterion=criterion,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predictions_rf = clf.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, predictions_rf, pos_label=1,average='macro')\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def random_florest(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(X_train, y_train, X_val, y_val, trial),\n",
    "                   n_trials=50, n_jobs=-1)\n",
    "\n",
    "    print(\"Melhores hiperparâmetros Random Forest:\")\n",
    "    print(study.best_params)\n",
    "\n",
    "    best_rf = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "    predictions_rf = best_rf.predict(X_test)\n",
    "    \n",
    "    return predictions_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01765274",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a144959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "\n",
    "def objective(X_train, y_train, X_val, y_val, trial):\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (100, 50)])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "    learning_rate_init = trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True)\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_val)\n",
    "    f1 = f1_score(y_val, preds, average='macro')\n",
    "    return f1\n",
    "\n",
    "def neural_network (X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(X_train, y_train, X_val, y_val, trial), n_trials=30)\n",
    "    print(\"Melhores parâmetros:\", study.best_params)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_model = MLPClassifier(\n",
    "        hidden_layer_sizes=best_params['hidden_layer_sizes'],\n",
    "        activation=best_params['activation'],\n",
    "        learning_rate_init=best_params['learning_rate_init'],\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    previsoes = best_model.predict(X_test)\n",
    "    \n",
    "    return previsoes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f827bcd",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d051225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "\n",
    "def objective(X_train, y_train, X_val, y_val, trial):\n",
    "    # Hiperparâmetros a otimizar\n",
    "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])  # compatíveis com L1 e L2\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, preds, average='macro')\n",
    "    return f1\n",
    "\n",
    "\n",
    "def logistic_regression(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(X_train, y_train, X_val, y_val, trial), n_trials=30)\n",
    "\n",
    "    print(\"Melhores parâmetros encontrados:\")\n",
    "    print(study.best_params)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_model = LogisticRegression(\n",
    "        **best_params,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    previsoes = best_model.predict(X_test)\n",
    "\n",
    "    return previsoes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
