{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5874fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fddcf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file          0\n",
       "id_sente      0\n",
       "id_article    0\n",
       "domain        0\n",
       "year          0\n",
       "sentences     0\n",
       "classe        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carregar dataset\n",
    "df = pd.read_csv('factnews_dataset.csv')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa80a44",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b710fb",
   "metadata": {},
   "source": [
    "divisão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d457cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#criar grupo treino, validação e teste\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['classe'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['classe'])\n",
    "\n",
    "#guardar conjuntos em memória\n",
    "train_df.to_csv(\"train.csv\", index=False) \n",
    "val_df.to_csv(\"val.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1708b8",
   "metadata": {},
   "source": [
    "balanceamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65b63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')\n",
    "val= pd.read_csv('val.csv')\n",
    "test= pd.read_csv('test.csv')\n",
    "\n",
    "y_test= test['classe']\n",
    "y_train= train['classe']\n",
    "y_val=val['classe']\n",
    "classes = test['classe'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce488a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto de treino:  classe\n",
      "-1     779\n",
      " 0    2375\n",
      " 1     312\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de validação:  classe\n",
      "-1    195\n",
      " 0    594\n",
      " 1     78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "conjunto de teste:  classe\n",
      "-1     417\n",
      " 0    1273\n",
      " 1     168\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das classes em cada conjunto\n",
    "print (\"conjunto de treino: \",y_train.value_counts().sort_index())\n",
    "print(\"\\nconjunto de validação: \",y_val.value_counts().sort_index())\n",
    "print(\"\\nconjunto de teste: \", y_test.value_counts().sort_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b76d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe\n",
      " 0    2375\n",
      "-1     779\n",
      " 1     312\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''from sklearn.utils import resample\n",
    "\n",
    "# Separar cada classe\n",
    "class_min = train[train['classe'] == -1]\n",
    "class_med = train[train['classe'] == 1]\n",
    "class_max = train[train['classe'] == 0]\n",
    "\n",
    "# Número da classe maior\n",
    "n_samples = len(class_max)\n",
    "\n",
    "# Replicar as classes menores até o tamanho da maior\n",
    "class_min_upsampled = resample(class_min, \n",
    "                            replace=True, \n",
    "                            n_samples=n_samples, \n",
    "                            random_state=42)\n",
    "\n",
    "class_med_upsampled = resample(class_med, \n",
    "                            replace=True, \n",
    "                            n_samples=n_samples, \n",
    "                            random_state=42)\n",
    "\n",
    "train_oversampling = pd.concat([class_min_upsampled, class_med_upsampled, class_max])\n",
    "\n",
    "# baralhar o conjunto de treino\n",
    "train_oversampling = train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(train_oversampling['classe'].value_counts())\n",
    "train_oversampling.to_csv('train_oversampling.txt', index=False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262d8a4",
   "metadata": {},
   "source": [
    "tokeinização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d610e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\didia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [neym, ,, part, 20, novembr, vai, lider, seleç...\n",
      "1    [forç, internac, transform, quest, taiwan, ass...\n",
      "2    [alianç, mai, quant, parlament, eleit, nome, p...\n",
      "3    [ger, mort, '', ,, declar, cabr, ,, 16ª, entre...\n",
      "4    [bisp, barr, (, ba, ), ,, dom, luiz, flávi, ca...\n",
      "Name: stems, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "#criar coluna tokens\n",
    "train['tokens'] = train['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "val['tokens']   = val['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "test['tokens'] = test['sentences'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "\n",
    "#remover stopwords\n",
    "train['tokens'] = train['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "val['tokens']   = val['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "test['tokens']  = test['tokens'].apply(lambda toks: [t for t in toks if t.lower() not in stop_words])\n",
    "\n",
    "#matizar\n",
    "#nltk . download ('rslp')\n",
    "stemmer = nltk . stem . RSLPStemmer ()\n",
    "train['stems'] = train['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "val['stems']   = val['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "test['stems'] = test['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "\n",
    "nltk . download ('rslp')\n",
    "stemmer = nltk . stem . RSLPStemmer ()\n",
    "train['stems'] = train['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "print(train['stems'].head())\n",
    "\n",
    "y_test= test['classe']\n",
    "y_train= train['classe']\n",
    "y_val=val['classe']\n",
    "classes = test['classe'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b02c9",
   "metadata": {},
   "source": [
    "# Construção dos modelos de representação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799b632",
   "metadata": {},
   "source": [
    "## TF-IDF - fred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13758dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_IDF():\n",
    "    tf_vect = TfidfVectorizer ( ngram_range =(1 ,2) , min_df =3 ,\n",
    "    max_df =0.5 , max_features =500)\n",
    "    p_tf = tf_vect . fit_transform ( docs )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eaac49",
   "metadata": {},
   "source": [
    "## CountVectorizer -didi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1399bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vec(train,val,test):\n",
    "    c_vect = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b|[^\\w\\s]\", ngram_range=(1,1), strip_accents='unicode',max_features=1000)\n",
    "\n",
    "    #juntar os tokens matizados em frases novvamente \n",
    "    text_train = train['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_val   = val['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    text_test = test['stems'].apply(lambda tokens: ' '.join(tokens))\n",
    "    \n",
    "    #print(\"Text train:\\n\", text_train.head())\n",
    "\n",
    "    # Transformar em vetores\n",
    "    X_train = c_vect.fit_transform(text_train)\n",
    "    X_val   = c_vect.transform(text_val)\n",
    "    X_test  = c_vect.transform(text_test)\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "666f038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count_vec, X_val_count_vec, X_test_count_vec = count_vec(train,val,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a974ef",
   "metadata": {},
   "source": [
    "## Glove -fred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f116c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72beca9e",
   "metadata": {},
   "source": [
    "## WORD2VEC -anaana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d7c7d",
   "metadata": {},
   "source": [
    "fontes : \n",
    "-   https://sites.google.com/view/nilc-usp/resources-and-tools?authuser=0\n",
    "-   https://huggingface.co/nilc-nlp/word2vec-skip-gram-300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bade9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install huggingface_hub\n",
    "#%pip install hf_hub_download\n",
    "#%pip install safetensors\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.numpy import load_file\n",
    "\n",
    "def carregar_word2vec():\n",
    "    path = hf_hub_download(repo_id=\"nilc-nlp/word2vec-skip-gram-300d\",\n",
    "                           filename=\"embeddings.safetensors\")\n",
    "\n",
    "    data = load_file(path)\n",
    "    vectors = data[\"embeddings\"]\n",
    "\n",
    "    vocab_path = hf_hub_download(repo_id=\"nilc-nlp/word2vec-skip-gram-300d\",\n",
    "                                 filename=\"vocab.txt\")\n",
    "    with open(vocab_path) as f:\n",
    "        vocab = [w.strip() for w in f]\n",
    "\n",
    "    print(vectors.shape)\n",
    "\n",
    "    model = KeyedVectors(vector_size=vectors.shape[1])\n",
    "    model.add_vectors(vocab, vectors)\n",
    "    model.fill_norms()\n",
    "\n",
    "    return model\n",
    "\n",
    "def vetor_frase(model, frase):\n",
    "    vectors = [model[w] for w in frase if w in model]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "def word2vec(train, val, test, coluna, model):\n",
    "    X_train = np.vstack([vetor_frase(model, tokens) for tokens in train[coluna]])\n",
    "    X_val   = np.vstack([vetor_frase(model, tokens) for tokens in val[coluna]])\n",
    "    X_test  = np.vstack([vetor_frase(model, tokens) for tokens in test[coluna]])\n",
    "\n",
    "\n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c9e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929606, 300)\n"
     ]
    }
   ],
   "source": [
    "model = carregar_word2vec()\n",
    "X_train_word2vec, X_val_word2vec, X_test_word2vec = word2vec(train, val, test, 'stems', model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "certos = (test_df['classe'] == test_df['Previsto4']).sum()\n",
    "total = len(test_df)\n",
    "\n",
    "matriz = confusion_matrix(test_df['classe'], test_df['Previsto4'], labels=classes)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matriz, display_labels=classes)\n",
    "disp.plot()\n",
    "plt.title(\"Matriz de confusão do teste\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(test_df['classe'], test_df['Previsto4'], labels=classes, digits=4)\n",
    "print(report)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955eb2ec",
   "metadata": {},
   "source": [
    "# Aplicar modelos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268c280",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc51ae",
   "metadata": {},
   "source": [
    "-   Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0229cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_MN(X_train, y_train, X_val, y_val, X_test, alphas):\n",
    "    best_alpha = None\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Procurar o melhor alpha com o conjunto de validação\n",
    "    for alpha in alphas:\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    print(f\"Melhor alpha encontrado: {best_alpha} (F1 val = {best_f1:.4f})\")\n",
    "\n",
    "    # Treinar o modelo final \n",
    "    final_clf = MultinomialNB(alpha=best_alpha)\n",
    "    final_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = final_clf.predict(X_test)\n",
    "\n",
    "    return y_test_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "222c6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def objective_naive_GS(trial, X_train, X_val, y_train, y_val):\n",
    "    # Definir o hiperparâmetro a otimizar\n",
    "    var_smoothing = trial.suggest_float(\"var_smoothing\", 1e-12, 1e-3, log=True)\n",
    "    # Criar o modelo\n",
    "    model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    # Treinar\n",
    "    model.fit(X_train, y_train)\n",
    "    # Avaliar no conjunto de validação\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
    "\n",
    "    return f1\n",
    "\n",
    "def naive_bayes_gs(X_train, X_val, X_test, y_train, y_val, n_trials=30):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective_naive_GS(trial, X_train, X_val, y_train, y_val),\n",
    "                   n_trials=n_trials, n_jobs=-1, show_progress_bar=False)\n",
    "    print(\"Melhores hiperparâmetros encontrados:\")\n",
    "    print(study.best_params)\n",
    "    # Treinar o melhor modelo com os melhores parâmetros\n",
    "    best_model = GaussianNB(**study.best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    # Avaliar no conjunto de teste\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c766d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 19:32:04,095] A new study created in memory with name: no-name-2c1c4c0e-8dfa-49f1-a510-c74d286794fd\n",
      "[I 2025-11-10 19:32:04,201] Trial 5 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 0.0005847340709527743}. Best is trial 5 with value: 0.4016961525191454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Melhor alpha encontrado: 0.1 (F1 val = 0.7918)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.72      0.71       417\n",
      "          -1       0.83      0.85      0.84      1273\n",
      "           0       0.27      0.21      0.24       168\n",
      "\n",
      "    accuracy                           0.76      1858\n",
      "   macro avg       0.60      0.59      0.60      1858\n",
      "weighted avg       0.75      0.76      0.76      1858\n",
      "\n",
      "[[ 299  108   10]\n",
      " [ 106 1082   85]\n",
      " [  17  115   36]]\n",
      "----WORD2VEC ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 19:32:04,224] Trial 6 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.4146317546733797e-05}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,228] Trial 0 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 5.1592505128262e-11}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,249] Trial 4 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.956973587815241e-11}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,263] Trial 3 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.643578122367029e-12}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,281] Trial 1 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.7910414396425882e-11}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,322] Trial 2 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 7.195378638315082e-12}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,326] Trial 7 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 0.0001445784843377698}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,368] Trial 8 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.294564954983013e-06}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,384] Trial 11 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.475574248086227e-06}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,394] Trial 10 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.415639931518261e-06}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,401] Trial 9 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 0.00015400935371940333}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,427] Trial 12 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.0431442699850604e-12}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,436] Trial 13 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.1420362418421147e-09}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,478] Trial 14 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.4653847564245496e-08}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,493] Trial 15 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 9.514901778932185e-10}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,516] Trial 16 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.4086362297437096e-08}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,546] Trial 17 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.3867895209476519e-09}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,550] Trial 19 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 6.882727957374673e-10}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,553] Trial 18 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 5.171143003758489e-10}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,595] Trial 21 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 6.395490606987171e-10}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,614] Trial 20 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 6.398591816520756e-10}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,623] Trial 22 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.5945074006266216e-10}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,648] Trial 23 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.0045088422941552e-10}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,662] Trial 24 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 1.0696804046748185e-10}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,676] Trial 26 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.920259932677671e-11}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,682] Trial 25 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 4.5853204183437256e-11}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,682] Trial 27 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.727212092919965e-11}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,693] Trial 28 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 3.357140602263903e-11}. Best is trial 5 with value: 0.4016961525191454.\n",
      "[I 2025-11-10 19:32:04,705] Trial 29 finished with value: 0.4016961525191454 and parameters: {'var_smoothing': 2.0315209471764265e-11}. Best is trial 5 with value: 0.4016961525191454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'var_smoothing': 0.0005847340709527743}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.42      0.43       417\n",
      "          -1       0.84      0.32      0.47      1273\n",
      "           0       0.11      0.62      0.18       168\n",
      "\n",
      "    accuracy                           0.37      1858\n",
      "   macro avg       0.46      0.46      0.36      1858\n",
      "weighted avg       0.68      0.37      0.43      1858\n",
      "\n",
      "[[175  44 198]\n",
      " [196 409 668]\n",
      " [ 30  33 105]]\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_NB= Naive_Bayes_MN(X_train_count_vec, y_train, X_val_count_vec,y_val , X_test_count_vec, \n",
    "                                    alphas=[0.01, 0.1, 0.5, 1.0, 3.0,5.0, 6.0, 7.0]) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_NB, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_NB))\n",
    "\n",
    "\n",
    "#TF-IDF\n",
    "\n",
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_NB= naive_bayes_gs(X_train_word2vec, X_val_word2vec, X_test_word2vec, y_train, y_val, n_trials=30) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, word2vec_predicted_NB, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_NB))\n",
    "#Glove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44bdd3",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab39b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, X_val, y_train, y_val):\n",
    "\n",
    "    #Definir hiperparâmetros a testar \n",
    "    C = trial.suggest_float('C', 0.01, 10.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "\n",
    "    #Criar modelo SVM \n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree)\n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree)\n",
    "\n",
    "    #treinar modelo com conjunto de treino\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #prever no conjunto de validação\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    #calcular f1\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "    return f1\n",
    "\n",
    "def svm(X_train, X_val, X_test, y_train, y_val, n_trials=30):\n",
    "    # Chamar o Optuna para otimizar os parâmetros\n",
    "    objeto_para_otimizar = optuna.create_study(direction='maximize')\n",
    "    objeto_para_otimizar.optimize(lambda trial: objective(trial, X_train, X_val, y_train, y_val),\n",
    "                   n_trials=n_trials, n_jobs=-1, show_progress_bar=False )\n",
    "\n",
    "    print(\"Melhores hiperparâmetros encontrados:\")\n",
    "    print(objeto_para_otimizar.best_params)\n",
    "\n",
    "    # Treinar o melhor modelo\n",
    "    best_model = SVC(**objeto_para_otimizar.best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    #  Avaliar no conjunto de teste\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f769d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 19:32:36,795] A new study created in memory with name: no-name-278c1c94-619d-4d4c-9e1d-b0e901f74558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 19:32:38,649] Trial 0 finished with value: 0.38074039026768175 and parameters: {'C': 0.5327345112419393, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.38074039026768175.\n",
      "[I 2025-11-10 19:32:38,687] Trial 5 finished with value: 0.6298317386665141 and parameters: {'C': 1.074486036180701, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.6298317386665141.\n",
      "[I 2025-11-10 19:32:38,702] Trial 2 finished with value: 0.271047227926078 and parameters: {'C': 0.014538213928159837, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.6298317386665141.\n",
      "[I 2025-11-10 19:32:38,904] Trial 3 finished with value: 0.6371999266499255 and parameters: {'C': 0.8547689235549176, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:39,129] Trial 7 finished with value: 0.35562906940044653 and parameters: {'C': 0.3307156194539283, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:39,268] Trial 1 finished with value: 0.5132308242445914 and parameters: {'C': 0.4156146283994637, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:39,576] Trial 4 finished with value: 0.37781779309445135 and parameters: {'C': 0.24180816475609546, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:39,900] Trial 6 finished with value: 0.5071067821067822 and parameters: {'C': 0.19618470720303738, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:40,312] Trial 9 finished with value: 0.455279593318809 and parameters: {'C': 4.075811785507964, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:40,811] Trial 8 finished with value: 0.5965989174495399 and parameters: {'C': 1.7836711200724666, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:40,993] Trial 14 finished with value: 0.5256238605702618 and parameters: {'C': 0.069685537769084, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:41,624] Trial 10 finished with value: 0.5565734927914937 and parameters: {'C': 1.7676568194495081, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:41,780] Trial 13 finished with value: 0.6127172814520152 and parameters: {'C': 3.7493685919484747, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:41,976] Trial 11 finished with value: 0.5916695307988297 and parameters: {'C': 2.9531284934276787, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:42,182] Trial 12 finished with value: 0.5177726926010678 and parameters: {'C': 0.6377438931784067, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:42,294] Trial 17 finished with value: 0.5270720764973639 and parameters: {'C': 0.06541198307116966, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:42,398] Trial 16 finished with value: 0.271047227926078 and parameters: {'C': 0.011085086673662562, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:42,778] Trial 15 finished with value: 0.5071067821067822 and parameters: {'C': 0.19246615713934118, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:43,236] Trial 18 finished with value: 0.5871032317420443 and parameters: {'C': 2.204418120504314, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:43,586] Trial 20 finished with value: 0.6298079314658687 and parameters: {'C': 1.1446230395884003, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:43,958] Trial 21 finished with value: 0.6345647082489188 and parameters: {'C': 1.0032055999262077, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:44,124] Trial 24 finished with value: 0.6345647082489188 and parameters: {'C': 1.015266805028161, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:44,906] Trial 26 finished with value: 0.271047227926078 and parameters: {'C': 7.954279735898009, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:45,254] Trial 27 finished with value: 0.271047227926078 and parameters: {'C': 8.950320774479042, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:45,478] Trial 19 finished with value: 0.582350621849796 and parameters: {'C': 8.670869572617685, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:45,664] Trial 22 finished with value: 0.5705898296571872 and parameters: {'C': 9.96766237021763, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:45,745] Trial 29 finished with value: 0.271047227926078 and parameters: {'C': 7.334709829605476, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:45,799] Trial 23 finished with value: 0.5837806384695394 and parameters: {'C': 8.766860782840874, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:46,177] Trial 25 finished with value: 0.581301525375525 and parameters: {'C': 9.248115404005414, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n",
      "[I 2025-11-10 19:32:47,066] Trial 28 finished with value: 0.5884091741353977 and parameters: {'C': 7.946403137714985, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.6371999266499255.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 0.8547689235549176, 'kernel': 'linear', 'gamma': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 19:32:49,218] A new study created in memory with name: no-name-c75c3ca4-9105-42dc-beb4-80a8e336475f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.64      0.67       417\n",
      "          -1       0.81      0.87      0.84      1273\n",
      "           0       0.28      0.18      0.22       168\n",
      "\n",
      "    accuracy                           0.76      1858\n",
      "   macro avg       0.60      0.56      0.58      1858\n",
      "weighted avg       0.74      0.76      0.75      1858\n",
      "\n",
      "[[ 268  138   11]\n",
      " [  96 1111   66]\n",
      " [  15  123   30]]\n",
      "----WORD2VEC ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 19:32:53,041] Trial 0 finished with value: 0.271047227926078 and parameters: {'C': 0.5436062645962279, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.271047227926078.\n",
      "[I 2025-11-10 19:32:53,496] Trial 1 finished with value: 0.46313868613138687 and parameters: {'C': 1.5024786729753439, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 1 with value: 0.46313868613138687.\n",
      "[I 2025-11-10 19:32:53,904] Trial 4 finished with value: 0.41158614386960846 and parameters: {'C': 0.6923107741311169, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.46313868613138687.\n",
      "[I 2025-11-10 19:32:54,020] Trial 2 finished with value: 0.30131012163821 and parameters: {'C': 0.12593217954236974, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 1 with value: 0.46313868613138687.\n",
      "[I 2025-11-10 19:32:54,271] Trial 6 finished with value: 0.271047227926078 and parameters: {'C': 0.28754023782484933, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.46313868613138687.\n",
      "[I 2025-11-10 19:32:54,370] Trial 5 finished with value: 0.5356140657714318 and parameters: {'C': 6.912494509544803, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:54,621] Trial 7 finished with value: 0.271047227926078 and parameters: {'C': 0.03410975750636334, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:55,496] Trial 3 finished with value: 0.29854071390121545 and parameters: {'C': 0.07741146789798714, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:56,980] Trial 8 finished with value: 0.35330479247696484 and parameters: {'C': 0.18913472183420757, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:57,303] Trial 13 finished with value: 0.271047227926078 and parameters: {'C': 8.889414965671378, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:58,257] Trial 11 finished with value: 0.271047227926078 and parameters: {'C': 0.017744863599893208, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:58,754] Trial 12 finished with value: 0.46050810369165934 and parameters: {'C': 2.56466886484515, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:58,916] Trial 9 finished with value: 0.271047227926078 and parameters: {'C': 0.012008701945708088, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:59,177] Trial 10 finished with value: 0.5137304125830581 and parameters: {'C': 7.986549982952951, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:32:59,747] Trial 14 finished with value: 0.46722453691220617 and parameters: {'C': 4.254155201476665, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:33:00,193] Trial 15 finished with value: 0.271047227926078 and parameters: {'C': 3.8197862999290164, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:33:00,446] Trial 16 finished with value: 0.271047227926078 and parameters: {'C': 0.014260076651936234, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 5 with value: 0.5356140657714318.\n",
      "[I 2025-11-10 19:33:02,909] Trial 17 finished with value: 0.5407212612331828 and parameters: {'C': 7.1554955844390244, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:03,989] Trial 20 finished with value: 0.45588341748930333 and parameters: {'C': 2.9307783131101686, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:04,256] Trial 18 finished with value: 0.45954228748787784 and parameters: {'C': 4.8015572861447176, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:04,407] Trial 19 finished with value: 0.4523046398046398 and parameters: {'C': 2.755451026887581, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:05,038] Trial 21 finished with value: 0.4747442642787784 and parameters: {'C': 9.77022798574402, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:05,699] Trial 24 finished with value: 0.4712962390307928 and parameters: {'C': 8.974427285324026, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:05,822] Trial 22 finished with value: 0.4721309763610367 and parameters: {'C': 8.58979270365197, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:06,202] Trial 23 finished with value: 0.4721309763610367 and parameters: {'C': 8.599810542072696, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:07,991] Trial 25 finished with value: 0.46121908296624553 and parameters: {'C': 1.4473118782110335, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:08,729] Trial 26 finished with value: 0.4304347826086956 and parameters: {'C': 1.011644355466102, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:09,103] Trial 27 finished with value: 0.4300255059474148 and parameters: {'C': 0.9526800605754672, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:09,415] Trial 29 finished with value: 0.454517077967772 and parameters: {'C': 1.3304412034903768, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 17 with value: 0.5407212612331828.\n",
      "[I 2025-11-10 19:33:09,944] Trial 28 finished with value: 0.5499021396127776 and parameters: {'C': 8.926843787631416, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 28 with value: 0.5499021396127776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 8.926843787631416, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.44      0.51       417\n",
      "          -1       0.76      0.90      0.83      1273\n",
      "           0       0.33      0.08      0.13       168\n",
      "\n",
      "    accuracy                           0.72      1858\n",
      "   macro avg       0.56      0.48      0.49      1858\n",
      "weighted avg       0.69      0.72      0.69      1858\n",
      "\n",
      "[[ 185  225    7]\n",
      " [ 104 1147   22]\n",
      " [  22  132   14]]\n"
     ]
    }
   ],
   "source": [
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_SVM= svm(X_train_count_vec, X_val_count_vec, X_test_count_vec, y_train, y_val, n_trials=30) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_SVM, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_SVM))\n",
    "\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_SVM= svm(X_train_word2vec, X_val_word2vec, X_test_word2vec, y_train, y_val, n_trials=30) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, word2vec_predicted_SVM, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791a4e1",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21c7661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def KNN(X_train, y_train, X_val, y_val, X_test):\n",
    "    k_values = range(1, 200,10)  # Determinar  intervalo de valores a testar para k\n",
    "    best_k = 1\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    k_list = []\n",
    "    accuracy_list = [] \n",
    "\n",
    "    for k in k_values:\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)  \n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_KNN = knn.predict(X_val) \n",
    "        accuracy = accuracy_score(y_val, y_pred_KNN)  \n",
    "\n",
    "        k_list.append(k)\n",
    "        accuracy_list.append(accuracy)  \n",
    "\n",
    "        if accuracy > best_accuracy: \n",
    "            best_accuracy = accuracy\n",
    "            best_k = k\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k)  \n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_KNN= knn.predict(X_test) \n",
    "    print(f\"Best k: {best_k}\")\n",
    "\n",
    "    return y_pred_KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4c3c7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Best k: 171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.56      0.63       417\n",
      "          -1       0.78      0.94      0.85      1273\n",
      "           0       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.77      1858\n",
      "   macro avg       0.50      0.50      0.49      1858\n",
      "weighted avg       0.70      0.77      0.72      1858\n",
      "\n",
      "[[ 232  185    0]\n",
      " [  77 1196    0]\n",
      " [   9  159    0]]\n",
      "----WORD2VEC ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.27      0.37       417\n",
      "          -1       0.73      0.95      0.82      1273\n",
      "           0       0.20      0.01      0.02       168\n",
      "\n",
      "    accuracy                           0.71      1858\n",
      "   macro avg       0.51      0.41      0.41      1858\n",
      "weighted avg       0.65      0.71      0.65      1858\n",
      "\n",
      "[[ 112  304    1]\n",
      " [  56 1210    7]\n",
      " [  13  153    2]]\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_KNN= KNN(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_KNN, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_KNN))\n",
    "\n",
    "#TF-IDF\n",
    "\n",
    "#Word2vec\n",
    "print (\"----WORD2VEC ----\")\n",
    "word2vec_predicted_KNN= KNN(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, word2vec_predicted_KNN, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_KNN))\n",
    "\n",
    "#Glove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49589df2",
   "metadata": {},
   "source": [
    "## Decison Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d53d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar um classificador de árvore de decisão baseado em entropia\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree(X_train, y_train, X_val, y_val, X_test):\n",
    "    alphas = np.linspace(0.000, 0.01, 20)  # Testar 20 valores entre 0 e 0.01\n",
    "    best_alpha = 0\n",
    "    best_acc = 0\n",
    "\n",
    "    for alpha in alphas:\n",
    "        clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_val = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_alpha = alpha\n",
    "\n",
    "    print(f\"Melhor alpha: {best_alpha:.4f} \")\n",
    "\n",
    "    # Treinar modelo final com o melhor alpha\n",
    "    final_clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=best_alpha, random_state=42)\n",
    "    final_clf.fit(X_train, y_train)\n",
    "    y_pred_test = final_clf.predict(X_test)\n",
    "\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d288c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----COUNT VECTORIZER ----\n",
      "Melhor alpha: 0.0026 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.64      0.68       417\n",
      "          -1       0.79      0.93      0.85      1273\n",
      "           0       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.78      1858\n",
      "   macro avg       0.51      0.52      0.51      1858\n",
      "weighted avg       0.71      0.78      0.74      1858\n",
      "\n",
      "[[ 266  151    0]\n",
      " [  92 1180    1]\n",
      " [   9  159    0]]\n",
      "----COUNT VECTORIZER ----\n",
      "Melhor alpha: 0.0047 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.30      0.35       417\n",
      "          -1       0.72      0.88      0.79      1273\n",
      "           0       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.67      1858\n",
      "   macro avg       0.38      0.39      0.38      1858\n",
      "weighted avg       0.59      0.67      0.62      1858\n",
      "\n",
      "[[ 126  291    0]\n",
      " [ 153 1120    0]\n",
      " [  26  142    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\didia\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "count_vec_predicted_DT= decision_tree(X_train_count_vec, y_train, X_val_count_vec, y_val, X_test_count_vec) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, count_vec_predicted_DT, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, count_vec_predicted_DT))\n",
    "\n",
    "#TF-IDF\n",
    "\n",
    "#Word2vec\n",
    "print (\"----COUNT VECTORIZER ----\")\n",
    "word2vec_predicted_DT= decision_tree(X_train_word2vec, y_train, X_val_word2vec, y_val, X_test_word2vec) \n",
    "lista_y = [str(c) for c in (train['classe'].unique())]\n",
    "print(metrics.classification_report(\n",
    "y_test, word2vec_predicted_DT, target_names=set(lista_y)))\n",
    "print(metrics.confusion_matrix(y_test, word2vec_predicted_DT))\n",
    "\n",
    "#Glove\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
